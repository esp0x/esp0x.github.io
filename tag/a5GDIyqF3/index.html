<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta name="keywords" content="信息安全">
<meta name="description" content="温故而知新">
<meta name="theme-color" content="#000">
<title>Esp0x</title>
<link rel="shortcut icon" href="/favicon.ico?v=1626407872846">
<link rel="stylesheet" href="/styles/main.css">
<link rel="stylesheet" href="/media/css/muse.css">

<link rel="stylesheet" href="/media/fonts/font-awesome.css">
<link
  href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"
  rel="stylesheet" type="text/css">

<link href="/media/hljs/styles/androidstudio.css"
  rel="stylesheet">

<script src="/media/hljs/highlight.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>

<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>



</head>

<body>
  <div class="head-top-line"></div>
  <div class="header-box">
    
<div class="muse">
  <header class="header bg-color ">
    <div class="blog-header box-shadow-wrapper  " id="header">
      <div class="nav-toggle" id="nav_toggle">
        <div class="toggle-box">
          <div class="line line-top"></div>
          <div class="line line-center"></div>
          <div class="line line-bottom"></div>
        </div>
      </div>
      <div class="site-meta">       
        <div class="site-title">
          
            <a href="/" class="brand">
              <span>Esp0x</span>
            </a>  
          
        </div>
        
          <p class="subtitle">精于心，简于形</p>
        
      </div>
      <nav class="site-nav" id="site_nav">
        <ul id="nav_ul">
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/" target="_self">
                  <i class="fa fa-home"></i> 首页
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/archives/" target="_self">
                  <i class="fa fa-archive"></i> 归档
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/tags/" target="_self">
                  <i class="fa fa-tags"></i> 标签
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/post/about/" target="_self">
                  <i class="fa fa-user"></i> 关于
                </a>
              
            </li>
          
          
            
              <li class="nav-item ">
                <a href="/friends/" target="_self">
                  
                    <i class="fa fa-address-book"></i> 友情链接
                  
                </a>
              </li>
            
          
        </ul>
      </nav>
    </div>
  </header>
</div>

<script type="text/javascript"> 
 
  let showNav = true;

  let navToggle = document.querySelector('#nav_toggle'),
  siteNav = document.querySelector('#site_nav');
  
  function navClick() {
    let sideBar = document.querySelector('.sidebar');
    let navUl = document.querySelector('#nav_ul');
    navToggle.classList.toggle('nav-toggle-active');
    siteNav.classList.toggle('nav-menu-active');
    if (siteNav.classList.contains('nav-menu-active')) {
      siteNav.style = "height: " + (navUl.children.length * 42) +"px !important";
    } else {
      siteNav.style = "";
    }
  }

  navToggle.addEventListener('click',navClick);  
</script>
  </div>
  <div class="main-continer">
    
    <div
      class="section-layout bg-color muse">
      <div class="section-layout-wrapper">
        <div id="sidebarMeta" class="sidebar">
    
<div class="sidebar-wrapper box-shadow-wrapper ">
  <div class="sidebar-item">
    <img class="site-author-image right-motion" src="/images/avatar.png"/>
    <p class="site-author-name">jiffies@live.com</p>
    
  </div>
  <div class="sidebar-item side-item-stat right-motion">
    <div class="sidebar-item-box">
      <a href="/archives/">
        
        <span class="site-item-stat-count">29</span>
        <span class="site-item-stat-name">文章</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="">
        <span class="site-item-stat-count">10</span>
        <span class="site-item-stat-name">分类</span>
      </a>
    </div>
    <div class="sidebar-item-box">
      <a href="/tags/">
        <span class="site-item-stat-count">10</span>
        <span class="site-item-stat-name">标签</span>
      </a>
    </div>
  </div>
  
  


</div>
</div>
<script>
  let sidebarMeta = document.querySelector('#sidebarMeta');
  let scheme = 'muse';
  let sidebarWrapper = document.querySelector('.sidebar-wrapper');
  if (sidebarMeta && (scheme === 'pisces' || scheme === 'gemini')) {
    document.addEventListener('scroll', function(e) {
      if (document.scrollingElement.scrollTop > parseInt(sidebarMeta.style.marginTop) + 10) {
        sidebarWrapper.classList.add('home-sidebar-fixed')
      } else {
        sidebarWrapper.classList.remove('home-sidebar-fixed')
      }
    });
  }
  </script>
        <div class="section-box tag-line box-shadow-wrapper">
          <section class="section tags-section posts-expand bg-color">
            <div class="padding-wrapper">
  <div class="tag-timeline-box">
    <div class="tag-timeline-wrapper">
      <div class="tag-timeline-title">
        <h2>
          信息安全
          <small>标签</small>
        </h2>
      </div>
      
      
      
      
      
      <a href="https://esp0x.github.io/post/msf-zhong-shi-yong-mei-ju-mo-kuai-jin-xing-ge-chong-fu-wu-deng-lu-de-po-jie/">
        <div class="motion-warpper">
          <div class="tag-post-node">
            <h1>
              07-16
              <small>MSF中使用枚举模块进行各种服务登陆的破解</small>
            </h1>
          </div>
        </div>
      </a>
      
      
      
      
      
      
      
      <a href="https://esp0x.github.io/post/hydra-bao-li-po-jie-gong-ju-jian-dan-shi-yong-shuo-ming/">
        <div class="motion-warpper">
          <div class="tag-post-node">
            <h1>
              07-16
              <small>Hydra暴力破解工具简单使用说明</small>
            </h1>
          </div>
        </div>
      </a>
      
      
      
      
      
      
      
      <a href="https://esp0x.github.io/post/sublist3r-zi-yu-ming-sao-miao-gong-ju-shi-yong-shuo-ming/">
        <div class="motion-warpper">
          <div class="tag-post-node">
            <h1>
              07-15
              <small>Sublist3r子域名扫描工具使用说明</small>
            </h1>
          </div>
        </div>
      </a>
      
      
      
      
      
      
      
      <a href="https://esp0x.github.io/post/subdomainbrutepy-gong-ju-de-jian-dan-shi-yong-shuo-ming/">
        <div class="motion-warpper">
          <div class="tag-post-node">
            <h1>
              07-15
              <small>SubDomainBrute.py工具的简单使用说明</small>
            </h1>
          </div>
        </div>
      </a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      <a href="https://esp0x.github.io/post/li-jie-oauth-20-de-ji-ben-liu-cheng/">
        <div class="motion-warpper">
          <div class="tag-post-node">
            <h1>
              02-04
              <small>理解OAuth 2.0的基本流程</small>
            </h1>
          </div>
        </div>
      </a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </div>
  </div>
</div>
          </section>
        </div>
      </div>
    </div>
    <div class="footer-box">
  <footer class="footer">
    <div class="copyright">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | © 2019-2020 Theme By <a href="https://github.com/hsxyhao/gridea-theme-next" target="_blank">HsxyHao</a>
    </div>
    <div class="poweredby">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
    </div>
  </footer>
  
  
    <div class="drawer-box right" id="drawer_box">
      <span class="muse-line muse-line-first"></span>
      <span class="muse-line muse-line-middle"></span>
      <span class="muse-line muse-line-last"></span>
    </div>
  
  <div class="muse back-to-top" id="back_to_top">
    <i class="fa fa-arrow-up"></i>
    
  </div>
  
    <div class="bg-img">
      <img src="\media\images\custom-bgImg.jpeg" />
    </div>
  
  
    
<link rel="stylesheet" href="/media/live2d/css/live2d.css" />
<div class="box-scale">
  <div id="landlord" style="left: 5px;bottom: px;"
    data-key="">
    <canvas id="live2d" width="500" height="560" class="live2d"></canvas>
    

      <div class="message" style="opacity:0"></div>
      <div class="live_talk_input_body">
        <div class="live_talk_input_name_body">
          <input name="name" type="text" class="live_talk_name white_input" id="AIuserName" autocomplete="off"
            placeholder="你的名字" />
        </div>
        <div class="live_talk_input_text_body">
          <input name="talk" type="text" class="live_talk_talk white_input" id="AIuserText" autocomplete="off"
            placeholder="要和我聊什么呀？" />
          <button type="button" class="live_talk_send_btn" id="talk_send">发送</button>
        </div>
      </div>
      <input name="live_talk" id="live_talk" value="1" type="hidden" />
      <div class="live_ico_box">
        <div class="live_ico_item type_info" id="showInfoBtn"></div>
        <div class="live_ico_item type_talk" id="showTalkBtn"></div>
        
        <div class="live_ico_item type_youdu" id="youduButton"></div>
        <div class="live_ico_item type_quit" id="hideButton"></div>
        <input name="live_statu_val" id="live_statu_val" value="0" type="hidden" />
        <audio src="" style="display:none;" id="live2d_bgm" data-bgm="0" preload="none"></audio>
        <input id="duType" value="douqilai" type="hidden">
        
      </div>
    
  </div>
</div>
<div id="open_live2d">召唤看板娘</div>
<script src="https://libs.baidu.com/jquery/2.0.0/jquery.min.js"></script>
<script>
  var message_Path = 'https://cdn.jsdelivr.net/gh/hsxyhao/live2d.github.io@master/';
  let landlord = document.querySelector('#landlord');
  var apiKey = landlord.dataset.key;
</script>
<script type="text/javascript" src="/media/live2d/js/live2d.js"></script>
<script>
	var home_Path = document.location.protocol + '//' + window.document.location.hostname + ":" + window.document.location.port + '/';
	var userAgent = window.navigator.userAgent.toLowerCase();
	var norunAI = ["android", "iphone", "ipod", "ipad", "windows phone", "mqqbrowser", "msie", "trident/7.0"];
	var norunFlag = false;

	for (var i = 0; i < norunAI.length; i++) {
		if (userAgent.indexOf(norunAI[i]) > -1) {
			norunFlag = true;
			break;
		}
	}

	if (!window.WebGLRenderingContext) {
		norunFlag = true;
	}

	if (!norunFlag) {
		var hitFlag = false;
		var AIFadeFlag = false;
		var liveTlakTimer = null;
		var sleepTimer_ = null;
		var AITalkFlag = false;
		var talkNum = 0;
		(function () {
			function renderTip(template, context) {
				var tokenReg = /(\\)?\{([^\{\}\\]+)(\\)?\}/g;
				return template.replace(tokenReg, function (word, slash1, token, slash2) {
					if (slash1 || slash2) {
						return word.replace('\\', '');
					}
					var variables = token.replace(/\s/g, '').split('.');
					var currentObject = context;
					var i, length, variable;
					for (i = 0, length = variables.length; i < length; ++i) {
						variable = variables[i];
						currentObject = currentObject[variable];
						if (currentObject === undefined || currentObject === null) return '';
					}
					return currentObject;
				});
			}

			String.prototype.renderTip = function (context) {
				return renderTip(this, context);
			};

			var re = /x/;
			re.toString = function () {
				showMessage('哈哈，你打开了控制台，是想要看看我的秘密吗？', 5000);
				return '';
			};

			$(document).on('copy', function () {
				showMessage('你都复制了些什么呀，转载要记得加上出处哦~~', 5000);
			});

			function initTips() {
				$.ajax({
					cache: true,
					url: message_Path + 'message.json',
					dataType: "json",
					success: function (result) {
						$.each(result.mouseover, function (index, tips) {
							$(tips.selector).mouseover(function () {
								var text = tips.text;
								if (Array.isArray(tips.text)) text = tips.text[Math.floor(Math.random() * tips.text.length + 1) - 1];
								text = text.renderTip({ text: $(this).text() });
								showMessage(text, 3000);
								talkValTimer();
								clearInterval(liveTlakTimer);
								liveTlakTimer = null;
							});
							$(tips.selector).mouseout(function () {
								showHitokoto();
								if (liveTlakTimer == null) {
									liveTlakTimer = window.setInterval(function () {
										showHitokoto();
									}, 15000);
								};
							});
						});
						$.each(result.click, function (index, tips) {
							$(tips.selector).click(function () {
								if (hitFlag) {
									return false
								}
								hitFlag = true;
								setTimeout(function () {
									hitFlag = false;
								}, 8000);
								var text = tips.text;
								if (Array.isArray(tips.text)) text = tips.text[Math.floor(Math.random() * tips.text.length + 1) - 1];
								text = text.renderTip({ text: $(this).text() });
								showMessage(text, 3000);
							});
							clearInterval(liveTlakTimer);
							liveTlakTimer = null;
							if (liveTlakTimer == null) {
								liveTlakTimer = window.setInterval(function () {
									showHitokoto();
								}, 15000);
							};
						});
					}
				});
			}
			initTips();

			var text;
			if (document.referrer !== '') {
				var referrer = document.createElement('a');
				referrer.href = document.referrer;
				text = '嗨！来自 <span style="color:#0099cc;">' + referrer.hostname + '</span> 的朋友！';
				var domain = referrer.hostname.split('.')[1];
				if (domain == 'baidu') {
					text = '嗨！ 来自 百度搜索 的朋友！<br>欢迎访问<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				} else if (domain == 'so') {
					text = '嗨！ 来自 360搜索 的朋友！<br>欢迎访问<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				} else if (domain == 'google') {
					text = '嗨！ 来自 谷歌搜索 的朋友！<br>欢迎访问<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				}
			} else {
				if (window.location.href == home_Path) { //主页URL判断，需要斜杠结尾
					var now = (new Date()).getHours();
					if (now > 23 || now <= 5) {
						text = '你是夜猫子呀？这么晚还不睡觉，明天起的来嘛？';
					} else if (now > 5 && now <= 7) {
						text = '早上好！一日之计在于晨，美好的一天就要开始了！';
					} else if (now > 7 && now <= 11) {
						text = '上午好！工作顺利嘛，不要久坐，多起来走动走动哦！';
					} else if (now > 11 && now <= 14) {
						text = '中午了，工作了一个上午，现在是午餐时间！';
					} else if (now > 14 && now <= 17) {
						text = '午后很容易犯困呢，今天的运动目标完成了吗？';
					} else if (now > 17 && now <= 19) {
						text = '傍晚了！窗外夕阳的景色很美丽呢，最美不过夕阳红~~';
					} else if (now > 19 && now <= 21) {
						text = '晚上好，今天过得怎么样？';
					} else if (now > 21 && now <= 23) {
						text = '已经这么晚了呀，早点休息吧，晚安~~';
					} else {
						text = '嗨~ 快来逗我玩吧！';
					}
				} else {
					text = '欢迎阅读<span style="color:#0099cc;">「 ' + document.title.split(' - ')[0] + ' 」</span>';
				}
			}
			showMessage(text, 12000);
		})();

		liveTlakTimer = setInterval(function () {
			showHitokoto();
		}, 15000);

		function showHitokoto() {
			if (sessionStorage.getItem("Sleepy") !== "1") {
				if (!AITalkFlag) {
					$.getJSON('https://v1.hitokoto.cn/', function (result) {
						talkValTimer();
						showMessage(result.hitokoto, 0);
					});
				}
			} else {
				hideMessage(0);
				if (sleepTimer_ == null) {
					sleepTimer_ = setInterval(function () {
						checkSleep();
					}, 200);
				}
			}
		}

		function checkSleep() {
			var sleepStatu = sessionStorage.getItem("Sleepy");
			if (sleepStatu !== '1') {
				talkValTimer();
				showMessage('你回来啦~', 0);
				clearInterval(sleepTimer_);
				sleepTimer_ = null;
			}
		}

		function showMessage(text, timeout) {
			if (Array.isArray(text)) text = text[Math.floor(Math.random() * text.length + 1) - 1];
			$('.message').stop();
			$('.message').html(text);
			$('.message').fadeTo(200, 1);
			//if (timeout === null) timeout = 5000;
			//hideMessage(timeout);
		}
		function talkValTimer() {
			$('#live_talk').val('1');
		}

		function hideMessage(timeout) {
			//$('.message').stop().css('opacity',1);
			if (timeout === null) timeout = 5000;
			$('.message').delay(timeout).fadeTo(200, 0);
		}

		function initLive2d() {
			$('#hideButton').on('click', function () {
				if (AIFadeFlag) {
					return false;
				} else {
					AIFadeFlag = true;
					localStorage.setItem("live2dhidden", "0");
					$('#landlord').fadeOut(200);
					$('#open_live2d').delay(200).fadeIn(200);
					setTimeout(function () {
						AIFadeFlag = false;
					}, 300);
				}
			});
			$('#open_live2d').on('click', function () {
				if (AIFadeFlag) {
					return false;
				} else {
					AIFadeFlag = true;
					localStorage.setItem("live2dhidden", "1");
					$('#open_live2d').fadeOut(200);
					$('#landlord').delay(200).fadeIn(200);
					setTimeout(function () {
						AIFadeFlag = false;
					}, 300);
				}
			});
			$('#youduButton').on('click', function () {
				if ($('#youduButton').hasClass('doudong')) {
					var typeIs = $('#youduButton').attr('data-type');
					$('#youduButton').removeClass('doudong');
					$('body').removeClass(typeIs);
					$('#youduButton').attr('data-type', '');
				} else {
					var duType = $('#duType').val();
					var duArr = duType.split(",");
					var dataType = duArr[Math.floor(Math.random() * duArr.length)];

					$('#youduButton').addClass('doudong');
					$('#youduButton').attr('data-type', dataType);
					$('body').addClass(dataType);
				}
			});
			if (apiKey) {
				$('#showInfoBtn').on('click', function () {
					var live_statu = $('#live_statu_val').val();
					if (live_statu == "0") {
						return
					} else {
						$('#live_statu_val').val("0");
						$('.live_talk_input_body').fadeOut(500);
						AITalkFlag = false;
						showHitokoto();
						$('#showTalkBtn').show();
						$('#showInfoBtn').hide();
					}
				});
				$('#showTalkBtn').on('click', function () {
					var live_statu = $('#live_statu_val').val();
					if (live_statu == "1") {
						return
					} else {
						$('#live_statu_val').val("1");
						$('.live_talk_input_body').fadeIn(500);
						AITalkFlag = true;
						$('#showTalkBtn').hide();
						$('#showInfoBtn').show();

					}
				});
				$('#talk_send').on('click', function () {
					var info_ = $('#AIuserText').val();
					var userid_ = $('#AIuserName').val();
					if (info_ == "") {
						showMessage('写点什么吧！', 0);
						return;
					}
					if (userid_ == "") {
						showMessage('聊之前请告诉我你的名字吧！', 0);
						return;
					}
					showMessage('思考中~', 0);
					let protocol = window.location.protocol.indexOf("s") > 0 ? "https" : "http";
					$.ajax({
						type: "get",
						url: `${protocol}://www.tuling123.com/openapi/api?key=${apiKey}&info=${info_}`,
						dataType: "json",
						success: function (res) {
							talkValTimer();
							showMessage(res.text, 0);
							$('#AIuserText').val("");
							sessionStorage.setItem("live2duser", userid_);
						},
						error: function (e) {
							talkValTimer();
							showMessage('似乎有什么错误，请和站长联系！', 0);
						}
					});
				});
			} else {
				$('#showInfoBtn').hide();
				$('#showTalkBtn').hide();
			}
			//获取音乐信息初始化
			var bgmListInfo = $('input[name=live2dBGM]');
			if (bgmListInfo.length == 0) {
				$('#musicButton').hide();
			} else {
				var bgmPlayNow = parseInt($('#live2d_bgm').attr('data-bgm'));
				var bgmPlayTime = 0;
				var live2dBGM_Num = sessionStorage.getItem("live2dBGM_Num");
				var live2dBGM_PlayTime = sessionStorage.getItem("live2dBGM_PlayTime");
				if (live2dBGM_Num) {
					if (live2dBGM_Num <= $('input[name=live2dBGM]').length - 1) {
						bgmPlayNow = parseInt(live2dBGM_Num);
					}
				}
				if (live2dBGM_PlayTime) {
					bgmPlayTime = parseInt(live2dBGM_PlayTime);
				}
				var live2dBGMSrc = bgmListInfo.eq(bgmPlayNow).val();
				$('#live2d_bgm').attr('data-bgm', bgmPlayNow);
				$('#live2d_bgm').attr('src', live2dBGMSrc);
				$('#live2d_bgm')[0].currentTime = bgmPlayTime;
				$('#live2d_bgm')[0].volume = 0.5;
				var live2dBGM_IsPlay = sessionStorage.getItem("live2dBGM_IsPlay");
				var live2dBGM_WindowClose = sessionStorage.getItem("live2dBGM_WindowClose");
				if (live2dBGM_IsPlay == '0' && live2dBGM_WindowClose == '0') {
					$('#live2d_bgm')[0].play();
					$('#musicButton').addClass('play');
				}
				sessionStorage.setItem("live2dBGM_WindowClose", '1');
				$('#musicButton').on('click', function () {
					if ($('#musicButton').hasClass('play')) {
						$('#live2d_bgm')[0].pause();
						$('#musicButton').removeClass('play');
						sessionStorage.setItem("live2dBGM_IsPlay", '1');
					} else {
						$('#live2d_bgm')[0].play();
						$('#musicButton').addClass('play');
						sessionStorage.setItem("live2dBGM_IsPlay", '0');
					}
				});
				window.onbeforeunload = function () {
					sessionStorage.setItem("live2dBGM_WindowClose", '0');
					if ($('#musicButton').hasClass('play')) {
						sessionStorage.setItem("live2dBGM_IsPlay", '0');
					}
				}
				document.getElementById('live2d_bgm').addEventListener("timeupdate", function () {
					var live2dBgmPlayTimeNow = document.getElementById('live2d_bgm').currentTime;
					sessionStorage.setItem("live2dBGM_PlayTime", live2dBgmPlayTimeNow);
				});
				document.getElementById('live2d_bgm').addEventListener("ended", function () {
					var listNow = parseInt($('#live2d_bgm').attr('data-bgm'));
					listNow++;
					if (listNow > $('input[name=live2dBGM]').length - 1) {
						listNow = 0;
					}
					var listNewSrc = $('input[name=live2dBGM]').eq(listNow).val();
					sessionStorage.setItem("live2dBGM_Num", listNow);
					$('#live2d_bgm').attr('src', listNewSrc);
					$('#live2d_bgm')[0].play();
					$('#live2d_bgm').attr('data-bgm', listNow);
				});
				document.getElementById('live2d_bgm').addEventListener("error", function () {
					$('#live2d_bgm')[0].pause();
					$('#musicButton').removeClass('play');
					showMessage('音乐似乎加载不出来了呢！', 0);
				});
			}
			//获取用户名
			var live2dUser = sessionStorage.getItem("live2duser");
			if (live2dUser !== null) {
				$('#AIuserName').val(live2dUser);
			}
			//获取位置
			var landL = sessionStorage.getItem("historywidth");
			var landB = sessionStorage.getItem("historyheight");
			if (landL == null || landB == null) {
				landL = '5px'
				landB = '0px'
			}
			$('#landlord').css('left', landL + 'px');
			$('#landlord').css('bottom', landB + 'px');
			//移动
			function getEvent() {
				return window.event || arguments.callee.caller.arguments[0];
			}
			var smcc = document.getElementById("landlord");
			var moveX = 0;
			var moveY = 0;
			var moveBottom = 0;
			var moveLeft = 0;
			var moveable = false;
			var docMouseMoveEvent = document.onmousemove;
			var docMouseUpEvent = document.onmouseup;
			smcc.onmousedown = function () {
				var ent = getEvent();
				moveable = true;
				moveX = ent.clientX;
				moveY = ent.clientY;
				var obj = smcc;
				moveBottom = parseInt(obj.style.bottom);
				moveLeft = parseInt(obj.style.left);
				if (isFirefox = navigator.userAgent.indexOf("Firefox") > 0) {
					window.getSelection().removeAllRanges();
				}
				document.onmousemove = function () {
					if (moveable) {
						var ent = getEvent();
						var x = moveLeft + ent.clientX - moveX;
						var y = moveBottom + (moveY - ent.clientY);
						obj.style.left = x + "px";
						obj.style.bottom = y + "px";
					}
				};
				document.onmouseup = function () {
					if (moveable) {
						var historywidth = obj.style.left;
						var historyheight = obj.style.bottom;
						historywidth = historywidth.replace('px', '');
						historyheight = historyheight.replace('px', '');
						sessionStorage.setItem("historywidth", historywidth);
						sessionStorage.setItem("historyheight", historyheight);
						document.onmousemove = docMouseMoveEvent;
						document.onmouseup = docMouseUpEvent;
						moveable = false;
						moveX = 0;
						moveY = 0;
						moveBottom = 0;
						moveLeft = 0;
					}
				};
			};
		}
		$(document).ready(function () {
			var AIimgSrc = [];
			let chooseLive2d = 'hijiki'
			if (chooseLive2d === 'histoire') {
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_00.png");
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_01.png");
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_02.png");
				AIimgSrc.push(message_Path + "model/histoire/histoire.1024/texture_03.png");
			} else if (chooseLive2d === 'rem') {
				AIimgSrc.push(message_Path + "model/rem/remu2048/texture_00.png");
			} else if (chooseLive2d === 'Aoba') {
				AIimgSrc.push(message_Path + "model/Aoba/textures/texture_00.png");
			} else if (chooseLive2d === 'hijiki') {
				AIimgSrc.push(message_Path + "model/hijiki/moc/hijiki.2048/texture_00.png");
			} else if (chooseLive2d === 'tororo') {
				AIimgSrc.push(message_Path + "model/tororo/moc/tororo.2048/texture_00.png");
			}
			var images = [];
			var imgLength = AIimgSrc.length;
			var loadingNum = 0;
			for (var i = 0; i < imgLength; i++) {
				images[i] = new Image();
				images[i].src = AIimgSrc[i];
				images[i].onload = function () {
					loadingNum++;
					if (loadingNum === imgLength) {
						var live2dhidden = localStorage.getItem("live2dhidden");
						if (live2dhidden === "0") {
							setTimeout(function () {
								$('#open_live2d').fadeIn(200);
							}, 1300);
						} else {
							setTimeout(function () {
								$('#landlord').fadeIn(200);
							}, 1300);
						}
						let model = '';
						if (chooseLive2d === 'histoire') {
							model = message_Path + "model/histoire/model.json";
						} else if (chooseLive2d === 'rem') {
							model = message_Path + "model/rem/model.json";
						} else if (chooseLive2d === 'Aoba') {
							model = message_Path + "model/Aoba/model.json";
						} else if (chooseLive2d === 'hijiki') {
							model = message_Path + "model/hijiki/hijiki.model.json";
						} else if (chooseLive2d === 'tororo') {
							model = message_Path + "model/tororo/tororo.model.json";
						}
						setTimeout(function () {
							loadlive2d("live2d", model);
						}, 1000);
						initLive2d();
						images = null;
					}
				}
			}
		});
	}
</script>
  
  
</div>
<script>

  let sideBarOpen = 'sidebar-open';
  let body = document.body;
  let back2Top = document.querySelector('#back_to_top'),
  back2TopText = document.querySelector('#back_to_top_text'),
  drawerBox = document.querySelector('#drawer_box'),
  rightSideBar = document.querySelector('.sidebar'),
  viewport = document.querySelector('body');

  function scrollAnimation(currentY, targetY) {
   
    let needScrollTop = targetY - currentY
    let _currentY = currentY
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10)
      _currentY += dist
      window.scrollTo(_currentY, currentY)
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY)
      } else {
        window.scrollTo(_currentY, targetY)
      }
    }, 1)
  }

  back2Top.addEventListener("click", function(e) {
    scrollAnimation(document.scrollingElement.scrollTop, 0);
    e.stopPropagation();
    return false;
  });
  
  window.addEventListener('scroll', function(e) {
    let percent = document.scrollingElement.scrollTop / (document.scrollingElement.scrollHeight - document.scrollingElement.clientHeight) * 100;
    if (percent > 1 && !back2Top.classList.contains('back-top-active')) {
      back2Top.classList.add('back-top-active');
    }
    if (percent == 0) {
      back2Top.classList.remove('back-top-active');
    }
    if (back2TopText) {
      back2TopText.textContent = Math.floor(percent);
    }
  });

  
  let hasCacu = false;
  window.onresize = function() {
    if (window.width > 991) {
      calcuHeight();
    } else {
      hasCacu = false;
    }
  }

  function calcuHeight() {
    // 动态调整站点概览高度
    if (!hasCacu && back2Top.classList.contains('pisces') || back2Top.classList.contains('gemini')) {
      let sideBar = document.querySelector('.sidebar');
      let navUl = document.querySelector('#site_nav');
      sideBar.style = 'margin-top:' + (navUl.offsetHeight + navUl.offsetTop + 15) + 'px;';
      hasCacu = true;
    }
  }
  calcuHeight();
  
  let open = false, MOTION_TIME = 300, RIGHT_MOVE_DIS = '320px';

  if (drawerBox) {
    let rightMotions = document.querySelectorAll('.right-motion');
    let right = drawerBox.classList.contains('right');

    let transitionDir = right ? "transition.slideRightIn" : "transition.slideLeftIn";

    let openProp, closeProp;
    if (right) {
      openProp = {
        paddingRight: RIGHT_MOVE_DIS 
      };
      closeProp = {
        paddingRight: '0px'
      };
    } else {
      openProp = {
        paddingLeft: RIGHT_MOVE_DIS 
      };
      closeProp = {
        paddingLeft: '0px'
      };
    }

    drawerBox.onclick = function() {
      open = !open;
      window.Velocity(rightSideBar, 'stop');
      window.Velocity(viewport, 'stop');
      window.Velocity(rightMotions, 'stop');
      if (open) {
        window.Velocity(rightSideBar, {
          width: RIGHT_MOVE_DIS
        }, {
          duration: MOTION_TIME,
          begin: function() {
            window.Velocity(rightMotions, transitionDir,{ });
          }
        })
        window.Velocity(viewport, openProp,{
          duration: MOTION_TIME
        });
      } else {
        window.Velocity(rightSideBar, {
          width: '0px'
        }, {
          duration: MOTION_TIME,
          begin: function() {
            window.Velocity(rightMotions, {
              opacity: 0
            });
          }
        })
        window.Velocity(viewport, closeProp ,{
          duration: MOTION_TIME
        });
      }
      for (let i = 0; i < drawerBox.children.length; i++) {
        drawerBox.children[i].classList.toggle('muse-line');
      }
      drawerBox.classList.toggle(sideBarOpen);
    }
  }

  // 链接跳转
  let newWindow = 'false'
  if (newWindow === 'true') {
    let links = document.querySelectorAll('.post-body a')
    links.forEach(item => {
      if (!item.classList.contains('btn')) {
        item.setAttribute("target","_blank");
      }
    })
  }
  // 代码高亮
  hljs.initHighlightingOnLoad();

</script>
  </div>
</body>
<input hidden id="copy" />
<script>
  //拿来主义(真香)^_^，Clipboard 实现摘自掘金 https://juejin.im/post/5aefeb6e6fb9a07aa43c20af
  window.Clipboard = (function (window, document, navigator) {
    var textArea,
      copy;

    // 判断是不是ios端
    function isOS() {
      return navigator.userAgent.match(/ipad|iphone/i);
    }
    //创建文本元素
    function createTextArea(text) {
      textArea = document.createElement('textArea');
      textArea.value = text;
      textArea.style.width = 0;
      textArea.style.height = 0;
      textArea.clientHeight = 0;
      textArea.clientWidth = 0;
      document.body.appendChild(textArea);
    }
    //选择内容
    function selectText() {
      var range,
        selection;

      if (isOS()) {
        range = document.createRange();
        range.selectNodeContents(textArea);
        selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
        textArea.setSelectionRange(0, 999999);
      } else {
        textArea.select();
      }
    }

    //复制到剪贴板
    function copyToClipboard() {
      try {
        document.execCommand("Copy")
      } catch (err) {
        alert("复制错误！请手动复制！")
      }
      document.body.removeChild(textArea);
    }

    copy = function (text) {
      createTextArea(text);
      selectText();
      copyToClipboard();
    };

    return {
      copy: copy
    };
  })(window, document, navigator);

  function copyCode(e) {
    if (e.srcElement.tagName === 'SPAN' && e.srcElement.classList.contains('copy-code')) {
      let code = e.currentTarget.querySelector('code');
      var text = code.innerText;
      if (e.srcElement.textContent === '复制成功') {
        console.log('复制操作频率过高');
        return;
      }
      e.srcElement.textContent = '复制成功';
      (function (elem) {
        setTimeout(() => {
          if (elem.textContent === '复制成功') {
            elem.textContent = '复制代码'
          }
        }, 1000);
      })(e.srcElement)
      Clipboard.copy(text);
    }
  }

  let pres = document.querySelectorAll('pre');
  pres.forEach(pre => {
    let code = pre.querySelector('code');
    let copyElem = document.createElement('span');
    copyElem.classList.add('copy-code');
    copyElem.textContent = '复制代码';
    pre.appendChild(copyElem);
    pre.onclick = copyCode
  })
</script>
<script src="/media/js/motion.js"></script>

<script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
<script>
  var scroll = new SmoothScroll('a[href*="#"]', {
    speed: 500
  });
</script>

<!-- <div class="search-mask" id="search_mask">
  <div class="search-box">
    <div class="search-title">
      <i class="fa fa-search"></i>
      <div class="input-box">
        <input type="text" placeholder="搜索">
      </div>
      <i class="fa fa-times-circle"></i>
    </div>
    <div class="result">
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/msf-zhong-shi-yong-mei-ju-mo-kuai-jin-xing-ge-chong-fu-wu-deng-lu-de-po-jie/"" data-c="
          &lt;h3 id=&#34;模块路径列表&#34;&gt;模块路径列表&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;auxiliary/scanner/ftp/ftp_login
auxiliary/scanner/ssh/ssh_login
auxiliary/scanner/telnet/telnet_login
auxiliary/scanner/smb/smb_login
auxiliary/scanner/mssql/mssql_login
auxiliary/scanner/mysql/mysql_login
auxiliary/scanner/oracle/oracle_login
auxiliary/scanner/postgres/postgres_login
auxiliary/scanner/vnc/vnc_login
auxiliary/scanner/pcanywhere/pcanywhere_login
auxiliary/scanner/snmp/snmp_login
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;使用方法&#34;&gt;使用方法&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# msfconsole

&amp;gt; use &amp;lt;模块路径&amp;gt;
&amp;gt; show options
&amp;gt; set &amp;lt;option&amp;gt; &amp;lt;value&amp;gt;
&amp;gt; run
&lt;/code&gt;&lt;/pre&gt;
">MSF中使用枚举模块进行各种服务登陆的破解</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/hydra-bao-li-po-jie-gong-ju-jian-dan-shi-yong-shuo-ming/"" data-c="
          &lt;h3 id=&#34;支持的破解协议&#34;&gt;支持的破解协议&lt;/h3&gt;
&lt;h4 id=&#34;afpcisco-aaacisco身份验证cisco启用cvsfirebirdftphttp-form-gethttp-form-posthttp-gethttp-headhttp-proxyhttps-form-gethttps-form-posthttps-gethttps-headhttp-proxyicqimapircldapms-sqlmysqlncpnntporacle-listeneroracle-sidoraclepc-anywhere-pcnfspop3postgresrdprexecrloginrshsap-r3sipsmbsmtpsmtp枚举snmpsocks5sshv1和v2subversionteamspeakts2telnetvmware-auth-vnc和xmpp&#34;&gt;AFP，Cisco AAA，Cisco身份验证，Cisco启用，CVS，Firebird，FTP，HTTP-FORM-GET，HTTP-FORM-POST，HTTP-GET，HTTP-HEAD，HTTP-PROXY，HTTPS-FORM- GET，HTTPS-FORM-POST，HTTPS-GET，HTTPS-HEAD，HTTP-Proxy，ICQ，IMAP，IRC，LDAP，MS-SQL，MYSQL，NCP，NNTP，Oracle Listener，Oracle SID，Oracle，PC-Anywhere， PCNFS，POP3，POSTGRES，RDP，Rexec，Rlogin，Rsh，SAP / R3，SIP，SMB，SMTP，SMTP枚举，SNMP，SOCKS5，SSH（v1和v2），Subversion，Teamspeak（TS2），Telnet，VMware-Auth ，VNC和XMPP。&lt;/h4&gt;
&lt;h3 id=&#34;参数列表&#34;&gt;参数列表&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;-R：继续从上一次进度接着破解
-S：大写，采用SSL链接
-s  &amp;lt;PORT&amp;gt;：小写，可通过这个参数指定非默认端口
-l  &amp;lt;LOGIN&amp;gt;：指定破解的用户，对特定用户破解
-L  &amp;lt;FILE&amp;gt;：指定用户名字典
-p  &amp;lt;PASS&amp;gt;：小写，指定密码破解，少用，一般是采用密码字典
-P  &amp;lt;FILE&amp;gt;：大写，指定密码字典
-e  &amp;lt;ns&amp;gt;：可选选项，n：空密码试探，s：使用指定用户和密码试探
-C  &amp;lt;FILE&amp;gt;：使用冒号分割格式，例如“登录名:密码”来代替 -L/-P 参数
-M  &amp;lt;FILE&amp;gt;：指定目标列表文件一行一条
-o  &amp;lt;FILE&amp;gt;：指定结果输出文件
-f ：在使用-M参数以后，找到第一对登录名或者密码的时候中止破解
-t &amp;lt;TASKS&amp;gt;：同时运行的线程数，默认为16
-w &amp;lt;TIME&amp;gt;：设置最大超时的时间，单位秒，默认是30s
-v / -V：显示详细过程
server：目标ip
service：指定服务名，支持的服务和协议：telnet ftp pop3[-ntlm] imap[-ntlm] smb smbnt http[s]-{head|get} http-{get|post}-form http-proxy cisco cisco-enable vnc ldap2 ldap3 mssql mysql oracle-listener postgres nntp socks5 rexec rlogin pcnfs snmp rsh cvs svn icq sapr3 ssh2 smtp-auth[-ntlm] pcanywhere teamspeak sip vmauthd firebird ncp afp等等
OPT：可选项
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;使用场景&#34;&gt;使用场景&lt;/h3&gt;
&lt;h3 id=&#34;破解ssh&#34;&gt;破解SSH&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# hydra -L users.txt -P password.txt -t 1 -vV -e ns 192.168.1.104 ssh
# hydra -L users.txt -P password.txt -t 1 -vV -e ns -o save.log 192.168.1.104 ssh
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;破解ftp&#34;&gt;破解FTP&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# hydra ip ftp -l 用户名 -P 密码字典 -t 线程(默认16) -vV
# hydra ip ftp -l 用户名 -P 密码字典 -e ns -vV
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;破解http&#34;&gt;破解HTTP&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;// get 方式提交，破解web登陆
# hydra -l 用户名 -p 密码字典 -t 线程 -vV -e ns ip http-get /admin/
# hydra -l 用户名 -p 密码字典 -t 线程 -vV -e ns -f ip http-get /admin/index.php

// post 方式提交(这里有两种，根据实际情况来构成命令)
// 需要提前采集认证通信时的数据包，以便确定参数名称
# hydra -l admin -P pass.lst -o ok.lst -t 1 -f 127.0.0.1 http-post-form &amp;quot;index.php:name=^USER^&amp;amp;pwd=^PASS^:&amp;lt;title&amp;gt;invalido&amp;lt;/title&amp;gt;&amp;quot;
# hydra -L user.txt \
			-P passwd.txt \
			-o http_get.txt \
			-vV 10.96.10.208 \
			http-get-form  &amp;quot;/vulnerabilities/brute/:username=^USER^&amp;amp;password=^PASS^&amp;amp;Login=Login:F=Username and/or password incorrect:H=Cookie: PHPSESSID=nvvrgk2f84qhnh43cm28pt42n6; security=low&amp;quot; \
			-t 3
USER^和^
PASS^代表是攻击载荷，
F=后面是代表密码错误时的关键字符串 ，
H后面是cookie信息
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;破解https&#34;&gt;破解HTTPS&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# hydra -m /index.php -l muts -P pass.txt 10.36.16.18 https
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;破解http-proxy&#34;&gt;破解http-proxy&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# hydra -l admin -P pass.txt http-proxy://10.36.16.18
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;破解smb&#34;&gt;破解SMB&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# hydra -l administrator -P pass.txt 10.36.16.18 smb
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;破解3389远程登陆&#34;&gt;破解3389远程登陆&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# hydra ip rdp -l administrator -P pass.txt -V
&lt;/code&gt;&lt;/pre&gt;
">Hydra暴力破解工具简单使用说明</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/sublist3r-zi-yu-ming-sao-miao-gong-ju-shi-yong-shuo-ming/"" data-c="
          &lt;h3 id=&#34;安装方式&#34;&gt;安装方式&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;// 源码使用
# git clone https://github.com/aboul3la/Sublist3r.git
# cd Sublist3r
# pip install -r requirements.txt

// Kali Linux安装
# apt update
# apt install sublist3r
# sublist3r --help
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;工具帮助信息&#34;&gt;工具帮助信息&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;usage: sublist3r.py [-h] -d DOMAIN [-b [BRUTEFORCE]] [-p PORTS] [-v [VERBOSE]] [-t THREADS] [-e ENGINES] [-o OUTPUT] [-n]

OPTIONS:
  -h, --help            show this help message and exit
  -d DOMAIN, --domain DOMAIN
                        Domain name to enumerate it&#39;s subdomains
  -b [BRUTEFORCE], --bruteforce [BRUTEFORCE]
                        Enable the subbrute bruteforce module
  -p PORTS, --ports PORTS
                        Scan the found subdomains against specified tcp ports
  -v [VERBOSE], --verbose [VERBOSE]
                        Enable Verbosity and display results in realtime
  -t THREADS, --threads THREADS
                        Number of threads to use for subbrute bruteforce
  -e ENGINES, --engines ENGINES
                        Specify a comma-separated list of search engines
  -o OUTPUT, --output OUTPUT
                        Save the results to text file
  -n, --no-color        Output without color

Example: python3 /usr/lib/python3/dist-packages/sublist3r.py -d google.com
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;使用场景&#34;&gt;使用场景&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;// 扫描子域名
# sublist3r -d qq.com

// 扫描子域名，并显示开放了80和443端口的子域名
# sublist3r -d qq.com -p 80, 443

// 输出到文件
# sublist3r -d qq.com -o filename.txt

&lt;/code&gt;&lt;/pre&gt;
">Sublist3r子域名扫描工具使用说明</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/subdomainbrutepy-gong-ju-de-jian-dan-shi-yong-shuo-ming/"" data-c="
          &lt;h3 id=&#34;安装方法&#34;&gt;安装方法&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# git clone https://github.com/lijiejie/subDomainsBrute.git

// python3 用户
# pip3 install aiodns
// python2 用户
# pip install dnspython gevent

// 字典路径
# cd subDomainsBrute/dict
# ls
dns_servers.txt  next_sub_full.txt  next_sub.txt  subnames_all_5_letters.txt  subnames_full.txt  subnames.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;工具帮助说明&#34;&gt;工具帮助说明&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;Usage: subDomainsBrute.py [options] target.com

Options:
  --version             show program&#39;s version number and exit
  -h, --help            show this help message and exit
  -f FILE               File contains new line delimited subs, default is
                        subnames.txt.
  --full                Full scan, NAMES FILE subnames_full.txt will be used
                        to brute
  -i, --ignore-intranet
                        Ignore domains pointed to private IPs
  -w, --wildcard        Force scan after wildcard test fail
  -t THREADS, --threads=THREADS
                        Num of scan threads, 200 by default
  -p PROCESS, --process=PROCESS
                        Num of scan Process, 6 by default
  -o OUTPUT, --output=OUTPUT
                        Output file name. default is {target}.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;使用场景&#34;&gt;使用场景&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;// 简单扫描
# python3 subDomainsBrute.py qq.com

// 全量扫描,full参数会使用字典路径下的subnames_full.txt
# python3 subDoaminBrute.py --full qq.com
&lt;/code&gt;&lt;/pre&gt;
">SubDomainBrute.py工具的简单使用说明</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/centos-78-shi-yong-chrony-jin-xing-shi-jian-tong-bu-pei-zhi/"" data-c="
          &lt;h3 id=&#34;1-安装&#34;&gt;1. 安装&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# yum -y install chrony
# systemctl enable chronyd
# systemctl start chronyd
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2配置&#34;&gt;2.配置&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# vi /etc/chrony.conf

# 使用 pool.ntp.org 项目中的公共服务器。以server开，理论上想添加多少时间服务器都可以。
# Use public servers from the pool.ntp.org project.
# Please consider joining the pool (http://www.pool.ntp.org/join.html).
server 0.centos.pool.ntp.org iburst
server 1.centos.pool.ntp.org iburst
server 2.centos.pool.ntp.org iburst
server 3.centos.pool.ntp.org iburst

# 根据实际时间计算出服务器增减时间的比率，然后记录到一个文件中，在系统重启后为系统做出最佳时间补偿调整。
# Record the rate at which the system clock gains/losses time.
driftfile /var/lib/chrony/drift

# 如果系统时钟的偏移量大于1秒，则允许系统时钟在前三次更新中步进。
# Allow the system clock to be stepped in the first three updates if its offset is larger than 1 second.
makestep 1.0 3

# 启用实时时钟（RTC）的内核同步。
# Enable kernel synchronization of the real-time clock (RTC).
rtcsync

# 通过使用 hwtimestamp 指令启用硬件时间戳
# Enable hardware timestamping on all interfaces that support it.
#hwtimestamp *

# Increase the minimum number of selectable sources required to adjust the system clock.
#minsources 2

# 指定 NTP 客户端地址，以允许或拒绝连接到扮演时钟服务器的机器
# Allow NTP client access from local network.
#allow 192.168.0.0/16

# Serve time even if not synchronized to a time source.
#local stratum 10

# 指定包含 NTP 身份验证密钥的文件。
# Specify file containing keys for NTP authentication.
#keyfile /etc/chrony.keys

# 指定日志文件的目录。
# Specify directory for log files.
logdir /var/log/chrony

# 选择日志文件要记录的信息。
# Select which information is logged.
#log measurements statistics tracking
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3手工同步&#34;&gt;3.手工同步&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 查看 ntp_servers
chronyc sources -v

# 查看 ntp_servers 状态
chronyc sourcestats -v

# 查看 ntp_servers 是否在线
chronyc activity -v

# 查看 ntp 详细信息
chronyc tracking -v

# 手工进行同步
chronyc -a makestep
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4修改时区&#34;&gt;4.修改时区&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 查看日期时间、时区及 NTP 状态
timedatectl

# 查看时区列表
timedatectl list-timezones
timedatectl list-timezones |  grep  -E &amp;quot;Asia/S.*&amp;quot;

# 修改时区
timedatectl set-timezone Asia/Shanghai

# 修改日期时间（可以只修改其中一个）
timedatectl set-time &amp;quot;2019-09-19 15:50:20&amp;quot;

# 开启 NTP
timedatectl set-ntp true/flase
&lt;/code&gt;&lt;/pre&gt;
">Centos 7/8 使用chrony进行时间同步配置</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/ru-he-bi-mian-zai-di-yi-ci-ssh-deng-lu-shi-shu-ru-yes-ti-shi-fu/"" data-c="
          &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;echo &amp;quot;StrictHostKeyChecking no&amp;quot; &amp;gt;~/.ssh/config
&lt;/code&gt;&lt;/pre&gt;
">如何避免在第一次SSH登陆时输入yes提示符</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/k8s-pod-jian-dan-jie-shao/"" data-c="
          &lt;h3 id=&#34;概念&#34;&gt;概念&lt;/h3&gt;
&lt;h5 id=&#34;在kubernetes集群中pod是所有业务类型的基础也是k8s管理的最小单位级它是一个或多个容器的组合-这些容器共享存储-网络和命名空间以及如何运行的规范-在pod中所有容器都被同一安排和调度并运行在共享的上下文中-对于具体应用而言pod是它们的逻辑主机pod包含业务相关的多个应用容器&#34;&gt;在Kubernetes集群中，Pod是所有业务类型的基础，也是K8S管理的最小单位级，它是一个或多个容器的组合。这些容器共享存储、网络和命名空间，以及如何运行的规范。在Pod中，所有容器都被同一安排和调度，并运行在共享的上下文中。对于具体应用而言，Pod是它们的逻辑主机，Pod包含业务相关的多个应用容器。&lt;/h5&gt;
&lt;h3 id=&#34;两个注意点&#34;&gt;两个注意点&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;1.网络:
  每一个Pod都会被指派一个唯一的Ip地址，在Pod中的每一个容器共享网络命名空间，包括Ip地址和网络端口。在同一个Pod中的容器可以同locahost进行互相通信。当Pod中的容器需要与Pod外的实体进行通信时，则需要通过端口等共享的网络资源。

2.存储:
  Pod能够被指定共享存储卷的集合，在Pod中所有的容器能够访问共享存储卷，允许这些容器共享数据。存储卷也允许在一个Pod持久化数据，以防止其中的容器需要被重启。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;pod的生命周期&#34;&gt;Pod的生命周期&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shel&#34;&gt;一共有4种状态：

1. Pending：APIserver已经创建该server，但pod中有一个或多个容器的镜像还未创建，可能在下载中；
2. Running：Pod中的所有容器都已创建，且至少有一个容器处于运行状态，正在启动或重启状态；
3. Failed：Pod内所有容器都已退出，其中至少有一个容器退出失败；
4. Unknown：由于某种原因无法获取Pod的状态比如网络问题；
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;pod的重启策略&#34;&gt;Pod的重启策略&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;重启策略对同一个Pod中的所有容器起作用，容器的重启由Node上的kubelet执行，支持三种策略，在配置文件中通过restartPolicy字段设置：
1. Always：只要退出就会重启
2. OnFailure：只有在失败退出时，才会重启
3. Never：只要退出，就不再重启

注意，这里的重启是指在Pod的宿主Node上进行本地重启，而不是调度到其它Node上。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;健康检查&#34;&gt;健康检查&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 两种探针类型：
一、LivenessProbe探针：  判断容器是否存活（running）
1.ExecAction，在容器内部执行一个命令，状态返回码为0，表示健康，示例：
apiVersion: v1
kind: Pod
metadata:
 name: liveness
spec:
  containers:
  - name: liveness
    image: liveness
    args: 
    - /bin/sh
    - -c
    - echo ok &amp;gt; /tmp/healthy: sleep 10; rm - rf /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/health
    initialDelaySeconds: 15
    timeoutSeconds: 1
    
2.TcpAction，通过IP和PORT，如果能够和容器建立连接则表示容器健康，示例：
apiVersion: v1
kind: Pod
metadata:
 name: pod-with-healthcheck
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
    livenessProbe:
      tcpSocket:
        port: 80
    initialDelaySeconds: 15
    timeoutSeconds: 1
3.HttpGetAction，发送get请求，返回码在200-400之间表示健康， 示例：
apiVersion: v1
kind: Pod
metadata:
 name: pod-with-healthcheck
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
    livenessProbe:
      httpGet:
        path: /_status/healthz  //请求路径
        port: 80
    initialDelaySeconds: 15
    timeoutSeconds: 1
    
二、ReadinessProbe探针： 用于判断容器是否启动完成（ready）
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;pod的调度&#34;&gt;Pod的调度&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 定向调度，nodeSelector
1.首先通过kubectl给node打上标签：
格式： kubectl label nodes &amp;lt;node-name&amp;gt; &amp;lt;label-key&amp;gt;=&amp;lt;label-value&amp;gt;
kubectl label nodes node1 zone=north

2.在pod定义里选择某个node
apiVersion: v1
kind: Pod
metadata:
name: pod-with-healthcheck
spec:
containers:
- name: nginx
  image: nginx
  ports:
  - containerPort: 80
nodeSelector:
  zone: north

# 亲和性和非亲和性
一、Node affinity（节点亲和性）
1. requiredDuringSchedulingIgnoredDuringExecution：
可认为一种强制限制，如果 Node 的标签发生了变化导致其没有符合 Pod 的调度要求节点，那么pod调度就会失败。
2.preferredDuringSchedulingIgnoredDuringExecution：
软限或偏好，同样如果 Node 的标签发生了变化导致其不再符合 pod 的调度要求，pod 依然会调度运行。

二、Pod Affinity（Pod亲和性）
    podAffinity用于调度pod可以和哪些pod部署在同一拓扑结构之下。而podAntiAffinity相反，其用于规定pod不可以和哪些pod部署在同一拓扑结构下。通过pod affinity与anti-affinity来解决pod和pod之间的关系。
&lt;/code&gt;&lt;/pre&gt;
">K8s-Pod简单介绍</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/namespace-ji-ben-zhi-shi/"" data-c="
          &lt;h3 id=&#34;名词解释&#34;&gt;名词解释&lt;/h3&gt;
&lt;h5 id=&#34;namespace是对一组资源和对象的抽象集合比如可用来将系统内部的对象划分为不同的项目或用户组-常见的podsservicesrc和deployments等都是属于某一个namespace的默认是default而nodepersistentvolumns等则不属于任何namespace&#34;&gt;Namespace是对一组资源和对象的抽象集合，比如可用来将系统内部的对象划分为不同的项目或用户组。常见的pods，services，rc和deployments等都是属于某一个namespace的（默认是default），而node，persistentVolumns等则不属于任何namespace。&lt;/h5&gt;
&lt;h3 id=&#34;namespace相关操作&#34;&gt;Namespace相关操作&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;kubectl可以通过–namespace或者-n选项指定namespace。如果不指定，默认为default。查看操作下,也可以通过设置–all-namespace=true来查看所有namespace下的资源。

# 查询ns
$ kubectl get namespaces
NAME          STATUS    AGE
default       Active    11d
kube-system   Active    11d

# 查询哪些资源位于namespace中
kubectl api-resources --namespaced=true
# 查看哪些资源不在命令空间
kubectl api-resources --namespaced=false

# 指定ns查询对应ns中的资源情况
kubectl get pods -n kube-system

# 创建
# 1.命令行直接创建
$ kubectl create namespace new-namespace

# 2.通过文件创建
$ cat my-namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: new-namespace

$ kubectl create -f ./my-namespace.yaml

# 删除，即删除该ns下所有资源
# 注意：default和kube-system命名空间不能删除
$ kubectl delete namespaces new-namespace

# 切换ns
kubectl config set-context --current --namespace=kube-system
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;关于namespace是否隔离网络&#34;&gt;关于Namespace是否隔离网络&lt;/h3&gt;
&lt;h5 id=&#34;一般情况下默认是不会隔离网络流量的除非对某个namespace设置了安全策略&#34;&gt;一般情况下，默认是不会隔离网络流量的，除非对某个namespace设置了安全策略。&lt;/h5&gt;
">K8s-Namespace基本知识</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/shi-yong-minikube-da-jian-ben-di-xue-xi-huan-jing/"" data-c="
          &lt;h3 id=&#34;安装kubectl&#34;&gt;安装kubectl&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 注意：安装方法推荐参考官方网站，安装方式随着版本变更会发生变动
# 下载二进制文件
curl -LO &amp;quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&amp;quot;
# 下载校验文件
curl -LO &amp;quot;https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256&amp;quot;
# 检查下载文件和校验文件是否匹配
echo &amp;quot;$(&amp;lt;kubectl.sha256) kubectl&amp;quot; | sha256sum --check
# 安装二进制文件
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
# 检查安装是否成功
kubectl version --client
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;安装minikube&#34;&gt;安装Minikube&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 下载二进制文件
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
# 安装二进制文件
sudo install minikube-linux-amd64 /usr/local/bin/minikube
# 启动集群，启动之前需要确保系统中有容器运行时，比如docker，kvm，否则集群启动失败
minikube start

# 若出现：The &amp;quot;docker&amp;quot; driver should not be used with root privileges.
# 将当前具有sudo权限的用户添加到docker组即可
sudo usermod -aG docker &amp;lt;username&amp;gt;
# 激活组的配置，这步必须
newgrp docker
# 再次启动
minikube start
# 查看集群信息
kubectl cluster-info

&lt;/code&gt;&lt;/pre&gt;
">K8s-使用Minikube搭建本地学习环境</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/playbook-zhong-shi-yong-copy-lai-chuan-shu-wen-jian/"" data-c="
          &lt;h3 id=&#34;基本配置示例&#34;&gt;基本配置示例&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;- hosts: all
    vars: 
      wss_url: http://10.77.10.125:8545 
    tasks:
      - name: &amp;quot;推送配置文件&amp;quot;
        template: src=/home/fm/ops/scripts/default.yaml dest=/etc/bee/default.yaml
      - name: &amp;quot;send all scripts&amp;quot;
        copy:
          src: &#39;{{ item.src }}&#39;
          dest: /tmp/
          owner: root
          group: root
          mode: 755
        with_items:
          - { src: &#39;/home/fm/ops/scripts/start05.sh&#39; }
          - { src: &#39;/home/fm/ops/scripts/stop.sh&#39; }
  
 
# 使用{{ item.src }}读取with_items中的数组元素，访问需要拷贝的每一个文件即可。

# 检查语法
ansible-playbook --syntax-check example.yaml
&lt;/code&gt;&lt;/pre&gt;
">Ansible-Playbook中使用copy来传输文件</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/playbook-zhong-yong-hu-de-qie-huan-wen-ti/"" data-c="
          &lt;h3 id=&#34;become配置示例&#34;&gt;become配置示例：&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;- hosts: www.360.com
  remote_user: zabbix
  become: yes
  become_method: su
  tasks:
   - selinux:
        state: disabled
   - name: disable firewalld
     shell: systemctl stop firewalld &amp;amp;&amp;amp; systemctl disable firewalld
 
# become说明
become:        yes  # 是否允许身份切换
become_method: su   # 切换用户身份的方式，有sudo、su、pbrun等方式，默认为sudo
become_user: root   # 切换指定的用户，默认不写，就是root
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;sudo配置解释&#34;&gt;sudo配置解释&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;hosts                # 指定主机分组，可以取并集，交集等
remote_user          # 用于指定远程主机上的执行任务的用户，最佳实践是该用户具有sudo权限
user                 # 和remote_user相同
sudo                 # 如果设置为yes，执行该任务组的用户在执行任务的时候，获取root权限，也可以命令行使用-b参数
sudo_user            # 如果设置user为A，sudo为yes，sudo_user为B时，则A用户在执行任务时会获得B用户的权限，比较麻烦，不推荐
&lt;/code&gt;&lt;/pre&gt;
">Ansible-Playbook中用户的切换问题</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/playbook-li-yong-tags-zhi-xing-bu-fen-task/"" data-c="
          &lt;h3 id=&#34;基本使用方法示例配置&#34;&gt;基本使用方法，示例配置：&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;tasks:
  - yum: name={{ item }} state=installed
    with_items:
       - httpd
    tags:
       - packages
  - name: copy httpd.conf
    template: src=templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf
    tags:
       - configuration
  - name: copy index.html
    template: src=templates/index.html.j2 dest=/var/www/html/index.html
    tags:
       - configuration
  
 
# 执行部分任务
ansible-playbook example.yml --tags &amp;quot;packages&amp;quot;

# 指定不执行packages部分的任务
ansible-playbook example.yml --skip-tags &amp;quot;configuration&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;特殊的tags&#34;&gt;特殊的tags&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# always 标签，即使指定执行了某tag的任务，标记为always的任务也会被执行
tasks:
  - debug: msg=&amp;quot;Always print this debug message&amp;quot;
    tags:
      - always
  - yum: name={{ item }} state=installed
    with_items:
       - httpd
    tags:
       - packages
  - template: src=templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf
    tags:
       - configuration

# 这里标记为always的任务也会被执行
ansible-playbook tags_always.yml --tags &amp;quot;packages&amp;quot;

# targged，untagged，all，使用这些标签时，不需要加双引号
tagged，即执行所有被打标签的任务
untagged，即执行所有未被打标签的任务
all，所有任务
&lt;/code&gt;&lt;/pre&gt;
">Ansible-Playbook利用tags执行部分task</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/shi-yong-prometheus-jian-kong-zhu-ji-docker-rong-qi-yun-xing-zhuang-tai/"" data-c="
          &lt;h3 id=&#34;部署方式容器化部署&#34;&gt;部署方式：容器化部署&lt;/h3&gt;
&lt;h4 id=&#34;部署流程&#34;&gt;部署流程：&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 运行node-exporter监控主机基本信息，访问9100端口进行验证
docker run -d --name node \
	-p 9100:9100 \
	-v /proc:/host/proc \
	-v /sys:/host/sys \
	-v /:/rootfs \
	--net=host prom/node-exporter \
	--path.procfs /host/proc \
	--path.sysfs /host/sys \
	--collector.filesystem.ignored-mount-points &amp;quot;^/(sys|proc|dev|host|etc)($|/)&amp;quot;

# 运行cAdvisor监控容器运行状态，访问8080端口进行验证
docker run -v /:/rootfs:ro \
	-v /var/run:/var/run/:rw \
	-v /sys:/sys:ro \
	-v /var/lib/docker:/var/lib/docker:ro \
	-p 8080:8080 \
	--detach=true \
	--name=cadvisor \
	--net=host google/cadvisor

# 在监控主节点上部署prometheus server，客户节点无需安装
docker run -d -p 9090:9090 --name prometheus --net=host prom/prometheus
# 将容器中的配置文件拷贝到宿主，进行修改
docker cp prometheus:/etc/prometheus/prometheus.yml ./
# 修改static_configs，指向所有客户节点的9100和8080端口获取数据
vim prometheus.yml

# 配置更新完成后，删除原prometheus server容器
docker rm prometheus -f
# 重新将本地配置文件映射到容器中，访问9090端口进行验证
docker run -d -p 9090:9090 --name prometheus --net=host -v /root/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus

# 部署grafana图形化界面，访问3000端口进行验证
mkdir grafana-storage
chmod 777 -R grafana-storage/
docker run -d -p 3000:3000 \
	--name grafana \
	-v /root/grafana-storage:/var/lib/grafana \
	-e &amp;quot;GF_SECURITY_ADMIN_PASSWORD=123456&amp;quot; grafana/grafana
	
# grafana模板，打开grafana.com, 点击dashborads，根据数据源和类型选择合适的模板

&lt;/code&gt;&lt;/pre&gt;
">Prometheus-使用prometheus监控主机docker容器运行状态</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/ru-he-chai-chu-linux-ruan-raid-she-bei/"" data-c="
          &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1. 卸载设备
# umount /dev/md0

2. 停止raid设备
# mdadm -S /dev/md0  // 停止raid设备

3. 查看属于raid组的设备名称
# blkid 

4. 从raid组中删除硬盘
# mdadm --misc --zero-superblock /dev/xxx

以下操作可选：
5. 删除配置文件：rm -f /etc/mdadm.conf

6. 更新/etc/fstab
&lt;/code&gt;&lt;/pre&gt;
">如何拆除Linux软Raid设备</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/nmap-gong-ju-chang-yong-shi-yong-chang-jing/"" data-c="
          &lt;h3 id=&#34;主机发现&#34;&gt;主机发现&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;以192.168.1.0/24举例

nmap -PE 192.168.1.0/24  # icmp
namp -PO 192.168.1.0/24  # ip
nmap -PS 192.168.1.0/24  # tcp syn
nmap -PA 192.168.1.0/24  # tcp ack
nmap -PU 192.168.1.0/24  # udp
nmap -PY 192.168.1.0/24  # sctp
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;端口扫描&#34;&gt;端口扫描&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1.SYN Scanning
nmap -sS 192.168.1.0/24  # 仅发送SYN，返回SYN/ACK应答表示端口开启，返回RST表示端口关闭

2.TCP Scanning
nmap -sT 192.168.1.0/24  # 建立完整的TCP连接，表示端口开启，否则表示关闭

3.UDP Scanning
nmap -sU 192.168.1.0/24  # UDP，无应答，表示端口开启；返回&amp;quot;Port Unreachable&amp;quot;信息，表示关闭

4.FIN Scanning
nmap -sF 192.168.1.0/24  # 在TCP数据包中重置FIN标志位，无应答，表示开启；返回RST，表示端口关闭

5.NULL Scanning
nmap -sN 192.168.1.0/24  # 在TCP数据包中不包含任何标志位，无应答，表示开启；返回RST，表示端口关闭

6.Xmas Scanning
nmap -sX 192.168.1.0/24  # 在TCP数据包中重置FIN、RST、PUSH标志位，无应答，表示开启；返回RST，表示端口关闭

7.IDLE Scanning
nmap -sI 172.16.1.1 192.168.1.0/24  
# 利用僵尸主机进行扫描，假设僵尸IP为172.16.1.1，当僵尸机返回序列ID增加数量为2时，表示开启，为1时关闭

8.指定端口扫描
nmap -p 80,443 192.168.1.0/24  # 可以指定多个端口

9.扫描常见的100个端口
nmap -F 192.168.1.0/24  # 快速模式

10.使用协议名进行扫描
nmap -p http 192.168.1.0/24
nmap -p smtp 192.168.1.0/24

11.扫描常用端口
nmap --top-ports &amp;lt;端口数量&amp;gt; 192.168.1.0/24

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;操作系统指纹识别&#34;&gt;操作系统指纹识别&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;nmap -O 192.168.1.0/24   # os
nmap -sV 192.168.1.0/24  # service version
nmap -A 192.168.1.0/24   # all
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;使用脚本&#34;&gt;使用脚本&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;nmap --script &amp;lt;脚本名称&amp;gt; 192.168.1.0/24
&lt;/code&gt;&lt;/pre&gt;
">Nmap工具常用使用场景</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/xfs-wen-jian-xi-tong-xiu-fu-liu-cheng/"" data-c="
          &lt;h3 id=&#34;详细流程如下&#34;&gt;详细流程如下：&lt;/h3&gt;
&lt;p&gt;1.使用 xfs_repair -n 执行文件系统错误检测，和 fsck -n 类似；&lt;br&gt;
2.使用 xfs_repair 尝试进行修复；&lt;br&gt;
3.当遇见无法正常挂载文件系统时，需要使用强制模式 -L 模式进行修复，会丢失部分数据，可以先对metadata进行模拟修复测试：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;xfs_metadump [partition] /path/to/file.metadump                                  # 对需要修复的分区进行dump&lt;/li&gt;
&lt;li&gt;xfs_mdrestore /path/to/file.metadump /path/to/file.img                         # 生成img文件&lt;/li&gt;
&lt;li&gt;losetup --show --find /path/to/file.img                                                    # 使用lostup工具将数据放到/dev/loop0&lt;/li&gt;
&lt;li&gt;xfs_repair -L /dev/loop0                                                                        # 尝试模拟修复&lt;/li&gt;
&lt;li&gt;mount /dev/loop0 /mnt&lt;/li&gt;
&lt;li&gt;check the damage&lt;/li&gt;
&lt;li&gt;(note, this is an image of file system layout, but not the actual data)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;4.拷贝真实数据，并对拷贝的数据进行修复：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ddrescue -f -n [partition] /path/to/rescued.img rescue.log                      # 这需要一个比原分区大小更大的磁盘&lt;/li&gt;
&lt;li&gt;ddrescue -d -f -r3 [partition] /path/to/rescued.img rescue.log&lt;/li&gt;
&lt;li&gt;losetup --show --find /path/to/rescued.img&lt;/li&gt;
&lt;li&gt;xfs_repair -L /dev/loop0&lt;/li&gt;
&lt;li&gt;mount /dev/loop0 /mnt&lt;/li&gt;
&lt;li&gt;check the damage&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;5.如果真实环境缺少这样的备份分区，那么直接使用xfs_repair -L模式进行强制修复。&lt;/p&gt;
">XFS文件系统修复流程</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/ipmitool-gong-ju-de-shi-yong-shuo-ming/"" data-c="
          &lt;h3 id=&#34;安装工具&#34;&gt;安装工具&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install -y ipmitool 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;启动服务&#34;&gt;启动服务&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;service ipmi start
ipmitool -I open shell     # 进入交互式shell
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;一-开关机重启&#34;&gt;一、开关机，重启&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1. 查看开关机状态：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power status

2. 开机：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power on

3. 关机：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power off

4. 重启：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power reset
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;二-用户管理&#34;&gt;二、用户管理&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 说明：[ChannelNo] 字段是可选的，ChannoNo为1或者8；BMC默认有2个用户：user id为1的匿名用户，user id为2的ADMIN用户；&amp;lt;&amp;gt;字段为必选内容；&amp;lt;privilege level&amp;gt;：2为user权限，3为Operator权限，4为Administrator权限；

1. 查看用户信息：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user list [ChannelNo]

2. 增加用户：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user set name &amp;lt;user id&amp;gt; &amp;lt;username&amp;gt;

3. 设置密码：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user set password &amp;lt;user id&amp;gt; &amp;lt;password&amp;gt;

4. 设置用户权限：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user priv &amp;lt;user id&amp;gt; &amp;lt;privilege level&amp;gt; [ChannelNo]

5. 启用/禁用用户：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user enable/disable &amp;lt;user id&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;三-ip网络设置&#34;&gt;三、IP网络设置&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 说明：[ChannelNo] 字段是可选的，ChannoNo为1(Share Nic网络)或者8（BMC独立管理网络）；设置网络参数，必须首先设置IP为静态，然后再进行其他设置；

1. 查看网络信息：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan print [ChannelNo]

2. 修改IP为静态还是DHCP模式：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set &amp;lt;ChannelNo&amp;gt; ipsrc &amp;lt;static/dhcp&amp;gt;

3. 修改IP地址：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set &amp;lt;ChannelNo&amp;gt; ipaddr &amp;lt;IPAddress&amp;gt;

4. 修改子网掩码：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set &amp;lt;ChannelNo&amp;gt; netmask &amp;lt;NetMask&amp;gt;

5. 修改默认网关：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set &amp;lt;ChannelNo&amp;gt; defgw ipaddr &amp;lt;默认网关&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;四-sol功能&#34;&gt;四、SOL功能&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 说明：&amp;lt;9.6/19.2/38.4/57.6/115.2&amp;gt;其中115.2代表115200，即*1000是表示的波特率;

1. 设置SOL串口波特率：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sol set volatile-bit-rate &amp;lt;9.6/19.2/38.4/57.6/115.2&amp;gt;

2. 打开SOL功能：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sol activate

3. 关闭SOL功能：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sol deactivate
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;五-sel日志查看&#34;&gt;五、SEL日志查看&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1. 查看SEL日志：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sel list
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;六-fru信息查看&#34;&gt;六、FRU信息查看&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1. 查看FRU信息：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) fru list
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;七-sdrsensor信息查看&#34;&gt;七、SDR，Sensor信息查看&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1. 查看SDR Sensor信息：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sdr

2. 查看Sensor信息：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sensor list
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;八-mc管理单元bmc状态和控制&#34;&gt;八、mc(管理单元BMC)状态和控制&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1. 重启动BMC：
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) mc reset &amp;lt;warm/cold&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;九-设置bmc的iptables防火墙&#34;&gt;九、设置BMC的iptables防火墙&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1. 设置某一段IP可以访问BMC
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x01 0x01 ip1(0xa 0xa 0xa 0xa) ip2(0xb 0xb 0xb 0xb)
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x09

2. 设置某个IP可以访问BMC
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x00 0x01 ip1(0xa 0xa 0xa 0xa)
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x09

3. 取消设置
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x08

4．获取防火墙设置
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x77 0x01 0x00

5. 阻止/开启某个端口
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x02 0x00/0x01 0x00 (portno)0x22 0x00

6. 取消某个端口的设置（6是5的对应取消操作）
ipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x06 0x00/0x01 0x00 (portno)0x22 0x00
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;参考文献&#34;&gt;参考文献&lt;/h3&gt;
&lt;p&gt;https://www.cnblogs.com/EricDing/p/8995263.html&lt;/p&gt;
">ipmitool工具的使用说明</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/nvidia-xian-qia-chang-yong-ming-ling/"" data-c="
          &lt;h3 id=&#34;gpu日志收集&#34;&gt;GPU日志收集&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# nvidia-bug-report.sh   // 执行后输出nvidia-bug-report.log.gz文件
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;驱动问题常见解决方法&#34;&gt;驱动问题常见解决方法&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;维持较新的驱动版本&lt;/li&gt;
&lt;li&gt;禁用nouveau模块&lt;/li&gt;
&lt;li&gt;打开GPU驱动常驻内存模式并配置开机自启动&lt;/li&gt;
&lt;li&gt;GPU故障后，可尝试重启主机解决&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;禁用nouveau模块&#34;&gt;禁用nouveau模块&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# lsmod | grep -i nouveau   // 如果有输出，表示启动状态，否则为禁用状态

# CentOS 7
# 编辑或新建 blacklist-nouveau.conf 文件
[root@zj ~]# vim /usr/lib/modprobe.d/blacklist-nouveau.conf
blacklist nouveau
options nouveau modeset=0

# 执行如下命令并重启系统使内核生效
[root@zj ~]# dracut -f
[root@zj ~]# shutdown -ry 0


# ubuntu 
# vi /etc/modprobe.d/blacklist.conf 最后一行加入
blacklist nouveau
# update-initramfs -u
# reboot
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;gpu驱动内存常驻模式&#34;&gt;GPU驱动内存常驻模式&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# nvidia-smi -pm 1
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;gpu加载数量和err检查&#34;&gt;GPU加载数量和ERR检查&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 以下两个命令显示的GPU卡数量需要保持一致，可用于判断是否有GPU离线
# lspci | grep -i nvidia 
# nvidia-smi

# 检查输出中是否包含ERR错误字样，可用于实现健康检查
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;gpu常用性能指标获取&#34;&gt;GPU常用性能指标获取&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# nvidia-smi \
&amp;gt;  --query-gpu=memory.total,memory.used,memory.free,utilization.memory,utilization.gpu,temperature.gpu,fan.speed \
&amp;gt;  --format=csv,noheader,nounits

# nvidia-smi --help-query-gpu   // 查看可用的查询参数
&lt;/code&gt;&lt;/pre&gt;
">NVIDIA显卡常用命令</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/li-jie-oauth-20-de-ji-ben-liu-cheng/"" data-c="
          &lt;h3 id=&#34;快递员场景&#34;&gt;快递员场景&lt;/h3&gt;
&lt;p&gt;需求：有没有一种办法，让快递员能够自由出入小区，又不用知道小区居民的密码，而且他的唯一权限就是送货，其他需要密码的场合，他都没有权限？&lt;/p&gt;
&lt;h3 id=&#34;授权机制的设计&#34;&gt;授权机制的设计&lt;/h3&gt;
&lt;p&gt;第一步，门禁系统的密码输入器下面，增加一个按钮，叫做&amp;quot;获取授权&amp;quot;。快递员需要首先按这个按钮，去申请授权。&lt;/p&gt;
&lt;p&gt;第二步，他按下按钮以后，屋主（也就是我）的手机就会跳出对话框：有人正在要求授权。系统还会显示该快递员的姓名、工号和所属的快递公司。&lt;/p&gt;
&lt;p&gt;我确认请求属实，就点击按钮，告诉门禁系统，我同意给予他进入小区的授权。&lt;/p&gt;
&lt;p&gt;第三步，门禁系统得到我的确认以后，向快递员显示一个进入小区的令牌（access token）。令牌就是类似密码的一串数字，只在短期内（比如七天）有效。&lt;/p&gt;
&lt;p&gt;第四步，快递员向门禁系统输入令牌，进入小区。&lt;/p&gt;
&lt;p&gt;有人可能会问，为什么不是远程为快递员开门，而要为他单独生成一个令牌？这是因为快递员可能每天都会来送货，第二天他还可以复用这个令牌。另外，有的小区有多重门禁，快递员可以使用同一个令牌通过它们。&lt;/p&gt;
&lt;h3 id=&#34;转换理解&#34;&gt;转换理解&lt;/h3&gt;
&lt;p&gt;所以，OAuth就是一种授权机制，数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（Token），用于替代密码，以供第三方使用。&lt;/p&gt;
&lt;h3 id=&#34;关于token&#34;&gt;关于Token&lt;/h3&gt;
&lt;p&gt;只需要记住三点：1、令牌的有效期是有限的，为了安全；2、令牌的权限范围一般很小；3、令牌可以被撤销；&lt;/p&gt;
&lt;h3 id=&#34;参考文献&#34;&gt;参考文献&lt;/h3&gt;
&lt;p&gt;http://www.ruanyifeng.com/blog/2019/04/oauth_design.html&lt;/p&gt;
">理解OAuth 2.0的基本流程</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/nginx-pei-zhi-wen-jian-xiang-jie/"" data-c="
          &lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;######Nginx配置文件nginx.conf中文详解#####

#定义Nginx运行的用户和用户组
user www www;

#nginx进程数，建议设置为等于CPU总核心数。
worker_processes 8;
 
#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]
error_log /usr/local/nginx/logs/error.log info;

#进程pid文件
pid /usr/local/nginx/logs/nginx.pid;

#指定进程可以打开的最大描述符：数目
#工作模式与连接数上限
#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。
#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。
#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。
worker_rlimit_nofile 65535;

events
{
    use epoll;

    #单个进程最大连接数（最大连接数=连接数*进程数）
    worker_connections 65535;

    #keepalive超时时间。
    keepalive_timeout 60;

    #分页大小可以用命令getconf PAGESIZE 取得。
    #getconf PAGESIZE 设置为该值的整数倍
    client_header_buffer_size 4k;

    #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。
    open_file_cache max=65535 inactive=60s;

    #语法:open_file_cache_valid time 
    #默认值 60 
    #使用字段:http, server, location 
    #这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.
    open_file_cache_valid 80s;

    #语法:open_file_cache_min_uses number 
    #默认值: 1 
    #使用字段:http, server, location  
    #这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.
    open_file_cache_min_uses 1;
    
    #语法:open_file_cache_errors on | off 
    #默认值: off 
    #使用字段:http, server, location 
    #这个指令指定是否在搜索一个文件是记录cache错误.
    open_file_cache_errors on;
}
 
#设定http服务器，利用它的反向代理功能提供负载均衡支持
http
{
    #文件扩展名与文件类型映射表
    include mime.types;

    #默认文件类型
    default_type application/octet-stream;

    #默认编码
    #charset utf-8;

    #服务器名字的hash表大小
    #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.
    server_names_hash_bucket_size 128;

    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。
    client_header_buffer_size 32k;

    #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。
    large_client_header_buffers 4 64k;

    #设定通过nginx上传文件的大小
    client_max_body_size 8m;

    #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。
    #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。
    sendfile on;

    #开启目录列表访问，合适下载服务器，默认关闭。
    autoindex on;

    #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用
    tcp_nopush on;
    tcp_nodelay on;

    #长连接超时时间，单位是秒
    keepalive_timeout 120;

    #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。
    fastcgi_connect_timeout 300;
    fastcgi_send_timeout 300;
    fastcgi_read_timeout 300;
    fastcgi_buffer_size 64k;
    fastcgi_buffers 4 64k;
    fastcgi_busy_buffers_size 128k;
    fastcgi_temp_file_write_size 128k;

    #gzip模块设置
    gzip on;               #开启gzip压缩输出
    gzip_min_length 1k;    #最小压缩文件大小
    gzip_buffers 4 16k;    #压缩缓冲区
    gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
    gzip_comp_level 2;     #压缩等级
    gzip_types text/plain application/x-javascript text/css application/xml;    #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。
    gzip_vary on;

    #开启限制IP连接数的时候需要使用
    #limit_zone crawler $binary_remote_addr 10m;

    #负载均衡配置
    upstream piao.jd.com {
        #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。
        server 192.168.80.121:80 weight=3;
        server 192.168.80.122:80 weight=2;
        server 192.168.80.123:80 weight=3;

        #nginx的upstream目前支持4种方式的分配
        #1、轮询（默认）
        #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
        #2、weight
        #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
        #2、ip_hash
        #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
        #例如：
        #upstream bakend {
        #    ip_hash;
        #    server 192.168.0.14:88;
        #    server 192.168.0.15:80;
        #}
        #3、fair（第三方）
        #按后端服务器的响应时间来分配请求，响应时间短的优先分配。
        #upstream backend {
        #    server server1;
        #    server server2;
        #    fair;
        #}
        #4、url_hash（第三方）
        #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
        #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法
        #upstream backend {
        #    server squid1:3128;
        #    server squid2:3128;
        #    hash $request_uri;
        #    hash_method crc32;
        #}

        #tips:
        #upstream bakend{#定义负载均衡设备的Ip及设备状态}{
        #    ip_hash;
        #    server 127.0.0.1:9090 down;
        #    server 127.0.0.1:8080 weight=2;
        #    server 127.0.0.1:6060;
        #    server 127.0.0.1:7070 backup;
        #}
        #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;

        #每个设备的状态设置为:
        #1.down表示单前的server暂时不参与负载
        #2.weight为weight越大，负载的权重就越大。
        #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误
        #4.fail_timeout:max_fails次失败后，暂停的时间。
        #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。

        #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。
        #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug
        #client_body_temp_path设置记录文件的目录 可以设置最多3层目录
        #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡
    }
     
     
     
    #虚拟主机的配置
    server
    {
        #监听端口
        listen 80;

        #域名可以有多个，用空格隔开
        server_name www.jd.com jd.com;
        index index.html index.htm index.php;
        root /data/www/jd;

        #对******进行负载均衡
        location ~ .*.(php|php5)?$
        {
            fastcgi_pass 127.0.0.1:9000;
            fastcgi_index index.php;
            include fastcgi.conf;
        }
         
        #图片缓存时间设置
        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$
        {
            expires 10d;
        }
         
        #JS和CSS缓存时间设置
        location ~ .*.(js|css)?$
        {
            expires 1h;
        }
         
        #日志格式设定
        #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；
        #$remote_user：用来记录客户端用户名称；
        #$time_local： 用来记录访问时间与时区；
        #$request： 用来记录请求的url与http协议；
        #$status： 用来记录请求状态；成功是200，
        #$body_bytes_sent ：记录发送给客户端文件主体内容大小；
        #$http_referer：用来记录从那个页面链接访问过来的；
        #$http_user_agent：记录客户浏览器的相关信息；
        #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。
        log_format access &#39;$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; &#39;
        &#39;$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &#39;
        &#39;&amp;quot;$http_user_agent&amp;quot; $http_x_forwarded_for&#39;;
         
        #定义本虚拟主机的访问日志
        access_log  /usr/local/nginx/logs/host.access.log  main;
        access_log  /usr/local/nginx/logs/host.access.404.log  log404;
         
        #对 &amp;quot;/&amp;quot; 启用反向代理
        location / {
            proxy_pass http://127.0.0.1:88;
            proxy_redirect off;
            proxy_set_header X-Real-IP $remote_addr;
             
            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
             
            #以下是一些反向代理的配置，可选。
            proxy_set_header Host $host;

            #允许客户端请求的最大单文件字节数
            client_max_body_size 10m;

            #缓冲区代理缓冲用户端请求的最大字节数，
            #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。
            #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误
            client_body_buffer_size 128k;

            #表示使nginx阻止HTTP应答代码为400或者更高的应答。
            proxy_intercept_errors on;

            #后端服务器连接的超时时间_发起握手等候响应超时时间
            #nginx跟后端服务器连接超时时间(代理连接超时)
            proxy_connect_timeout 90;

            #后端服务器数据回传时间(代理发送超时)
            #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据
            proxy_send_timeout 90;

            #连接成功后，后端服务器响应时间(代理接收超时)
            #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）
            proxy_read_timeout 90;

            #设置代理服务器（nginx）保存用户头信息的缓冲区大小
            #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小
            proxy_buffer_size 4k;

            #proxy_buffers缓冲区，网页平均在32k以下的设置
            #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k
            proxy_buffers 4 32k;

            #高负荷下缓冲大小（proxy_buffers*2）
            proxy_busy_buffers_size 64k;

            #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长
            #设定缓存文件夹大小，大于这个值，将从upstream服务器传
            proxy_temp_file_write_size 64k;
        }
         
        #设定查看Nginx状态的地址
        location /NginxStatus {
            stub_status on;
            access_log on;
            auth_basic &amp;quot;NginxStatus&amp;quot;;
            auth_basic_user_file confpasswd;
            #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。
        }
         
        #本地动静分离反向代理配置
        #所有jsp的页面均交由tomcat或resin处理
        location ~ .(jsp|jspx|do)?$ {
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_pass http://127.0.0.1:8080;
        }
         
        #所有静态文件由nginx直接读取不经过tomcat或resin
        location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|
        pdf|xls|mp3|wma)$
        {
            expires 15d; 
        }
         
        location ~ .*.(js|css)?$
        {
            expires 1h;
        }
    }
}
######Nginx配置文件nginx.conf中文详解#####
&lt;/code&gt;&lt;/pre&gt;
">Nginx配置文件详解</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/nc-ming-ling-shi-yong/"" data-c="
          &lt;h3 id=&#34;端口扫描&#34;&gt;端口扫描&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# nc -vz -w 5 127.0.0.1 1-1024   // 扫描本地1-1024端口范围
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;监听端口&#34;&gt;监听端口&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# nc -l 8000     // 监听TCP端口
# nc -ul 9999    // 监听UDP端口
# nc -vuz 127.0.0.1 9999   // 测试本地UDP端口
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;传输文件&#34;&gt;传输文件&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1.上传
# nc -l 9999 &amp;gt; filename
# nc 127.0.0.1 9999 &amp;lt; source

2.下载
# nc -l 9999 &amp;lt; filename
# nc 127.0.0.1 9999 &amp;gt; target
&lt;/code&gt;&lt;/pre&gt;
">nc命令使用</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/storcli-gong-ju-shi-yong-shuo-ming/"" data-c="
          &lt;h3 id=&#34;记录一下storcli工具的基本查询方法主要用于实现监控目的对于更改raid的相关命令暂时不在这里记录&#34;&gt;记录一下storcli工具的基本查询方法，主要用于实现监控目的，对于更改Raid的相关命令暂时不在这里记录。&lt;/h3&gt;
&lt;h3 id=&#34;获取帮助信息&#34;&gt;获取帮助信息&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 -h
     Storage Command Line Tool  Ver 1.23.02 Mar 28, 2017

     (c)Copyright 2017, AVAGO Corporation, All Rights Reserved.

storcli -v 
storcli -h| -help| ? 
storcli -h| -help| ? legacy
storcli show 
storcli show all
storcli show ctrlcount
storcli show file=&amp;lt;filepath&amp;gt;
storcli /cx add vd r[0|1|5|6|00|10|50|60]
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;显示raid卡相关信息&#34;&gt;显示Raid卡相关信息&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 show all
Status Code = 0
Status = Success
Description = None

Number of Controllers = 1
Host Name = A-f8f21e93eca4-nas014
Operating System  = Linux3.10.0-1062.el7.x86_64

System Overview :
===============

-------------------------------------------------------------------------------------
Ctl Model                   Ports PDs DGs DNOpt VDs VNOpt BBU sPR DS  EHS ASOs Hlth  
-------------------------------------------------------------------------------------
  0 AVAGOMegaRAIDSAS9361-8i     8  25   2     1   2     1 Opt On  1&amp;amp;2 Y      3 NdAtn 
-------------------------------------------------------------------------------------

Ctl=Controller Index|DGs=Drive groups|VDs=Virtual drives|Fld=Failed
PDs=Physical drives|DNOpt=DG NotOptimal|VNOpt=VD NotOptimal|Opt=Optimal
Msng=Missing|Dgd=Degraded|NdAtn=Need Attention|Unkwn=Unknown
sPR=Scheduled Patrol Read|DS=DimmerSwitch|EHS=Emergency Hot Spare
Y=Yes|N=No|ASOs=Advanced Software Options|BBU=Battery backup unit
Hlth=Health|Safe=Safe-mode boot

# 这里的optimal表示是否是最优状态
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;显示控制器信息&#34;&gt;显示控制器信息&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0 show   //这里c0表示第一个控制器
Generating detailed summary of the adapter, it may take a while to complete.

Controller = 0
...省略
Device Number = 0
Function Number = 0
Drive Groups = 2

TOPOLOGY :
========

-----------------------------------------------------------------------------
DG Arr Row EID:Slot DID Type  State BT       Size PDC  PI SED DS3  FSpace TR 
-----------------------------------------------------------------------------
 ... 省略
 1 0   12  10:12    37  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   13  10:13    36  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   14  10:14    46  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   15  -        -   DRIVE Msng  -   14.551 TB -    -  -   -    -      N  
 1 0   16  10:16    38  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   17  10:17    35  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   18  10:18    45  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N    
-----------------------------------------------------------------------------
... 省略

Missing Drives Count = 1

# 这里提示我们有一块盘丢失，需要进行处理
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;显示剩余空间&#34;&gt;显示剩余空间&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0 show freespace
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;显示ccconsistency-check&#34;&gt;显示CC（Consistency Check）&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0 show cc
Controller = 0
Status = Success
Description = None

Controller Properties :
=====================

-----------------------------------------------
Ctrl_Prop                 Value                
-----------------------------------------------
CC Operation Mode         Concurrent           
CC Execution Delay        168                  
CC Next Starttime         02/04/2021, 15:00:00 
CC Current State          Stopped              
CC Number of iterations   15                   
CC Number of VD completed 1                    
CC Excluded VDs           None                 
-----------------------------------------------

&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;显示cc速率&#34;&gt;显示CC速率&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0 show ccrate
Controller = 0
Status = Success
Description = None


Controller Properties :
=====================

----------------
Ctrl_Prop Value 
----------------
CC Rate   30%   
----------------
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;查看与设置rebuild速率&#34;&gt;查看与设置Rebuild速率&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0 show rebuildrate     //查看速率
# ./storcli64 /c0 set rebuildrate=30   //设置速率
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;清除raid卡物理磁盘cache&#34;&gt;清除Raid卡，物理磁盘Cache&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0 flushcache
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;获取所有enclosure信息&#34;&gt;获取所有enclosure信息&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0/eall show
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;获取单个enclosure信息&#34;&gt;获取单个enclosure信息&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0/e10 show &amp;lt;all&amp;gt;    //加上all参数表示获取详细信息
# ./strocli64 /c0/e10 show status   //获取风扇等设备详细信息
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;获取所有磁盘详细信息&#34;&gt;获取所有磁盘详细信息&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0/eall/sall show
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;卷组信息获取&#34;&gt;卷组信息获取&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# ./storcli64 /c0/dall show   // 这里的卷组称为DG
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;
&lt;p&gt;https://www.cnblogs.com/luxiaodai/p/9878747.html&lt;/p&gt;
">StorCLI工具使用说明</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/mysql-de-zu-ti-jiao-yuan-li/"" data-c="
          &lt;h2 id=&#34;事务提交流程&#34;&gt;事务提交流程&lt;/h2&gt;
&lt;h3 id=&#34;大致流程如下&#34;&gt;大致流程如下：&lt;/h3&gt;
&lt;p&gt;有binlog的情况下，commit动作开始时，会有一个Redo XID写入redo，然后写data到binlog，binlog写成功后，会将binlog的filename和日志写的position再写回redo（position也会写入pos文件），此时事务完成（committed）。如果只有XID，没有filename和position，则表示事务为prepare状态。&lt;/p&gt;
&lt;h3 id=&#34;流程&#34;&gt;流程：&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# commit; --&amp;gt; write XID to redo. --&amp;gt; write data to Binlog. --&amp;gt; write filename,postsion of binlog to redo. --&amp;gt; commited.
# 记录Binlog是在InnoDB引擎Prepare（即Redo Log写入磁盘）之后，这点至关重要。
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://esp0x.github.io/post-images/1610962074302.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;不同阶段crash的情况&#34;&gt;不同阶段crash的情况：&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;crash发生阶段&lt;/th&gt;
&lt;th&gt;事务状态&lt;/th&gt;
&lt;th&gt;事务结果&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;当事务在prepare阶段crash&lt;/td&gt;
&lt;td&gt;该事务未写入binlog，引擎层也未写入redo到磁盘&lt;/td&gt;
&lt;td&gt;该事务rollback&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;当事务在binlog写阶段crash&lt;/td&gt;
&lt;td&gt;此时引擎层redo写盘完成，但binlog日志还未落盘&lt;/td&gt;
&lt;td&gt;该事务rollback&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;当事务在binlog日志写入磁盘后crash，但引擎层未来得及commit&lt;/td&gt;
&lt;td&gt;此时引擎层redo已经写盘，server层binlog已经写盘，但redo中事务状态未正确结束&lt;/td&gt;
&lt;td&gt;读出binlog中的XID，并通知引擎层提交这些XID的事务。引擎层提交这些事务后，会回滚其他事务，使引擎层redo和binlog日志在事务上始终保持一致。事务通过recovery自动完成提交&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;wal机制&#34;&gt;WAL机制&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;WAL（Write Ahead Log）：对数据文件进行修改前，必须将修改先记录到日志。&lt;/li&gt;
&lt;li&gt;Redo log就是一种WAL应用，用于保证数据库的持久性，每次事务提交时，不用同步刷新磁盘，只需要刷新redo log就行了。相比刷盘的随机IO，写redo log的顺序IO能够提升事务提交速度。&lt;/li&gt;
&lt;li&gt;组提交：
&lt;ol&gt;
&lt;li&gt;未开启binlog：redo log的刷盘操作是主要瓶颈，mysql使用组提交，将多个redo log刷盘操作合并成一个。&lt;/li&gt;
&lt;li&gt;开启binlog：为了保证redo log和binlog数据一致性，mysql使用了二阶段提交，此时binlog成为瓶颈，mysql增加了binlog的组提交来解决这个问题，分为三个阶段（Flush、Sync、Commit），最大化刷盘收益。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;过程详解&#34;&gt;过程详解&lt;/h3&gt;
&lt;p&gt;在Mysql中每个阶段都有一个队列，每个队列都有一把锁保护，第一个进入队列的事务成为leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。&lt;/p&gt;
&lt;h4 id=&#34;flush阶段&#34;&gt;Flush阶段&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;首先获取队列中的事务组；&lt;/li&gt;
&lt;li&gt;将redo中prepare阶段的数据刷盘；&lt;/li&gt;
&lt;li&gt;将binlog数据写入文件，此处是文件缓冲，不保证数据库crash时，binlog的完整性；&lt;/li&gt;
&lt;li&gt;Flush阶段的作用是提供了redo 的组提交；&lt;/li&gt;
&lt;li&gt;如果这一步crash，由于不保证binlog中存在事务记录，所以数据库恢复后会回滚，此时二阶段提交状态还是prepare；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;sync阶段&#34;&gt;Sync阶段&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;为了增加一组事务中的事务数量，提升刷盘效率，使用两个参数进行控制：
&lt;ol&gt;
&lt;li&gt;binlog_group_commit_sync_delay=N  等待N 微秒后，开始事务刷盘&lt;/li&gt;
&lt;li&gt;binlog_group_commit_sync_no_delay=N  对列中事务达到N个，立刻刷盘，忽略上面那个时间参数&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Sync阶段的作用是支持binlog的组提交；&lt;/li&gt;
&lt;li&gt;如果此时crash，由于binlog中有事务记录，数据库恢复后会继续提交该事务；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;commit阶段&#34;&gt;Commit阶段&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;首先获取队列中的事务组；&lt;/li&gt;
&lt;li&gt;依次将redo中已经prepare的事务在引擎层进行提交；&lt;/li&gt;
&lt;li&gt;Commit阶段不用刷盘，如上所述，Flush阶段中的Redo log刷盘已经足够保证数据库崩溃时的数据安全了；&lt;/li&gt;
&lt;li&gt;Commit阶段队列的作用是承接Sync阶段的事务，完成最后的引擎提交，使得Sync可以尽早的处理下一组事务，最大化组提交的效率；&lt;/li&gt;
&lt;/ul&gt;
">Mysql的组提交原理</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/gtid-ji-chu-yuan-li/"" data-c="
          &lt;h2 id=&#34;一-gtid概述&#34;&gt;一、GTID概述&lt;/h2&gt;
&lt;p&gt;GTID是MYSQL5.6新增的特性，GTID（Global Transaction Identifier）全称为全局事务标示符,用以数据库实例事务唯一标识，其组成主要是source_id和transaction_id 即GTID = source_id:transaction_id。其中source_id是数据库启动自动生成的数据库实例唯一标识，保存在auto.cnf中，而transaction_id则是事务执行的序列号。&lt;/p&gt;
&lt;h2 id=&#34;二-gtid优缺点&#34;&gt;二、GTID优缺点&lt;/h2&gt;
&lt;h3 id=&#34;优点&#34;&gt;优点：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;复制安全性更高，一个事务在每个实例上只执行一次；&lt;/li&gt;
&lt;li&gt;故障切换简单，可通过设置MASTER_AUTO_POSITION=1，而非master_log_file和master_log_pos来建立主从关系；&lt;/li&gt;
&lt;li&gt;可根据GTID确定事务最早提交的实例；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;缺点&#34;&gt;缺点：&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;组复制中，必须要求统一开启GTID或者关闭GTID；&lt;/li&gt;
&lt;li&gt;不支持复制create table table_name select ... from table_name_xx ;&lt;/li&gt;
&lt;li&gt;不支持create temporary table和drop temporary table；&lt;/li&gt;
&lt;li&gt;不支持sql_slave_skip_counter，可通过set global gtid_next=&#39;&#39; 跳过；&lt;/li&gt;
&lt;li&gt;从库和主库都必须设置log_slave_updates&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;三-gtid工作原理&#34;&gt;三、GTID工作原理&lt;/h2&gt;
&lt;p&gt;1、master更新数据时，会在事务前产生GTID，一同记录到binlog日志中。&lt;br&gt;
2、slave端的i/o 线程将变更的binlog，写入到本地的relay log中。&lt;br&gt;
3、sql线程从relay log中获取GTID，然后对比slave端的binlog是否有记录。&lt;br&gt;
4、如果有记录，说明该GTID的事务已经执行，slave会忽略。&lt;br&gt;
5、如果没有记录，slave就会从relay log中执行该GTID的事务，并记录到binlog。&lt;br&gt;
6、在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。&lt;/p&gt;
&lt;h2 id=&#34;四-gtid开启和关闭&#34;&gt;四、GTID开启和关闭&lt;/h2&gt;
&lt;p&gt;gtid_mode=ON(必选)&lt;br&gt;
log_bin=ON(必选)&lt;br&gt;
log-slave-updates=ON(必选)&lt;br&gt;
enforce-gtid-consistency(必选)&lt;br&gt;
log-bin = /home/mysql/mysql-bin（必选）&lt;br&gt;
binlog_format = MIXED（必选mixed或者row）&lt;br&gt;
##&lt;br&gt;
change master to master_host = &#39;ipaddr&#39;,master_port = 3306,master_user = &#39;username&#39;,master_password=&#39;password&#39;,master_auto_position = 1;&lt;/p&gt;
&lt;h2 id=&#34;五-gtid适用场景&#34;&gt;五、GTID适用场景&lt;/h2&gt;
&lt;p&gt;1、搭建高可用架构，方便主从切换后，新的从库重新指定主库（例如一主二从的结构，A为mater,B为Slave，C为Slave，A宕机切换到B后，C重新指定主库为B）&lt;br&gt;
2、不经常使用create table table_name select * from table_name/create temporary table/update t1,t2 where ...这种语句的场合&lt;/p&gt;
">GTID基础原理</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/mysql-shi-wu-ge-chi-ji-bie-ji-shi-xian/"" data-c="
          &lt;h2 id=&#34;四个基本要素acid&#34;&gt;四个基本要素（ACID）&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;原子性（Atomicity）&lt;/li&gt;
&lt;li&gt;一致性（Consistency）&lt;/li&gt;
&lt;li&gt;隔离性（Isolation）&lt;/li&gt;
&lt;li&gt;持久性（Durability）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;事务的并发问题&#34;&gt;事务的并发问题&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读到的数据是脏数据；&lt;/li&gt;
&lt;li&gt;不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取的数据不一致；&lt;/li&gt;
&lt;li&gt;幻读：幻读并不是说两次读取的结果集不同，幻读侧重的方面是某一次的select操作得到的结果所表征的数据状态无法支撑后续的业务操作。具体来说，select某条记录是否存在，不存在，准备插入此记录，但执行insert时发现此记录已存在，无法插入，此时就发生了幻读。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;事务隔离级别&#34;&gt;事务隔离级别&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;事务隔离级别&lt;/th&gt;
&lt;th&gt;脏读&lt;/th&gt;
&lt;th&gt;不可重复读&lt;/th&gt;
&lt;th&gt;幻读&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;读未提交（read-uncommitted）&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;不可重复读（read-committed）&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;可重复读（repeatable-read）&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;串行化（serializable）&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;查看数据库隔离级别&#34;&gt;查看数据库隔离级别&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;mysql&amp;gt; select @@global.tx_isolation, @@tx_isolation;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;acid实现原理&#34;&gt;ACID实现原理&lt;/h2&gt;
&lt;h3 id=&#34;原子性&#34;&gt;原子性&lt;/h3&gt;
&lt;p&gt;实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB实现回滚，依赖的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log，如果事务执行失败或调用rollback，导致事务需要回滚，便可以利用undo log中的信息将数据进行回滚。undo log其实就是记录数据修改时的相反操作。&lt;/p&gt;
&lt;h3 id=&#34;持久性&#34;&gt;持久性&lt;/h3&gt;
&lt;p&gt;实现持久性主要依赖redo log，redo log采用WAL，所有修改先写入日志，再更新到Buffer Pool，保证了数据库不会因意外宕机而丢失。写redo log是要比刷缓存到磁盘要快的，原因如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;刷脏是随机IO、这个很好理解；而redo log是追加操作，属于顺序IO，所以速度快；&lt;/li&gt;
&lt;li&gt;刷脏是以Page为单位的，Mysql默认页大小是16KB，一个Page上一个小的修改都需要整页写入；而redo log中只包含真正需要写入的部分，无效IO减少；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;关于binlog和redo log的区别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作用不同：redo log是用于crash recovery的，保证MySQL宕机也不会影响持久性；binlog是用于point-in-time recovery的，保证服务器可以基于时间点恢复数据，此外binlog还用于主从复制。&lt;/li&gt;
&lt;li&gt;层次不同：redo log是InnoDB存储引擎实现的，而binlog是MySQL的服务器层实现的，同时支持InnoDB和其他存储引擎。&lt;/li&gt;
&lt;li&gt;内容不同：redo log是物理日志，内容基于磁盘的Page；binlog的内容是二进制的，根据binlog_format参数的不同，可能基于sql语句、基于数据本身或者二者的混合。&lt;/li&gt;
&lt;li&gt;写入时机不同：binlog在事务提交时写入；redo log的写入时机相对多元，可以通过双1设置进行控制；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;隔离性&#34;&gt;隔离性&lt;/h3&gt;
&lt;p&gt;隔离性追求的是并发条件下事务之间互不干扰；主要考虑两种场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;两个事务的写操作之间的影响：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;InnoDB通过锁机制来保证同一时刻只有一个事务进行写操作，简单理解为，事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据，其他事务需要等待该锁释放后才能对同一数据进行操作。&lt;/li&gt;
&lt;li&gt;表锁会锁住整个表，并发性能较差；&lt;/li&gt;
&lt;li&gt;行锁只锁定需要操作的数据，并发性能好，但数据较多时性能也会下降；绝大多数情况下，我们使用行锁即可；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两个事务的读操作之间的影响：&lt;/p&gt;
&lt;p&gt;Mysql中默认的隔离级别是RR，InnoDB实现的RR可以避免幻读的问题，即使用MVCC技术，Multi-Version Concurrency Control。&lt;/p&gt;
&lt;p&gt;MVCC最大的优点是读不加锁，因此读写不冲突，并发性好。InnoDB实现MVCC，多个版本的数据可以共存，主要依赖以下技术和数据结构：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;数据库需要做好版本控制，防止不该被事务看到的数据(例如还没提交的事务修改的数据)被看到。在InnoDB中，主要是通过使用readview的技术来实现判断。查询出来的每一行记录，都会用readview来判断一下当前这行是否可以被当前事务看到，如果可以，则输出，否则就利用undolog来构建历史版本，再进行判断，知道记录构建到最老的版本或者可见性条件满足。

在trx_sys中，一直维护这一个全局的活跃的读写事务id(trx_sys-&amp;gt;descriptors)，id按照从小到大排序，表示在某个时间点，数据库中所有的活跃(已经开始但还没提交)的读写(必须是读写事务，只读事务不包含在内)事务。当需要一个一致性读的时候(即创建新的readview时)，会把全局读写事务id拷贝一份到readview本地(read_view_t-&amp;gt;descriptors)，当做当前事务的快照。read_view_t-&amp;gt;up_limit_id是read_view_t-&amp;gt;descriptors这数组中最小的值，read_view_t-&amp;gt;low_limit_id是创建readview时的max_trx_id，即一定大于read_view_t-&amp;gt;descriptors中的最大值。当查询出一条记录后(记录上有一个trx_id，表示这条记录最后被修改时的事务id)，可见性判断的逻辑如下(lock_clust_rec_cons_read_sees)：

如果记录上的trx_id小于read_view_t-&amp;gt;up_limit_id，则说明这条记录的最后修改在readview创建之前，因此这条记录可以被看见。

如果记录上的trx_id大于等于read_view_t-&amp;gt;low_limit_id，则说明这条记录的最后修改在readview创建之后，因此这条记录肯定不可以被看家。

如果记录上的trx_id在up_limit_id和low_limit_id之间，且trx_id在read_view_t-&amp;gt;descriptors之中，则表示这条记录的最后修改是在readview创建之时，被另外一个活跃事务所修改，所以这条记录也不可以被看见。如果trx_id不在read_view_t-&amp;gt;descriptors之中，则表示这条记录的最后修改在readview创建之前，所以可以看到。

基于上述判断，如果记录不可见，则尝试使用undo去构建老的版本(row_vers_build_for_consistent_read)，直到找到可以被看见的记录或者解析完所有的undo。

针对RR隔离级别，在第一次创建readview后，这个readview就会一直持续到事务结束，也就是说在事务执行过程中，数据的可见性不会变，所以在事务内部不会出现不一致的情况。针对RC隔离级别，事务中的每个查询语句都单独构建一个readview，所以如果两个查询之间有事务提交了，两个查询读出来的结果就不一样。从这里可以看出，在InnoDB中，RR隔离级别的效率是比RC隔离级别的高。此外，针对RU隔离级别，由于不会去检查可见性，所以在一条SQL中也会读到不一致的数据。针对串行化隔离级别，InnoDB是通过锁机制来实现的，而不是通过多版本控制的机制，所以性能很差。

由于readview的创建涉及到拷贝全局活跃读写事务id，所以需要加上trx_sys-&amp;gt;mutex这把大锁，为了减少其对性能的影响，关于readview有很多优化。例如，如果前后两个查询之间，没有产生新的读写事务，那么前一个查询创建的readview是可以被后一个查询复用的。
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;操作指令：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;mysql&amp;gt; select * from information_schema.innodb_locks; #锁的概况
mysql&amp;gt; show engine innodb status;                     #InnoDB整体状态，其中包括锁的情况
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;一致性&#34;&gt;一致性&lt;/h3&gt;
&lt;p&gt;一致性是事务追求的终极目标，原子性、持久性和隔离性，都是为了实现一致性而存在的；实现一致性也需要应用层面进行保障；&lt;/p&gt;
&lt;h3 id=&#34;运维相关指令和参数&#34;&gt;运维相关指令和参数&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1、首先介绍一下information_schema中的三张表: innodb_trx, innodb_locks和innodb_lock_waits。由于这些表几乎需要查询所有事务子系统的核心数据结构，为了减少查询对系统性能的影响，InnoDB预留了一块内存，内存里面存了相关数据的副本，如果两次查询的时间小于0.1秒(CACHE_MIN_IDLE_TIME_US)，则访问的都是同一个副本。如果超过0.1秒，则这块内存会做一次更新，每次更新会把三张表用到的所有数据统一更新一遍，因为这三张表经常需要做表连接操作，所以一起更新能保证数据的一致性。这里简单介绍一下innodb_trx表中的字段，另外两张表涉及到事物锁的相关信息，由于篇幅限制，后续有机会在介绍。

trx_id: 就是trx_t中的事务id，如果是只读事务，这个id跟trx_t的指针地址有关，所以可能是一个很大的数字(trx_get_id_for_print)。
trx_weight: 这个是事务的权重，计算方法就是undolog数量加上事务已经加上锁的数量。在事务回滚的时候，优先选择回滚权重小的事务，有非事务引擎参与的事务被认为权重是最大的。
trx_rows_modified：这个就是当前事务已经产生的undolog数量，每更新一条记录一次，就会产生一条undo。
trx_concurrency_tickets: 每次这个事务需要进入InnoDB层时，这个值都会减一，如果减到0，则事务需要等待(压力大的情况下)。
trx_is_read_only: 如果是以start transaction read only启动事务的，那么这个字段是1，否则为0。
trx_autocommit_non_locking: 如果一个事务是一个普通的select语句(后面没有跟for update, share lock等)，且当时的autocommit为1，则这个字段为1，否则为0。
trx_state: 表示事务当前的状态，只能有RUNNING, LOCK WAIT, ROLLING BACK, COMMITTING这几种状态, 是比较粗粒度的状态。
trx_operation_state: 表示事务当前的详细状态，相比于trx_state更加详细，例如有rollback to a savepoint, getting list of referencing foreign keys, rollback of internal trx on stats tables, dropping indexes等。

2、与事务相关的undo参数

innodb_undo_directory: undo文件的目录，建议放在独立的一块盘上，尤其在经常有大事务的情况下。
innodb_undo_logs: 这个是定义了undo segment的个数。在给读写事务分配undo segment的时候，拿这个值去做轮训分配。
Innodb_available_undo_logs: 这个是一个status变量，在启动的时候就确定了，表示的是系统上分配的undo segment。举个例子说明其与innodb_undo_logs的关系：假设系统初始化的时候innodb_undo_logs为128，则在文件上一定有128个undo segment，Innodb_available_undo_logs也为128，但是启动起来后，innodb_undo_logs动态被调整为100，则后续的读写事务只会使用到前100个回滚段，最后的20多个不会使用。
innodb_undo_tablespaces: 存放undo segment的物理文件个数，文件名为undoN，undo segment会比较均匀的分布在undo tablespace中。

3、与Purge相关的参数

innodb_purge_threads: Purge Worker和Purge Coordinator总共的个数。在实际的实现中，使用多少个线程去做Purge是InnoDB根据实时负载进行动态调节的。
innodb_purge_batch_size: 一次性处理的undolog的数量，处理完这个数量后，Purge线程会计算是否需要sleep。
innodb_max_purge_lag: 如果全局历史链表超过这个值，就会增加Purge Worker线程的数量，也会使用sleep的方式delay用户的DML。
innodb_max_purge_lag_delay: 这个表示通过sleep方式delay用户DML最大的时间。

4、与回滚相关的参数

innodb_lock_wait_timeout: 等待行锁的最大时间，如果超时，则会滚当前语句或者整个事务。发生回滚后返回类似错误：Lock wait timeout exceeded; try restarting transaction。
innodb_rollback_on_timeout: 如果这个参数为true，则当发生因为等待行锁而产生的超时时，回滚掉整个事务，否则只回滚当前的语句。这个就是隐式回滚机制。主要是为了兼容之前的版本。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;原子性：语句要么全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；实现主要基于undo log&lt;/li&gt;
&lt;li&gt;持久性：保证事务提交后不会因为宕机等原因导致数据丢失；实现主要基于redo log&lt;/li&gt;
&lt;li&gt;隔离性：保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是RR，RR的实现主要基于锁机制（包含next-key lock）、MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView）&lt;/li&gt;
&lt;li&gt;一致性：事务追求的最终目标，一致性的实现既需要数据库层面的保障，也需要应用层面的保障&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考文献&#34;&gt;参考文献&lt;/h2&gt;
&lt;h4 id=&#34;httpmysqltaobaoorgmonthly20171201&#34;&gt;http://mysql.taobao.org/monthly/2017/12/01/&lt;/h4&gt;
&lt;h4 id=&#34;httpswwwcnblogscomkismetvp10331633html&#34;&gt;https://www.cnblogs.com/kismetv/p/10331633.html&lt;/h4&gt;
&lt;h4 id=&#34;httpszhuanlanzhihucomp40208895&#34;&gt;https://zhuanlan.zhihu.com/p/40208895&lt;/h4&gt;
&lt;h4 id=&#34;httpswwwcnblogscomhuanongyingp7021555html&#34;&gt;https://www.cnblogs.com/huanongying/p/7021555.html&lt;/h4&gt;
">Mysql事务隔离级别及实现</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-huan-jing-da-jian/"" data-c="
          &lt;h2 id=&#34;准备机器&#34;&gt;准备机器&lt;/h2&gt;
&lt;p&gt;两台centos7系统服务器：&lt;/p&gt;
&lt;p&gt;主mysql：192.168.50.1&lt;/p&gt;
&lt;p&gt;从mysql：192.168.50.2&lt;/p&gt;
&lt;h2 id=&#34;安装mysql&#34;&gt;安装mysql&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;下载yum源&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装yum源&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;rpm -Uvh mysql80-community-release-el7-3.noarch.rpm
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安装mysql&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;yum install -y mysql-community-server
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;启动mysql，并获取root初始密码&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# 确保selinux为disabled
# 确保关闭了firewalld服务

systemctl start mysqld

[root@localhost ~]# grep password /var/log/mysqld.log 
2020-10-19T02:47:35.912896Z 1 [Note] A temporary password is generated for root@localhost: -1k-1KjU*LG)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;登入mysql，并重置root密码&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;mysql -uroot -p 
mysql&amp;gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;qUXmZP11JwJ_11&#39;; # root本地访问，且重置
mysql&amp;gt; exit
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;主mysql数据库配置&#34;&gt;主Mysql数据库配置&lt;/h2&gt;
&lt;p&gt;编辑my.cnf配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vim /etc/my.cnf

[mysqld]
port=9006          #指定新的端口
server-id=110      #设置主服务器的ID(不能和别的服务器重复，建议使用ip的最后一段)
log-bin=mysql-bin  #binlog日志文件名
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;创建用于主从同步的账户&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ mysql -u root -p  #登录MySQL
mysql&amp;gt; CREATE USER &#39;repl&#39;@&#39;192.168.50.2&#39; IDENTIFIED WITH mysql_native_password BY &#39;Top_master_1&#39;; # 主库创建用于从库同步的账号
mysql&amp;gt; grant replication slave on *.* to &#39;repl&#39;@&#39;192.168.50.2&#39;;  #赋予主从同步权限，指定具体的数据库在/etc/my.cnf中完成
mysql&amp;gt; flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重启MySQL，使my.cnf 配置生效；查看主库状态&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ systemctl restart mysqld #重启MySQL
mysql -u root -p
mysql&amp;gt; show master status; #查看主库的状态  File,Position 这两个值需要放到slave配置中
+--------------------+----------+--------------+------------------+-------------------+
| File               | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+--------------------+----------+--------------+------------------+-------------------+
| mysql-bin.00001    |      156 |     xxxx     |                  |                   |
+--------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;从mysql数据库配置&#34;&gt;从Mysql数据库配置&lt;/h2&gt;
&lt;p&gt;编辑配置文件&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;vim /etc/my.cnf

[mysqld]
port=9006
server-id=111
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;配置完成后，重启从库的MySQL&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;$ systemctl restart mysqld  #重启MySQL
$ mysql -u root -p          #登录mysql
mysql&amp;gt; stop slave;          #关闭从库
mysql&amp;gt; change master to master_host=&#39;192.168.50.1&#39;,master_port=9006,master_user=&#39;repl&#39;,master_password=&#39;Top_master_1&#39;,master_log_file=&#39;mysql-bin.00001&#39;,master_log_pos=156; #配置主库信息
mysql&amp;gt; start slave;            #开启从库 
mysql&amp;gt; show slave status \G;   #Slave_IO_Running,Slave_SQL_Running 都为Yes的时候表示配置成功
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;主库创建数据库和数据表&#34;&gt;主库创建数据库和数据表&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create database topmanager DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
登入从库，可以看到从库中出现同样的数据库和数据表，表明已同步&lt;/code&gt;&lt;/pre&gt;
">Mysql主从复制环境搭建</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/mysql-shuang-1-she-zhi-shu-ju-an-quan-de-guan-jian-can-shu/"" data-c="
          &lt;h2 id=&#34;一-参数及设置说明&#34;&gt;一、参数及设置说明&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;# innodb_flush_log_at_trx_commit
1.设置为0：log buffer将每秒一次地写入log file中，并且log file的flush操作同时进行；该模式下，在事务提交时，不会主动触发写入磁盘的操作；
2.设置为1：每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去;
3.设置为2：每次事务提交时MySQL都会把log buffer的数据写入log file，但是flush(刷到磁盘)操作并不会同时进行。该模式下,MySQL会每秒执行一次 flush(刷到磁盘)操作。

# sync_binlog
sync_binlog 的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。
当sync_binlog =N (N&amp;gt;0) ，MySQL 在每写 N次 二进制日志binary log时，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去。

注意：如果启用了autocommit，那么每一个语句statement就会有一次写操作；否则每个事务对应一个写操作。

# 性能与安全性对比 
1.双1设置时，写入性能最差，安全性最高；
2.sync_binlog=N (N&amp;gt;1 ) innodb_flush_log_at_trx_commit=2 时，性能最好，安全性较差；
3.innodb_flush_log_at_trx_commit设置为0，mysqld进程崩溃会导致上一秒钟所有事务数据的丢失；
4.innodb_flush_log_at_trx_commit设置为2，当系统崩溃或者断电时，上一秒的所有数据才有可能丢失；
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;二-对io影响较大的几个参数&#34;&gt;二、对IO影响较大的几个参数&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;1.innodb_buffer_pool_size # 该参数控制innodb缓存大小，用于缓存应用访问的数据，推荐配置为系统可用内存的80%。
2.binlog_cache_size       # 该参数控制二进制日志缓冲大小，当事务还没有提交时，事务日志存放于cache，当遇到大事务cache不够用的时，mysql会把uncommitted的部分写入临时文件,等到committed的时候才会写入正式的持久化日志文件。
3.innodb_max_dirty_pages_pct     # 该参数可以直接控制Dirty Page在BP中所占的比率，当dirty page达到了该参数的阈值，就会触发MySQL系统刷新数据到磁盘。
4.innodb_flush_log_at_trx_commit # 该参数确定日志文件何时write、flush。
5.sync_binlog         # sync_binlog的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。
6.innodb_flush_method # 该参数控制日志或数据文件如何write、flush。可选的值为fsync，o_dsync，o_direct，littlesync，nosync。
&lt;/code&gt;&lt;/pre&gt;
">Mysql双1设置-数据安全的关键参数</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/mysql-fen-ku-fen-biao-ce-lue/"" data-c="
          &lt;p&gt;数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库性能的目的。&lt;/p&gt;
&lt;h2 id=&#34;垂直切分&#34;&gt;垂直切分&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://esp0x.github.io/post-images/1610676801903.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
垂直切分常见有垂直分库和垂直分表两种：&lt;/p&gt;
&lt;p&gt;垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库中。类似微服务架构，每一个微服务单独使用一个数据库的形式。&lt;/p&gt;
&lt;p&gt;垂直分表是基于数据库中的列进行， 针对某个表字段过多，可以新建一张扩展表，将不常用的字段或长度较大的字段拆分到扩展表中。这样可以避免跨页问题，MySQL底层是通过数据页存储的，一条记录过大会导致跨页，造成额外的性能损失。&lt;/p&gt;
&lt;h3 id=&#34;垂直切分的优点&#34;&gt;垂直切分的优点：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;解决业务系统层面的耦合，使得业务逻辑更清晰；&lt;/li&gt;
&lt;li&gt;与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等；&lt;/li&gt;
&lt;li&gt;高并发场景下，垂直切分一定程度上能够提升访问性能；&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;垂直切分的缺点&#34;&gt;垂直切分的缺点：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;部分表无法join，只能通过接口方式，开发难度增加；&lt;/li&gt;
&lt;li&gt;分布式事务处理复杂；&lt;/li&gt;
&lt;li&gt;没有解决单表数据过大的问题；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;水平切分&#34;&gt;水平切分&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://esp0x.github.io/post-images/1610676821810.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
当一个应用难以再细粒化的垂直切分，或切分后单表数据量过大，存在读写性能问题时，就需要考虑水平切分了。&lt;/p&gt;
&lt;p&gt;水平切分包括库内分表和分库分表，库内分表只解决了单一表数据量过大的问题，没有将表分布到不同的机器上，对于数据库访问性能提升有限。&lt;/p&gt;
&lt;h3 id=&#34;水平切分的优点&#34;&gt;水平切分的优点：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;不存在单表数据量过大问题，提升了表的访问性能；&lt;/li&gt;
&lt;li&gt;应用端改造较小，不需要进行业务拆分；&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;水平切分的缺点&#34;&gt;水平切分的缺点：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;跨分片事务的一致性难以保证；&lt;/li&gt;
&lt;li&gt;跨库的join关联查询性能较差；&lt;/li&gt;
&lt;li&gt;数据库多次扩展难度和维护量增加；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;几种典型的数据分片规则&#34;&gt;几种典型的数据分片规则&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;根据数值范围&lt;/p&gt;
&lt;p&gt;例如：按照时间维度，将不同月，甚至不同日的数据存储到不同的表；又或者，按照userId进行划分，1-9999的记录分到第一个库，10000-20000的分到第二个库，以此类推；&lt;/p&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单表大小可控；&lt;/li&gt;
&lt;li&gt;天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点，无需对其他分片进行数据迁移；&lt;/li&gt;
&lt;li&gt;使用分片字段进行查询时，速度更快；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;缺点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;热点数据成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间的数据，可能会被频繁地读写，有些分片存储历史数据，则很少被查询。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;根据数值取模&lt;/p&gt;
&lt;p&gt;一般采用hash取模mod的切分方式。&lt;/p&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;缺点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;后期扩展时，需要迁移旧的数据；（通过一致性hash算法可以避免这个问题）&lt;/li&gt;
&lt;li&gt;容易面临跨分片查询的复杂问题，比如频繁查询中不包含分片字段，将会导致无法定位数据库，从而向所有数据库发起请求，再在内存中合并数据，性能损失严重；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;分库分表需要解决的问题&#34;&gt;分库分表需要解决的问题&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;事务问题&lt;/p&gt;
&lt;p&gt;方案一：使用分布式事务，交由数据库管理，简单有效；缺点是随着节点增加，性能代价越来越高。（需要协调的节点变多）&lt;/p&gt;
&lt;p&gt;方案二：由应用程序和数据库共同控制，性能上有优势；缺点是开发难度较大；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;跨节点Join问题&lt;/p&gt;
&lt;p&gt;分两次查询，第一次查询的结果集中找出关联数据的ID，根据这些ID发起第二次请求得到关联数据；在应用设计时应尽量避免进行关联查询；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;跨节点的count、order by、group by以及聚合函数问题&lt;/p&gt;
&lt;p&gt;分别在各个节点进行数据合并，最后在统一进行合并，缺点是当数据集较大时，占用的内存资源很多；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据迁移、容量规划、扩容等问题&lt;/p&gt;
&lt;p&gt;当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;全局主键避重问题&lt;/p&gt;
&lt;p&gt;由于表同时存在于多个数据库中，主键值设置为自增序列将不能使用，需要单独设计全局主键，一般可以用UUID的方案解决；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;跨分片的排序分页&lt;/p&gt;
&lt;p&gt;一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。&lt;/p&gt;
&lt;p&gt;如果是在前台应用提供分页，则限定用户只能看前面n页，这个限制在业务上也是合理的，一般看后面的分页意义不大（如果一定要看，可以要求用户缩小范围重新查询）。&lt;/p&gt;
&lt;p&gt;如果是后台批处理任务要求分批获取数据，则可以加大page size，比如每次获取5000条记录，有效减少分页数（当然离线访问一般走备库，避免冲击主库）。&lt;/p&gt;
&lt;p&gt;分库设计时，一般还有配套大数据平台汇总所有分库的记录，有些分页查询可以考虑走大数据平台。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
">Mysql分库分表策略</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-yuan-li/"" data-c="
          &lt;h3 id=&#34;原理图如下&#34;&gt;原理图如下：&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://esp0x.github.io/post-images/1610671157156.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;主从复制流程详解&#34;&gt;主从复制流程详解：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;master库发生数据改变时，会将改变写入binglog日志；&lt;/li&gt;
&lt;li&gt;slave库会在一定时间间隔内对master的binlog进行检测以确定是否发生改变，如果发生改变，则开始一个IO thread请求master二进制事件；&lt;/li&gt;
&lt;li&gt;同时，master为每一个过来请求的IO thread开启一个dump线程，用于将二进制事件发送给IO thread，slave的IO thread将此二进制事件写入本地relay log（中继日志）中，并开启SQL thread从中继日志中读取二进制日志，在本地进行重放（replay），从而使得本地数据与master保持一致；最后IO thread和SQL thread进入睡眠状态，等待下次唤醒。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;主从复制形式&#34;&gt;主从复制形式：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;主从&lt;/li&gt;
&lt;li&gt;主主&lt;/li&gt;
&lt;li&gt;一主多从&lt;/li&gt;
&lt;li&gt;多主一从&lt;/li&gt;
&lt;li&gt;联级复制&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;主从同步延时分析&#34;&gt;主从同步延时分析：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;master对所有DDL和DML产生的日志都写入binlog，由于是顺序写，所以效率很高；反之，slave的SQL thread进行relay log的重放时，DML和DDL的IO是随机的，不是顺序，所以成本较高，这里会增加一部分延时；&lt;/li&gt;
&lt;li&gt;由于SQL thread是单线程的，当master的并发较高时，过多的DML可能会导致slave的SQL thread来不及处理，这里会增加一部分延时；&lt;/li&gt;
&lt;li&gt;slave中有部分SQL产生了锁等待，这种情况就是slave有一些读请求与重放请求产生了锁冲突导致的，也会增加延时；&lt;/li&gt;
&lt;li&gt;slave在充当读库角色的时候，如果查询访问压力过大，会消耗部分系统资源，影响同步效率；&lt;/li&gt;
&lt;li&gt;大事务执行，即当master有大事务执行时，比如执行了10分钟，binlog写入必须要等待事务处理完毕，那么slave开始进行同步的时候就已经延时10分钟了；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;延时解决办法&#34;&gt;延时解决办法：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;业务层实现读写分离，一主多从，主写从读，分散压力；&lt;/li&gt;
&lt;li&gt;业务层和数据库层之间加入缓存策略，降低直接对数据库的读压力；频繁写的场景不适合加缓存，会导致缓存命中降低；&lt;/li&gt;
&lt;li&gt;升级硬件；&lt;/li&gt;
&lt;li&gt;MTS问题，即多线程的slave，从5.6版本开始支持，针对不同粒度（库、表、行）设置并行同步；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;57版本后的并行复制策略&#34;&gt;5.7版本后的并行复制策略&lt;/h2&gt;
&lt;h4 id=&#34;redo-log的两阶段提交&#34;&gt;Redo log的两阶段提交&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;先写redo，再写binlog：假设在redo写完，binlog还没有写完的时候，Mysql进程异常重启，这时仍然能够通过redo log恢复数据，但由于binlog没有这条记录，所以之后备份日志的时候，binlog是缺失这条记录的，以后需要用binlog恢复数据时，就会缺少一条数据的更新；&lt;/li&gt;
&lt;li&gt;先写binlog，再写redo log：如果binlog写完后crash，由于redo log还没写，崩溃恢复后这个事务无效，但是binlog有记录，以后用这个binlog恢复数据时，就会多出一条更新记录；&lt;/li&gt;
&lt;li&gt;二阶段提交：使用二阶段提交时，会综合redo和binlog的状态进行处理，如果写入binlog之前crash，那么由于redo处于prepare阶段，只需要对当前事务进行回滚即可；如果写入binlog之后crash，那么由于redo处于prepare阶段，只需要对当前事务进行提交即可。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;并行复制的思想&#34;&gt;并行复制的思想&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;同时处于prepare状态的事务，在备库执行是可以并行的；&lt;/li&gt;
&lt;li&gt;处于prepare状态的事务，与处于commit状态的事务之间，在备库执行也是可以并行的；&lt;/li&gt;
&lt;li&gt;binlog_group_commit_sync_delay参数，表示延迟多少微妙后才调用fsync；&lt;/li&gt;
&lt;li&gt;binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync；&lt;/li&gt;
&lt;/ol&gt;
">Mysql主从复制原理</a>
      </div>
      
      <div class="item">
        <a class="result-title" href="https://esp0x.github.io/post/about/"" data-c="
          &lt;blockquote&gt;
&lt;p&gt;系统管理员 &amp;amp; 独立安全研究员 &amp;amp; 半吊子的程序员 /&amp;lt;.&amp;gt;:) 😈&lt;/p&gt;
&lt;/blockquote&gt;
">关于</a>
      </div>
      
    </div>
  </div>
</div>
<script>
  // var escape = "[{&#34;content&#34;:&#34;&lt;h3 id=\&#34;模块路径列表\&#34;&gt;模块路径列表&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;auxiliary/scanner/ftp/ftp_login\nauxiliary/scanner/ssh/ssh_login\nauxiliary/scanner/telnet/telnet_login\nauxiliary/scanner/smb/smb_login\nauxiliary/scanner/mssql/mssql_login\nauxiliary/scanner/mysql/mysql_login\nauxiliary/scanner/oracle/oracle_login\nauxiliary/scanner/postgres/postgres_login\nauxiliary/scanner/vnc/vnc_login\nauxiliary/scanner/pcanywhere/pcanywhere_login\nauxiliary/scanner/snmp/snmp_login\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;使用方法\&#34;&gt;使用方法&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# msfconsole\n\n&amp;gt; use &amp;lt;模块路径&amp;gt;\n&amp;gt; show options\n&amp;gt; set &amp;lt;option&amp;gt; &amp;lt;value&amp;gt;\n&amp;gt; run\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;msf-zhong-shi-yong-mei-ju-mo-kuai-jin-xing-ge-chong-fu-wu-deng-lu-de-po-jie&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;MSF中使用枚举模块进行各种服务登陆的破解&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;安全工具&#34;,&#34;slug&#34;:&#34;tdcjZJ8GF&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/tdcjZJ8GF/&#34;},{&#34;name&#34;:&#34;信息安全&#34;,&#34;slug&#34;:&#34;a5GDIyqF3&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/a5GDIyqF3/&#34;}],&#34;date&#34;:&#34;2021-07-16 10:15:07&#34;,&#34;dateFormat&#34;:&#34;2021-07-16&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/msf-zhong-shi-yong-mei-ju-mo-kuai-jin-xing-ge-chong-fu-wu-deng-lu-de-po-jie/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:26000,&#34;words&#34;:76,&#34;minutes&#34;:1},&#34;description&#34;:&#34;模块路径列表\nauxiliary/scanner/ftp/ftp_login\nauxiliary/scanner/ssh/ssh_login\nauxiliary/scanner/telnet/telnet_login\nauxiliary/s...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%A8%A1%E5%9D%97%E8%B7%AF%E5%BE%84%E5%88%97%E8%A1%A8\&#34;&gt;模块路径列表&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95\&#34;&gt;使用方法&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;支持的破解协议\&#34;&gt;支持的破解协议&lt;/h3&gt;\n&lt;h4 id=\&#34;afpcisco-aaacisco身份验证cisco启用cvsfirebirdftphttp-form-gethttp-form-posthttp-gethttp-headhttp-proxyhttps-form-gethttps-form-posthttps-gethttps-headhttp-proxyicqimapircldapms-sqlmysqlncpnntporacle-listeneroracle-sidoraclepc-anywhere-pcnfspop3postgresrdprexecrloginrshsap-r3sipsmbsmtpsmtp枚举snmpsocks5sshv1和v2subversionteamspeakts2telnetvmware-auth-vnc和xmpp\&#34;&gt;AFP，Cisco AAA，Cisco身份验证，Cisco启用，CVS，Firebird，FTP，HTTP-FORM-GET，HTTP-FORM-POST，HTTP-GET，HTTP-HEAD，HTTP-PROXY，HTTPS-FORM- GET，HTTPS-FORM-POST，HTTPS-GET，HTTPS-HEAD，HTTP-Proxy，ICQ，IMAP，IRC，LDAP，MS-SQL，MYSQL，NCP，NNTP，Oracle Listener，Oracle SID，Oracle，PC-Anywhere， PCNFS，POP3，POSTGRES，RDP，Rexec，Rlogin，Rsh，SAP / R3，SIP，SMB，SMTP，SMTP枚举，SNMP，SOCKS5，SSH（v1和v2），Subversion，Teamspeak（TS2），Telnet，VMware-Auth ，VNC和XMPP。&lt;/h4&gt;\n&lt;h3 id=\&#34;参数列表\&#34;&gt;参数列表&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;-R：继续从上一次进度接着破解\n-S：大写，采用SSL链接\n-s  &amp;lt;PORT&amp;gt;：小写，可通过这个参数指定非默认端口\n-l  &amp;lt;LOGIN&amp;gt;：指定破解的用户，对特定用户破解\n-L  &amp;lt;FILE&amp;gt;：指定用户名字典\n-p  &amp;lt;PASS&amp;gt;：小写，指定密码破解，少用，一般是采用密码字典\n-P  &amp;lt;FILE&amp;gt;：大写，指定密码字典\n-e  &amp;lt;ns&amp;gt;：可选选项，n：空密码试探，s：使用指定用户和密码试探\n-C  &amp;lt;FILE&amp;gt;：使用冒号分割格式，例如“登录名:密码”来代替 -L/-P 参数\n-M  &amp;lt;FILE&amp;gt;：指定目标列表文件一行一条\n-o  &amp;lt;FILE&amp;gt;：指定结果输出文件\n-f ：在使用-M参数以后，找到第一对登录名或者密码的时候中止破解\n-t &amp;lt;TASKS&amp;gt;：同时运行的线程数，默认为16\n-w &amp;lt;TIME&amp;gt;：设置最大超时的时间，单位秒，默认是30s\n-v / -V：显示详细过程\nserver：目标ip\nservice：指定服务名，支持的服务和协议：telnet ftp pop3[-ntlm] imap[-ntlm] smb smbnt http[s]-{head|get} http-{get|post}-form http-proxy cisco cisco-enable vnc ldap2 ldap3 mssql mysql oracle-listener postgres nntp socks5 rexec rlogin pcnfs snmp rsh cvs svn icq sapr3 ssh2 smtp-auth[-ntlm] pcanywhere teamspeak sip vmauthd firebird ncp afp等等\nOPT：可选项\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;使用场景\&#34;&gt;使用场景&lt;/h3&gt;\n&lt;h3 id=\&#34;破解ssh\&#34;&gt;破解SSH&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# hydra -L users.txt -P password.txt -t 1 -vV -e ns 192.168.1.104 ssh\n# hydra -L users.txt -P password.txt -t 1 -vV -e ns -o save.log 192.168.1.104 ssh\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;破解ftp\&#34;&gt;破解FTP&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# hydra ip ftp -l 用户名 -P 密码字典 -t 线程(默认16) -vV\n# hydra ip ftp -l 用户名 -P 密码字典 -e ns -vV\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;破解http\&#34;&gt;破解HTTP&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;// get 方式提交，破解web登陆\n# hydra -l 用户名 -p 密码字典 -t 线程 -vV -e ns ip http-get /admin/\n# hydra -l 用户名 -p 密码字典 -t 线程 -vV -e ns -f ip http-get /admin/index.php\n\n// post 方式提交(这里有两种，根据实际情况来构成命令)\n// 需要提前采集认证通信时的数据包，以便确定参数名称\n# hydra -l admin -P pass.lst -o ok.lst -t 1 -f 127.0.0.1 http-post-form &amp;quot;index.php:name=^USER^&amp;amp;pwd=^PASS^:&amp;lt;title&amp;gt;invalido&amp;lt;/title&amp;gt;&amp;quot;\n# hydra -L user.txt \\\n\t\t\t-P passwd.txt \\\n\t\t\t-o http_get.txt \\\n\t\t\t-vV 10.96.10.208 \\\n\t\t\thttp-get-form  &amp;quot;/vulnerabilities/brute/:username=^USER^&amp;amp;password=^PASS^&amp;amp;Login=Login:F=Username and/or password incorrect:H=Cookie: PHPSESSID=nvvrgk2f84qhnh43cm28pt42n6; security=low&amp;quot; \\\n\t\t\t-t 3\nUSER^和^\nPASS^代表是攻击载荷，\nF=后面是代表密码错误时的关键字符串 ，\nH后面是cookie信息\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;破解https\&#34;&gt;破解HTTPS&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# hydra -m /index.php -l muts -P pass.txt 10.36.16.18 https\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;破解http-proxy\&#34;&gt;破解http-proxy&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# hydra -l admin -P pass.txt http-proxy://10.36.16.18\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;破解smb\&#34;&gt;破解SMB&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# hydra -l administrator -P pass.txt 10.36.16.18 smb\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;破解3389远程登陆\&#34;&gt;破解3389远程登陆&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# hydra ip rdp -l administrator -P pass.txt -V\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;hydra-bao-li-po-jie-gong-ju-jian-dan-shi-yong-shuo-ming&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Hydra暴力破解工具简单使用说明&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;安全工具&#34;,&#34;slug&#34;:&#34;tdcjZJ8GF&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/tdcjZJ8GF/&#34;},{&#34;name&#34;:&#34;信息安全&#34;,&#34;slug&#34;:&#34;a5GDIyqF3&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/a5GDIyqF3/&#34;}],&#34;date&#34;:&#34;2021-07-16 08:39:37&#34;,&#34;dateFormat&#34;:&#34;2021-07-16&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/hydra-bao-li-po-jie-gong-ju-jian-dan-shi-yong-shuo-ming/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;4 min read&#34;,&#34;time&#34;:226000,&#34;words&#34;:781,&#34;minutes&#34;:4},&#34;description&#34;:&#34;支持的破解协议\nAFP，Cisco AAA，Cisco身份验证，Cisco启用，CVS，Firebird，FTP，HTTP-FORM-GET，HTTP-FORM-POST，HTTP-GET，HTTP-HEAD，HTTP-PROXY，HTTP...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%94%AF%E6%8C%81%E7%9A%84%E7%A0%B4%E8%A7%A3%E5%8D%8F%E8%AE%AE\&#34;&gt;支持的破解协议&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#afpcisco-aaacisco%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81cisco%E5%90%AF%E7%94%A8cvsfirebirdftphttp-form-gethttp-form-posthttp-gethttp-headhttp-proxyhttps-form-gethttps-form-posthttps-gethttps-headhttp-proxyicqimapircldapms-sqlmysqlncpnntporacle-listeneroracle-sidoraclepc-anywhere-pcnfspop3postgresrdprexecrloginrshsap-r3sipsmbsmtpsmtp%E6%9E%9A%E4%B8%BEsnmpsocks5sshv1%E5%92%8Cv2subversionteamspeakts2telnetvmware-auth-vnc%E5%92%8Cxmpp\&#34;&gt;AFP，Cisco AAA，Cisco身份验证，Cisco启用，CVS，Firebird，FTP，HTTP-FORM-GET，HTTP-FORM-POST，HTTP-GET，HTTP-HEAD，HTTP-PROXY，HTTPS-FORM- GET，HTTPS-FORM-POST，HTTPS-GET，HTTPS-HEAD，HTTP-Proxy，ICQ，IMAP，IRC，LDAP，MS-SQL，MYSQL，NCP，NNTP，Oracle Listener，Oracle SID，Oracle，PC-Anywhere， PCNFS，POP3，POSTGRES，RDP，Rexec，Rlogin，Rsh，SAP / R3，SIP，SMB，SMTP，SMTP枚举，SNMP，SOCKS5，SSH（v1和v2），Subversion，Teamspeak（TS2），Telnet，VMware-Auth ，VNC和XMPP。&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8F%82%E6%95%B0%E5%88%97%E8%A1%A8\&#34;&gt;参数列表&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF\&#34;&gt;使用场景&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%A0%B4%E8%A7%A3ssh\&#34;&gt;破解SSH&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%A0%B4%E8%A7%A3ftp\&#34;&gt;破解FTP&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%A0%B4%E8%A7%A3http\&#34;&gt;破解HTTP&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%A0%B4%E8%A7%A3https\&#34;&gt;破解HTTPS&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%A0%B4%E8%A7%A3http-proxy\&#34;&gt;破解http-proxy&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%A0%B4%E8%A7%A3smb\&#34;&gt;破解SMB&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%A0%B4%E8%A7%A33389%E8%BF%9C%E7%A8%8B%E7%99%BB%E9%99%86\&#34;&gt;破解3389远程登陆&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;安装方式\&#34;&gt;安装方式&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;// 源码使用\n# git clone https://github.com/aboul3la/Sublist3r.git\n# cd Sublist3r\n# pip install -r requirements.txt\n\n// Kali Linux安装\n# apt update\n# apt install sublist3r\n# sublist3r --help\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;工具帮助信息\&#34;&gt;工具帮助信息&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;usage: sublist3r.py [-h] -d DOMAIN [-b [BRUTEFORCE]] [-p PORTS] [-v [VERBOSE]] [-t THREADS] [-e ENGINES] [-o OUTPUT] [-n]\n\nOPTIONS:\n  -h, --help            show this help message and exit\n  -d DOMAIN, --domain DOMAIN\n                        Domain name to enumerate it&#39;s subdomains\n  -b [BRUTEFORCE], --bruteforce [BRUTEFORCE]\n                        Enable the subbrute bruteforce module\n  -p PORTS, --ports PORTS\n                        Scan the found subdomains against specified tcp ports\n  -v [VERBOSE], --verbose [VERBOSE]\n                        Enable Verbosity and display results in realtime\n  -t THREADS, --threads THREADS\n                        Number of threads to use for subbrute bruteforce\n  -e ENGINES, --engines ENGINES\n                        Specify a comma-separated list of search engines\n  -o OUTPUT, --output OUTPUT\n                        Save the results to text file\n  -n, --no-color        Output without color\n\nExample: python3 /usr/lib/python3/dist-packages/sublist3r.py -d google.com\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;使用场景\&#34;&gt;使用场景&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;// 扫描子域名\n# sublist3r -d qq.com\n\n// 扫描子域名，并显示开放了80和443端口的子域名\n# sublist3r -d qq.com -p 80, 443\n\n// 输出到文件\n# sublist3r -d qq.com -o filename.txt\n\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;sublist3r-zi-yu-ming-sao-miao-gong-ju-shi-yong-shuo-ming&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Sublist3r子域名扫描工具使用说明&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;安全工具&#34;,&#34;slug&#34;:&#34;tdcjZJ8GF&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/tdcjZJ8GF/&#34;},{&#34;name&#34;:&#34;信息安全&#34;,&#34;slug&#34;:&#34;a5GDIyqF3&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/a5GDIyqF3/&#34;}],&#34;date&#34;:&#34;2021-07-15 10:54:45&#34;,&#34;dateFormat&#34;:&#34;2021-07-15&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/sublist3r-zi-yu-ming-sao-miao-gong-ju-shi-yong-shuo-ming/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;2 min read&#34;,&#34;time&#34;:71000,&#34;words&#34;:214,&#34;minutes&#34;:2},&#34;description&#34;:&#34;安装方式\n// 源码使用\n# git clone https://github.com/aboul3la/Sublist3r.git\n# cd Sublist3r\n# pip install -r requirements.txt\n\n// ...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%AE%89%E8%A3%85%E6%96%B9%E5%BC%8F\&#34;&gt;安装方式&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%B7%A5%E5%85%B7%E5%B8%AE%E5%8A%A9%E4%BF%A1%E6%81%AF\&#34;&gt;工具帮助信息&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF\&#34;&gt;使用场景&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;安装方法\&#34;&gt;安装方法&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# git clone https://github.com/lijiejie/subDomainsBrute.git\n\n// python3 用户\n# pip3 install aiodns\n// python2 用户\n# pip install dnspython gevent\n\n// 字典路径\n# cd subDomainsBrute/dict\n# ls\ndns_servers.txt  next_sub_full.txt  next_sub.txt  subnames_all_5_letters.txt  subnames_full.txt  subnames.txt\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;工具帮助说明\&#34;&gt;工具帮助说明&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;Usage: subDomainsBrute.py [options] target.com\n\nOptions:\n  --version             show program&#39;s version number and exit\n  -h, --help            show this help message and exit\n  -f FILE               File contains new line delimited subs, default is\n                        subnames.txt.\n  --full                Full scan, NAMES FILE subnames_full.txt will be used\n                        to brute\n  -i, --ignore-intranet\n                        Ignore domains pointed to private IPs\n  -w, --wildcard        Force scan after wildcard test fail\n  -t THREADS, --threads=THREADS\n                        Num of scan threads, 200 by default\n  -p PROCESS, --process=PROCESS\n                        Num of scan Process, 6 by default\n  -o OUTPUT, --output=OUTPUT\n                        Output file name. default is {target}.txt\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;使用场景\&#34;&gt;使用场景&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;// 简单扫描\n# python3 subDomainsBrute.py qq.com\n\n// 全量扫描,full参数会使用字典路径下的subnames_full.txt\n# python3 subDoaminBrute.py --full qq.com\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;subdomainbrutepy-gong-ju-de-jian-dan-shi-yong-shuo-ming&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;SubDomainBrute.py工具的简单使用说明&#34;,&#34;tags&#34;:[{&#34;index&#34;:-1,&#34;name&#34;:&#34;安全工具&#34;,&#34;slug&#34;:&#34;tdcjZJ8GF&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/tdcjZJ8GF/&#34;},{&#34;name&#34;:&#34;信息安全&#34;,&#34;slug&#34;:&#34;a5GDIyqF3&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/a5GDIyqF3/&#34;}],&#34;date&#34;:&#34;2021-07-15 10:02:42&#34;,&#34;dateFormat&#34;:&#34;2021-07-15&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/subdomainbrutepy-gong-ju-de-jian-dan-shi-yong-shuo-ming/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;2 min read&#34;,&#34;time&#34;:61000,&#34;words&#34;:184,&#34;minutes&#34;:2},&#34;description&#34;:&#34;安装方法\n# git clone https://github.com/lijiejie/subDomainsBrute.git\n\n// python3 用户\n# pip3 install aiodns\n// python2 用户\n# pi...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%AE%89%E8%A3%85%E6%96%B9%E6%B3%95\&#34;&gt;安装方法&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%B7%A5%E5%85%B7%E5%B8%AE%E5%8A%A9%E8%AF%B4%E6%98%8E\&#34;&gt;工具帮助说明&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF\&#34;&gt;使用场景&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;1-安装\&#34;&gt;1. 安装&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# yum -y install chrony\n# systemctl enable chronyd\n# systemctl start chronyd\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;2配置\&#34;&gt;2.配置&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# vi /etc/chrony.conf\n\n# 使用 pool.ntp.org 项目中的公共服务器。以server开，理论上想添加多少时间服务器都可以。\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\nserver 0.centos.pool.ntp.org iburst\nserver 1.centos.pool.ntp.org iburst\nserver 2.centos.pool.ntp.org iburst\nserver 3.centos.pool.ntp.org iburst\n\n# 根据实际时间计算出服务器增减时间的比率，然后记录到一个文件中，在系统重启后为系统做出最佳时间补偿调整。\n# Record the rate at which the system clock gains/losses time.\ndriftfile /var/lib/chrony/drift\n\n# 如果系统时钟的偏移量大于1秒，则允许系统时钟在前三次更新中步进。\n# Allow the system clock to be stepped in the first three updates if its offset is larger than 1 second.\nmakestep 1.0 3\n\n# 启用实时时钟（RTC）的内核同步。\n# Enable kernel synchronization of the real-time clock (RTC).\nrtcsync\n\n# 通过使用 hwtimestamp 指令启用硬件时间戳\n# Enable hardware timestamping on all interfaces that support it.\n#hwtimestamp *\n\n# Increase the minimum number of selectable sources required to adjust the system clock.\n#minsources 2\n\n# 指定 NTP 客户端地址，以允许或拒绝连接到扮演时钟服务器的机器\n# Allow NTP client access from local network.\n#allow 192.168.0.0/16\n\n# Serve time even if not synchronized to a time source.\n#local stratum 10\n\n# 指定包含 NTP 身份验证密钥的文件。\n# Specify file containing keys for NTP authentication.\n#keyfile /etc/chrony.keys\n\n# 指定日志文件的目录。\n# Specify directory for log files.\nlogdir /var/log/chrony\n\n# 选择日志文件要记录的信息。\n# Select which information is logged.\n#log measurements statistics tracking\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;3手工同步\&#34;&gt;3.手工同步&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 查看 ntp_servers\nchronyc sources -v\n\n# 查看 ntp_servers 状态\nchronyc sourcestats -v\n\n# 查看 ntp_servers 是否在线\nchronyc activity -v\n\n# 查看 ntp 详细信息\nchronyc tracking -v\n\n# 手工进行同步\nchronyc -a makestep\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;4修改时区\&#34;&gt;4.修改时区&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 查看日期时间、时区及 NTP 状态\ntimedatectl\n\n# 查看时区列表\ntimedatectl list-timezones\ntimedatectl list-timezones |  grep  -E &amp;quot;Asia/S.*&amp;quot;\n\n# 修改时区\ntimedatectl set-timezone Asia/Shanghai\n\n# 修改日期时间（可以只修改其中一个）\ntimedatectl set-time &amp;quot;2019-09-19 15:50:20&amp;quot;\n\n# 开启 NTP\ntimedatectl set-ntp true/flase\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;centos-78-shi-yong-chrony-jin-xing-shi-jian-tong-bu-pei-zhi&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Centos 7/8 使用chrony进行时间同步配置&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Linux&#34;,&#34;slug&#34;:&#34;U7XkBZwyl&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/U7XkBZwyl/&#34;}],&#34;date&#34;:&#34;2021-07-14 09:25:52&#34;,&#34;dateFormat&#34;:&#34;2021-07-14&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/centos-78-shi-yong-chrony-jin-xing-shi-jian-tong-bu-pei-zhi/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;3 min read&#34;,&#34;time&#34;:150000,&#34;words&#34;:525,&#34;minutes&#34;:3},&#34;description&#34;:&#34;1. 安装\n# yum -y install chrony\n# systemctl enable chronyd\n# systemctl start chronyd\n\n2.配置\n# vi /etc/chrony.conf\n\n# 使用 poo...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#1-%E5%AE%89%E8%A3%85\&#34;&gt;1. 安装&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#2%E9%85%8D%E7%BD%AE\&#34;&gt;2.配置&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#3%E6%89%8B%E5%B7%A5%E5%90%8C%E6%AD%A5\&#34;&gt;3.手工同步&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#4%E4%BF%AE%E6%94%B9%E6%97%B6%E5%8C%BA\&#34;&gt;4.修改时区&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;echo &amp;quot;StrictHostKeyChecking no&amp;quot; &amp;gt;~/.ssh/config\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;ru-he-bi-mian-zai-di-yi-ci-ssh-deng-lu-shi-shu-ru-yes-ti-shi-fu&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;如何避免在第一次SSH登陆时输入yes提示符&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Linux&#34;,&#34;slug&#34;:&#34;U7XkBZwyl&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/U7XkBZwyl/&#34;}],&#34;date&#34;:&#34;2021-06-23 11:46:19&#34;,&#34;dateFormat&#34;:&#34;2021-06-23&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/ru-he-bi-mian-zai-di-yi-ci-ssh-deng-lu-shi-shu-ru-yes-ti-shi-fu/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:3000,&#34;words&#34;:8,&#34;minutes&#34;:1},&#34;description&#34;:&#34;echo &amp;quot;StrictHostKeyChecking no&amp;quot; &amp;gt;~/.ssh/config\n\n&#34;,&#34;toc&#34;:&#34;&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;概念\&#34;&gt;概念&lt;/h3&gt;\n&lt;h5 id=\&#34;在kubernetes集群中pod是所有业务类型的基础也是k8s管理的最小单位级它是一个或多个容器的组合-这些容器共享存储-网络和命名空间以及如何运行的规范-在pod中所有容器都被同一安排和调度并运行在共享的上下文中-对于具体应用而言pod是它们的逻辑主机pod包含业务相关的多个应用容器\&#34;&gt;在Kubernetes集群中，Pod是所有业务类型的基础，也是K8S管理的最小单位级，它是一个或多个容器的组合。这些容器共享存储、网络和命名空间，以及如何运行的规范。在Pod中，所有容器都被同一安排和调度，并运行在共享的上下文中。对于具体应用而言，Pod是它们的逻辑主机，Pod包含业务相关的多个应用容器。&lt;/h5&gt;\n&lt;h3 id=\&#34;两个注意点\&#34;&gt;两个注意点&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-python\&#34;&gt;1.网络:\n  每一个Pod都会被指派一个唯一的Ip地址，在Pod中的每一个容器共享网络命名空间，包括Ip地址和网络端口。在同一个Pod中的容器可以同locahost进行互相通信。当Pod中的容器需要与Pod外的实体进行通信时，则需要通过端口等共享的网络资源。\n\n2.存储:\n  Pod能够被指定共享存储卷的集合，在Pod中所有的容器能够访问共享存储卷，允许这些容器共享数据。存储卷也允许在一个Pod持久化数据，以防止其中的容器需要被重启。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;pod的生命周期\&#34;&gt;Pod的生命周期&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shel\&#34;&gt;一共有4种状态：\n\n1. Pending：APIserver已经创建该server，但pod中有一个或多个容器的镜像还未创建，可能在下载中；\n2. Running：Pod中的所有容器都已创建，且至少有一个容器处于运行状态，正在启动或重启状态；\n3. Failed：Pod内所有容器都已退出，其中至少有一个容器退出失败；\n4. Unknown：由于某种原因无法获取Pod的状态比如网络问题；\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;pod的重启策略\&#34;&gt;Pod的重启策略&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-py\&#34;&gt;重启策略对同一个Pod中的所有容器起作用，容器的重启由Node上的kubelet执行，支持三种策略，在配置文件中通过restartPolicy字段设置：\n1. Always：只要退出就会重启\n2. OnFailure：只有在失败退出时，才会重启\n3. Never：只要退出，就不再重启\n\n注意，这里的重启是指在Pod的宿主Node上进行本地重启，而不是调度到其它Node上。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;健康检查\&#34;&gt;健康检查&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 两种探针类型：\n一、LivenessProbe探针：  判断容器是否存活（running）\n1.ExecAction，在容器内部执行一个命令，状态返回码为0，表示健康，示例：\napiVersion: v1\nkind: Pod\nmetadata:\n name: liveness\nspec:\n  containers:\n  - name: liveness\n    image: liveness\n    args: \n    - /bin/sh\n    - -c\n    - echo ok &amp;gt; /tmp/healthy: sleep 10; rm - rf /tmp/healthy; sleep 600\n    livenessProbe:\n      exec:\n        command:\n        - cat\n        - /tmp/health\n    initialDelaySeconds: 15\n    timeoutSeconds: 1\n    \n2.TcpAction，通过IP和PORT，如果能够和容器建立连接则表示容器健康，示例：\napiVersion: v1\nkind: Pod\nmetadata:\n name: pod-with-healthcheck\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n    livenessProbe:\n      tcpSocket:\n        port: 80\n    initialDelaySeconds: 15\n    timeoutSeconds: 1\n3.HttpGetAction，发送get请求，返回码在200-400之间表示健康， 示例：\napiVersion: v1\nkind: Pod\nmetadata:\n name: pod-with-healthcheck\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n    livenessProbe:\n      httpGet:\n        path: /_status/healthz  //请求路径\n        port: 80\n    initialDelaySeconds: 15\n    timeoutSeconds: 1\n    \n二、ReadinessProbe探针： 用于判断容器是否启动完成（ready）\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;pod的调度\&#34;&gt;Pod的调度&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 定向调度，nodeSelector\n1.首先通过kubectl给node打上标签：\n格式： kubectl label nodes &amp;lt;node-name&amp;gt; &amp;lt;label-key&amp;gt;=&amp;lt;label-value&amp;gt;\nkubectl label nodes node1 zone=north\n\n2.在pod定义里选择某个node\napiVersion: v1\nkind: Pod\nmetadata:\nname: pod-with-healthcheck\nspec:\ncontainers:\n- name: nginx\n  image: nginx\n  ports:\n  - containerPort: 80\nnodeSelector:\n  zone: north\n\n# 亲和性和非亲和性\n一、Node affinity（节点亲和性）\n1. requiredDuringSchedulingIgnoredDuringExecution：\n可认为一种强制限制，如果 Node 的标签发生了变化导致其没有符合 Pod 的调度要求节点，那么pod调度就会失败。\n2.preferredDuringSchedulingIgnoredDuringExecution：\n软限或偏好，同样如果 Node 的标签发生了变化导致其不再符合 pod 的调度要求，pod 依然会调度运行。\n\n二、Pod Affinity（Pod亲和性）\n    podAffinity用于调度pod可以和哪些pod部署在同一拓扑结构之下。而podAntiAffinity相反，其用于规定pod不可以和哪些pod部署在同一拓扑结构下。通过pod affinity与anti-affinity来解决pod和pod之间的关系。\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;k8s-pod-jian-dan-jie-shao&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;K8s-Pod简单介绍&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Kubernetes&#34;,&#34;slug&#34;:&#34;wZhxXn6g4&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/wZhxXn6g4/&#34;}],&#34;date&#34;:&#34;2021-06-08 15:06:03&#34;,&#34;dateFormat&#34;:&#34;2021-06-08&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/k8s-pod-jian-dan-jie-shao/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;4 min read&#34;,&#34;time&#34;:239000,&#34;words&#34;:1003,&#34;minutes&#34;:4},&#34;description&#34;:&#34;概念\n在Kubernetes集群中，Pod是所有业务类型的基础，也是K8S管理的最小单位级，它是一个或多个容器的组合。这些容器共享存储、网络和命名空间，以及如何运行的规范。在Pod中，所有容器都被同一安排和调度，并运行在共享的上下文中。对于...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%A6%82%E5%BF%B5\&#34;&gt;概念&lt;/a&gt;&lt;br&gt;\n*\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9C%A8kubernetes%E9%9B%86%E7%BE%A4%E4%B8%ADpod%E6%98%AF%E6%89%80%E6%9C%89%E4%B8%9A%E5%8A%A1%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B9%9F%E6%98%AFk8s%E7%AE%A1%E7%90%86%E7%9A%84%E6%9C%80%E5%B0%8F%E5%8D%95%E4%BD%8D%E7%BA%A7%E5%AE%83%E6%98%AF%E4%B8%80%E4%B8%AA%E6%88%96%E5%A4%9A%E4%B8%AA%E5%AE%B9%E5%99%A8%E7%9A%84%E7%BB%84%E5%90%88-%E8%BF%99%E4%BA%9B%E5%AE%B9%E5%99%A8%E5%85%B1%E4%BA%AB%E5%AD%98%E5%82%A8-%E7%BD%91%E7%BB%9C%E5%92%8C%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E4%BB%A5%E5%8F%8A%E5%A6%82%E4%BD%95%E8%BF%90%E8%A1%8C%E7%9A%84%E8%A7%84%E8%8C%83-%E5%9C%A8pod%E4%B8%AD%E6%89%80%E6%9C%89%E5%AE%B9%E5%99%A8%E9%83%BD%E8%A2%AB%E5%90%8C%E4%B8%80%E5%AE%89%E6%8E%92%E5%92%8C%E8%B0%83%E5%BA%A6%E5%B9%B6%E8%BF%90%E8%A1%8C%E5%9C%A8%E5%85%B1%E4%BA%AB%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E4%B8%AD-%E5%AF%B9%E4%BA%8E%E5%85%B7%E4%BD%93%E5%BA%94%E7%94%A8%E8%80%8C%E8%A8%80pod%E6%98%AF%E5%AE%83%E4%BB%AC%E7%9A%84%E9%80%BB%E8%BE%91%E4%B8%BB%E6%9C%BApod%E5%8C%85%E5%90%AB%E4%B8%9A%E5%8A%A1%E7%9B%B8%E5%85%B3%E7%9A%84%E5%A4%9A%E4%B8%AA%E5%BA%94%E7%94%A8%E5%AE%B9%E5%99%A8\&#34;&gt;在Kubernetes集群中，Pod是所有业务类型的基础，也是K8S管理的最小单位级，它是一个或多个容器的组合。这些容器共享存储、网络和命名空间，以及如何运行的规范。在Pod中，所有容器都被同一安排和调度，并运行在共享的上下文中。对于具体应用而言，Pod是它们的逻辑主机，Pod包含业务相关的多个应用容器。&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%A4%E4%B8%AA%E6%B3%A8%E6%84%8F%E7%82%B9\&#34;&gt;两个注意点&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#pod%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F\&#34;&gt;Pod的生命周期&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#pod%E7%9A%84%E9%87%8D%E5%90%AF%E7%AD%96%E7%95%A5\&#34;&gt;Pod的重启策略&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5\&#34;&gt;健康检查&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#pod%E7%9A%84%E8%B0%83%E5%BA%A6\&#34;&gt;Pod的调度&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;名词解释\&#34;&gt;名词解释&lt;/h3&gt;\n&lt;h5 id=\&#34;namespace是对一组资源和对象的抽象集合比如可用来将系统内部的对象划分为不同的项目或用户组-常见的podsservicesrc和deployments等都是属于某一个namespace的默认是default而nodepersistentvolumns等则不属于任何namespace\&#34;&gt;Namespace是对一组资源和对象的抽象集合，比如可用来将系统内部的对象划分为不同的项目或用户组。常见的pods，services，rc和deployments等都是属于某一个namespace的（默认是default），而node，persistentVolumns等则不属于任何namespace。&lt;/h5&gt;\n&lt;h3 id=\&#34;namespace相关操作\&#34;&gt;Namespace相关操作&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;kubectl可以通过–namespace或者-n选项指定namespace。如果不指定，默认为default。查看操作下,也可以通过设置–all-namespace=true来查看所有namespace下的资源。\n\n# 查询ns\n$ kubectl get namespaces\nNAME          STATUS    AGE\ndefault       Active    11d\nkube-system   Active    11d\n\n# 查询哪些资源位于namespace中\nkubectl api-resources --namespaced=true\n# 查看哪些资源不在命令空间\nkubectl api-resources --namespaced=false\n\n# 指定ns查询对应ns中的资源情况\nkubectl get pods -n kube-system\n\n# 创建\n# 1.命令行直接创建\n$ kubectl create namespace new-namespace\n\n# 2.通过文件创建\n$ cat my-namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: new-namespace\n\n$ kubectl create -f ./my-namespace.yaml\n\n# 删除，即删除该ns下所有资源\n# 注意：default和kube-system命名空间不能删除\n$ kubectl delete namespaces new-namespace\n\n# 切换ns\nkubectl config set-context --current --namespace=kube-system\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;关于namespace是否隔离网络\&#34;&gt;关于Namespace是否隔离网络&lt;/h3&gt;\n&lt;h5 id=\&#34;一般情况下默认是不会隔离网络流量的除非对某个namespace设置了安全策略\&#34;&gt;一般情况下，默认是不会隔离网络流量的，除非对某个namespace设置了安全策略。&lt;/h5&gt;\n&#34;,&#34;fileName&#34;:&#34;namespace-ji-ben-zhi-shi&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;K8s-Namespace基本知识&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Kubernetes&#34;,&#34;slug&#34;:&#34;wZhxXn6g4&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/wZhxXn6g4/&#34;}],&#34;date&#34;:&#34;2021-06-08 15:03:54&#34;,&#34;dateFormat&#34;:&#34;2021-06-08&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/namespace-ji-ben-zhi-shi/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;2 min read&#34;,&#34;time&#34;:78000,&#34;words&#34;:312,&#34;minutes&#34;:2},&#34;description&#34;:&#34;名词解释\nNamespace是对一组资源和对象的抽象集合，比如可用来将系统内部的对象划分为不同的项目或用户组。常见的pods，services，rc和deployments等都是属于某一个namespace的（默认是default），而no...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A\&#34;&gt;名词解释&lt;/a&gt;&lt;br&gt;\n*\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#namespace%E6%98%AF%E5%AF%B9%E4%B8%80%E7%BB%84%E8%B5%84%E6%BA%90%E5%92%8C%E5%AF%B9%E8%B1%A1%E7%9A%84%E6%8A%BD%E8%B1%A1%E9%9B%86%E5%90%88%E6%AF%94%E5%A6%82%E5%8F%AF%E7%94%A8%E6%9D%A5%E5%B0%86%E7%B3%BB%E7%BB%9F%E5%86%85%E9%83%A8%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%88%92%E5%88%86%E4%B8%BA%E4%B8%8D%E5%90%8C%E7%9A%84%E9%A1%B9%E7%9B%AE%E6%88%96%E7%94%A8%E6%88%B7%E7%BB%84-%E5%B8%B8%E8%A7%81%E7%9A%84podsservicesrc%E5%92%8Cdeployments%E7%AD%89%E9%83%BD%E6%98%AF%E5%B1%9E%E4%BA%8E%E6%9F%90%E4%B8%80%E4%B8%AAnamespace%E7%9A%84%E9%BB%98%E8%AE%A4%E6%98%AFdefault%E8%80%8Cnodepersistentvolumns%E7%AD%89%E5%88%99%E4%B8%8D%E5%B1%9E%E4%BA%8E%E4%BB%BB%E4%BD%95namespace\&#34;&gt;Namespace是对一组资源和对象的抽象集合，比如可用来将系统内部的对象划分为不同的项目或用户组。常见的pods，services，rc和deployments等都是属于某一个namespace的（默认是default），而node，persistentVolumns等则不属于任何namespace。&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#namespace%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C\&#34;&gt;Namespace相关操作&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%85%B3%E4%BA%8Enamespace%E6%98%AF%E5%90%A6%E9%9A%94%E7%A6%BB%E7%BD%91%E7%BB%9C\&#34;&gt;关于Namespace是否隔离网络&lt;/a&gt;&lt;br&gt;\n*\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%80%E8%88%AC%E6%83%85%E5%86%B5%E4%B8%8B%E9%BB%98%E8%AE%A4%E6%98%AF%E4%B8%8D%E4%BC%9A%E9%9A%94%E7%A6%BB%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%E7%9A%84%E9%99%A4%E9%9D%9E%E5%AF%B9%E6%9F%90%E4%B8%AAnamespace%E8%AE%BE%E7%BD%AE%E4%BA%86%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5\&#34;&gt;一般情况下，默认是不会隔离网络流量的，除非对某个namespace设置了安全策略。&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;安装kubectl\&#34;&gt;安装kubectl&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 注意：安装方法推荐参考官方网站，安装方式随着版本变更会发生变动\n# 下载二进制文件\ncurl -LO &amp;quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&amp;quot;\n# 下载校验文件\ncurl -LO &amp;quot;https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256&amp;quot;\n# 检查下载文件和校验文件是否匹配\necho &amp;quot;$(&amp;lt;kubectl.sha256) kubectl&amp;quot; | sha256sum --check\n# 安装二进制文件\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n# 检查安装是否成功\nkubectl version --client\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;安装minikube\&#34;&gt;安装Minikube&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 下载二进制文件\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\n# 安装二进制文件\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\n# 启动集群，启动之前需要确保系统中有容器运行时，比如docker，kvm，否则集群启动失败\nminikube start\n\n# 若出现：The &amp;quot;docker&amp;quot; driver should not be used with root privileges.\n# 将当前具有sudo权限的用户添加到docker组即可\nsudo usermod -aG docker &amp;lt;username&amp;gt;\n# 激活组的配置，这步必须\nnewgrp docker\n# 再次启动\nminikube start\n# 查看集群信息\nkubectl cluster-info\n\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;shi-yong-minikube-da-jian-ben-di-xue-xi-huan-jing&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;K8s-使用Minikube搭建本地学习环境&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Kubernetes&#34;,&#34;slug&#34;:&#34;wZhxXn6g4&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/wZhxXn6g4/&#34;}],&#34;date&#34;:&#34;2021-06-08 15:02:59&#34;,&#34;dateFormat&#34;:&#34;2021-06-08&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/shi-yong-minikube-da-jian-ben-di-xue-xi-huan-jing/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;2 min read&#34;,&#34;time&#34;:78000,&#34;words&#34;:285,&#34;minutes&#34;:2},&#34;description&#34;:&#34;安装kubectl\n# 注意：安装方法推荐参考官方网站，安装方式随着版本变更会发生变动\n# 下载二进制文件\ncurl -LO &amp;quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%AE%89%E8%A3%85kubectl\&#34;&gt;安装kubectl&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%AE%89%E8%A3%85minikube\&#34;&gt;安装Minikube&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;基本配置示例\&#34;&gt;基本配置示例&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;- hosts: all\n    vars: \n      wss_url: http://10.77.10.125:8545 \n    tasks:\n      - name: &amp;quot;推送配置文件&amp;quot;\n        template: src=/home/fm/ops/scripts/default.yaml dest=/etc/bee/default.yaml\n      - name: &amp;quot;send all scripts&amp;quot;\n        copy:\n          src: &#39;{{ item.src }}&#39;\n          dest: /tmp/\n          owner: root\n          group: root\n          mode: 755\n        with_items:\n          - { src: &#39;/home/fm/ops/scripts/start05.sh&#39; }\n          - { src: &#39;/home/fm/ops/scripts/stop.sh&#39; }\n  \n \n# 使用{{ item.src }}读取with_items中的数组元素，访问需要拷贝的每一个文件即可。\n\n# 检查语法\nansible-playbook --syntax-check example.yaml\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;playbook-zhong-shi-yong-copy-lai-chuan-shu-wen-jian&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Ansible-Playbook中使用copy来传输文件&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Ansible&#34;,&#34;slug&#34;:&#34;a1RiQn9Xn&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/a1RiQn9Xn/&#34;},{&#34;name&#34;:&#34;工具使用&#34;,&#34;slug&#34;:&#34;ETGdbG1UX&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/ETGdbG1UX/&#34;}],&#34;date&#34;:&#34;2021-06-07 17:27:30&#34;,&#34;dateFormat&#34;:&#34;2021-06-07&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/playbook-zhong-shi-yong-copy-lai-chuan-shu-wen-jian/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:33000,&#34;words&#34;:109,&#34;minutes&#34;:1},&#34;description&#34;:&#34;基本配置示例\n- hosts: all\n    vars: \n      wss_url: http://10.77.10.125:8545 \n    tasks:\n      - name: &amp;quot;推送配置文件&amp;quot;\n    ...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B\&#34;&gt;基本配置示例&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;become配置示例\&#34;&gt;become配置示例：&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;- hosts: www.360.com\n  remote_user: zabbix\n  become: yes\n  become_method: su\n  tasks:\n   - selinux:\n        state: disabled\n   - name: disable firewalld\n     shell: systemctl stop firewalld &amp;amp;&amp;amp; systemctl disable firewalld\n \n# become说明\nbecome:        yes  # 是否允许身份切换\nbecome_method: su   # 切换用户身份的方式，有sudo、su、pbrun等方式，默认为sudo\nbecome_user: root   # 切换指定的用户，默认不写，就是root\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;sudo配置解释\&#34;&gt;sudo配置解释&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;hosts                # 指定主机分组，可以取并集，交集等\nremote_user          # 用于指定远程主机上的执行任务的用户，最佳实践是该用户具有sudo权限\nuser                 # 和remote_user相同\nsudo                 # 如果设置为yes，执行该任务组的用户在执行任务的时候，获取root权限，也可以命令行使用-b参数\nsudo_user            # 如果设置user为A，sudo为yes，sudo_user为B时，则A用户在执行任务时会获得B用户的权限，比较麻烦，不推荐\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;playbook-zhong-yong-hu-de-qie-huan-wen-ti&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Ansible-Playbook中用户的切换问题&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Ansible&#34;,&#34;slug&#34;:&#34;a1RiQn9Xn&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/a1RiQn9Xn/&#34;},{&#34;name&#34;:&#34;工具使用&#34;,&#34;slug&#34;:&#34;ETGdbG1UX&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/ETGdbG1UX/&#34;}],&#34;date&#34;:&#34;2021-06-07 17:21:20&#34;,&#34;dateFormat&#34;:&#34;2021-06-07&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/playbook-zhong-yong-hu-de-qie-huan-wen-ti/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:52000,&#34;words&#34;:215,&#34;minutes&#34;:1},&#34;description&#34;:&#34;become配置示例：\n- hosts: www.360.com\n  remote_user: zabbix\n  become: yes\n  become_method: su\n  tasks:\n   - selinux:\n        ...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#become%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B\&#34;&gt;become配置示例：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#sudo%E9%85%8D%E7%BD%AE%E8%A7%A3%E9%87%8A\&#34;&gt;sudo配置解释&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;基本使用方法示例配置\&#34;&gt;基本使用方法，示例配置：&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;tasks:\n  - yum: name={{ item }} state=installed\n    with_items:\n       - httpd\n    tags:\n       - packages\n  - name: copy httpd.conf\n    template: src=templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf\n    tags:\n       - configuration\n  - name: copy index.html\n    template: src=templates/index.html.j2 dest=/var/www/html/index.html\n    tags:\n       - configuration\n  \n \n# 执行部分任务\nansible-playbook example.yml --tags &amp;quot;packages&amp;quot;\n\n# 指定不执行packages部分的任务\nansible-playbook example.yml --skip-tags &amp;quot;configuration&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;特殊的tags\&#34;&gt;特殊的tags&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# always 标签，即使指定执行了某tag的任务，标记为always的任务也会被执行\ntasks:\n  - debug: msg=&amp;quot;Always print this debug message&amp;quot;\n    tags:\n      - always\n  - yum: name={{ item }} state=installed\n    with_items:\n       - httpd\n    tags:\n       - packages\n  - template: src=templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf\n    tags:\n       - configuration\n\n# 这里标记为always的任务也会被执行\nansible-playbook tags_always.yml --tags &amp;quot;packages&amp;quot;\n\n# targged，untagged，all，使用这些标签时，不需要加双引号\ntagged，即执行所有被打标签的任务\nuntagged，即执行所有未被打标签的任务\nall，所有任务\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;playbook-li-yong-tags-zhi-xing-bu-fen-task&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Ansible-Playbook利用tags执行部分task&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Ansible&#34;,&#34;slug&#34;:&#34;a1RiQn9Xn&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/a1RiQn9Xn/&#34;},{&#34;name&#34;:&#34;工具使用&#34;,&#34;slug&#34;:&#34;ETGdbG1UX&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/ETGdbG1UX/&#34;}],&#34;date&#34;:&#34;2021-06-07 17:20:35&#34;,&#34;dateFormat&#34;:&#34;2021-06-07&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/playbook-li-yong-tags-zhi-xing-bu-fen-task/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;2 min read&#34;,&#34;time&#34;:66000,&#34;words&#34;:227,&#34;minutes&#34;:2},&#34;description&#34;:&#34;基本使用方法，示例配置：\ntasks:\n  - yum: name={{ item }} state=installed\n    with_items:\n       - httpd\n    tags:\n       - packages\n...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E7%A4%BA%E4%BE%8B%E9%85%8D%E7%BD%AE\&#34;&gt;基本使用方法，示例配置：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%89%B9%E6%AE%8A%E7%9A%84tags\&#34;&gt;特殊的tags&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;部署方式容器化部署\&#34;&gt;部署方式：容器化部署&lt;/h3&gt;\n&lt;h4 id=\&#34;部署流程\&#34;&gt;部署流程：&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 运行node-exporter监控主机基本信息，访问9100端口进行验证\ndocker run -d --name node \\\n\t-p 9100:9100 \\\n\t-v /proc:/host/proc \\\n\t-v /sys:/host/sys \\\n\t-v /:/rootfs \\\n\t--net=host prom/node-exporter \\\n\t--path.procfs /host/proc \\\n\t--path.sysfs /host/sys \\\n\t--collector.filesystem.ignored-mount-points &amp;quot;^/(sys|proc|dev|host|etc)($|/)&amp;quot;\n\n# 运行cAdvisor监控容器运行状态，访问8080端口进行验证\ndocker run -v /:/rootfs:ro \\\n\t-v /var/run:/var/run/:rw \\\n\t-v /sys:/sys:ro \\\n\t-v /var/lib/docker:/var/lib/docker:ro \\\n\t-p 8080:8080 \\\n\t--detach=true \\\n\t--name=cadvisor \\\n\t--net=host google/cadvisor\n\n# 在监控主节点上部署prometheus server，客户节点无需安装\ndocker run -d -p 9090:9090 --name prometheus --net=host prom/prometheus\n# 将容器中的配置文件拷贝到宿主，进行修改\ndocker cp prometheus:/etc/prometheus/prometheus.yml ./\n# 修改static_configs，指向所有客户节点的9100和8080端口获取数据\nvim prometheus.yml\n\n# 配置更新完成后，删除原prometheus server容器\ndocker rm prometheus -f\n# 重新将本地配置文件映射到容器中，访问9090端口进行验证\ndocker run -d -p 9090:9090 --name prometheus --net=host -v /root/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus\n\n# 部署grafana图形化界面，访问3000端口进行验证\nmkdir grafana-storage\nchmod 777 -R grafana-storage/\ndocker run -d -p 3000:3000 \\\n\t--name grafana \\\n\t-v /root/grafana-storage:/var/lib/grafana \\\n\t-e &amp;quot;GF_SECURITY_ADMIN_PASSWORD=123456&amp;quot; grafana/grafana\n\t\n# grafana模板，打开grafana.com, 点击dashborads，根据数据源和类型选择合适的模板\n\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;shi-yong-prometheus-jian-kong-zhu-ji-docker-rong-qi-yun-xing-zhuang-tai&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Prometheus-使用prometheus监控主机docker容器运行状态&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Prometheus&#34;,&#34;slug&#34;:&#34;R7jEZk-Br&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/R7jEZk-Br/&#34;}],&#34;date&#34;:&#34;2021-06-07 16:27:03&#34;,&#34;dateFormat&#34;:&#34;2021-06-07&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/shi-yong-prometheus-jian-kong-zhu-ji-docker-rong-qi-yun-xing-zhuang-tai/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;2 min read&#34;,&#34;time&#34;:98000,&#34;words&#34;:344,&#34;minutes&#34;:2},&#34;description&#34;:&#34;部署方式：容器化部署\n部署流程：\n# 运行node-exporter监控主机基本信息，访问9100端口进行验证\ndocker run -d --name node \\\n\t-p 9100:9100 \\\n\t-v /proc:/host/proc...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F%E5%AE%B9%E5%99%A8%E5%8C%96%E9%83%A8%E7%BD%B2\&#34;&gt;部署方式：容器化部署&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%83%A8%E7%BD%B2%E6%B5%81%E7%A8%8B\&#34;&gt;部署流程：&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1. 卸载设备\n# umount /dev/md0\n\n2. 停止raid设备\n# mdadm -S /dev/md0  // 停止raid设备\n\n3. 查看属于raid组的设备名称\n# blkid \n\n4. 从raid组中删除硬盘\n# mdadm --misc --zero-superblock /dev/xxx\n\n以下操作可选：\n5. 删除配置文件：rm -f /etc/mdadm.conf\n\n6. 更新/etc/fstab\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;ru-he-chai-chu-linux-ruan-raid-she-bei&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;如何拆除Linux软Raid设备&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Linux&#34;,&#34;slug&#34;:&#34;U7XkBZwyl&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/U7XkBZwyl/&#34;}],&#34;date&#34;:&#34;2021-04-20 16:11:37&#34;,&#34;dateFormat&#34;:&#34;2021-04-20&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/ru-he-chai-chu-linux-ruan-raid-she-bei/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:20000,&#34;words&#34;:74,&#34;minutes&#34;:1},&#34;description&#34;:&#34;1. 卸载设备\n# umount /dev/md0\n\n2. 停止raid设备\n# mdadm -S /dev/md0  // 停止raid设备\n\n3. 查看属于raid组的设备名称\n# blkid \n\n4. 从raid组中删除硬盘\n# md...&#34;,&#34;toc&#34;:&#34;&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;主机发现\&#34;&gt;主机发现&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;以192.168.1.0/24举例\n\nnmap -PE 192.168.1.0/24  # icmp\nnamp -PO 192.168.1.0/24  # ip\nnmap -PS 192.168.1.0/24  # tcp syn\nnmap -PA 192.168.1.0/24  # tcp ack\nnmap -PU 192.168.1.0/24  # udp\nnmap -PY 192.168.1.0/24  # sctp\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;端口扫描\&#34;&gt;端口扫描&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1.SYN Scanning\nnmap -sS 192.168.1.0/24  # 仅发送SYN，返回SYN/ACK应答表示端口开启，返回RST表示端口关闭\n\n2.TCP Scanning\nnmap -sT 192.168.1.0/24  # 建立完整的TCP连接，表示端口开启，否则表示关闭\n\n3.UDP Scanning\nnmap -sU 192.168.1.0/24  # UDP，无应答，表示端口开启；返回&amp;quot;Port Unreachable&amp;quot;信息，表示关闭\n\n4.FIN Scanning\nnmap -sF 192.168.1.0/24  # 在TCP数据包中重置FIN标志位，无应答，表示开启；返回RST，表示端口关闭\n\n5.NULL Scanning\nnmap -sN 192.168.1.0/24  # 在TCP数据包中不包含任何标志位，无应答，表示开启；返回RST，表示端口关闭\n\n6.Xmas Scanning\nnmap -sX 192.168.1.0/24  # 在TCP数据包中重置FIN、RST、PUSH标志位，无应答，表示开启；返回RST，表示端口关闭\n\n7.IDLE Scanning\nnmap -sI 172.16.1.1 192.168.1.0/24  \n# 利用僵尸主机进行扫描，假设僵尸IP为172.16.1.1，当僵尸机返回序列ID增加数量为2时，表示开启，为1时关闭\n\n8.指定端口扫描\nnmap -p 80,443 192.168.1.0/24  # 可以指定多个端口\n\n9.扫描常见的100个端口\nnmap -F 192.168.1.0/24  # 快速模式\n\n10.使用协议名进行扫描\nnmap -p http 192.168.1.0/24\nnmap -p smtp 192.168.1.0/24\n\n11.扫描常用端口\nnmap --top-ports &amp;lt;端口数量&amp;gt; 192.168.1.0/24\n\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;操作系统指纹识别\&#34;&gt;操作系统指纹识别&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;nmap -O 192.168.1.0/24   # os\nnmap -sV 192.168.1.0/24  # service version\nnmap -A 192.168.1.0/24   # all\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;使用脚本\&#34;&gt;使用脚本&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;nmap --script &amp;lt;脚本名称&amp;gt; 192.168.1.0/24\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;nmap-gong-ju-chang-yong-shi-yong-chang-jing&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Nmap工具常用使用场景&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;nmap&#34;,&#34;slug&#34;:&#34;10NnMGZ95&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/10NnMGZ95/&#34;},{&#34;name&#34;:&#34;工具使用&#34;,&#34;slug&#34;:&#34;ETGdbG1UX&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/ETGdbG1UX/&#34;}],&#34;date&#34;:&#34;2021-03-29 13:50:49&#34;,&#34;dateFormat&#34;:&#34;2021-03-29&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/nmap-gong-ju-chang-yong-shi-yong-chang-jing/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;3 min read&#34;,&#34;time&#34;:136000,&#34;words&#34;:478,&#34;minutes&#34;:3},&#34;description&#34;:&#34;主机发现\n以192.168.1.0/24举例\n\nnmap -PE 192.168.1.0/24  # icmp\nnamp -PO 192.168.1.0/24  # ip\nnmap -PS 192.168.1.0/24  # tcp syn...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%BB%E6%9C%BA%E5%8F%91%E7%8E%B0\&#34;&gt;主机发现&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%AB%AF%E5%8F%A3%E6%89%AB%E6%8F%8F\&#34;&gt;端口扫描&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%8C%87%E7%BA%B9%E8%AF%86%E5%88%AB\&#34;&gt;操作系统指纹识别&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BD%BF%E7%94%A8%E8%84%9A%E6%9C%AC\&#34;&gt;使用脚本&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;详细流程如下\&#34;&gt;详细流程如下：&lt;/h3&gt;\n&lt;p&gt;1.使用 xfs_repair -n 执行文件系统错误检测，和 fsck -n 类似；&lt;br&gt;\n2.使用 xfs_repair 尝试进行修复；&lt;br&gt;\n3.当遇见无法正常挂载文件系统时，需要使用强制模式 -L 模式进行修复，会丢失部分数据，可以先对metadata进行模拟修复测试：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;xfs_metadump [partition] /path/to/file.metadump                                  # 对需要修复的分区进行dump&lt;/li&gt;\n&lt;li&gt;xfs_mdrestore /path/to/file.metadump /path/to/file.img                         # 生成img文件&lt;/li&gt;\n&lt;li&gt;losetup --show --find /path/to/file.img                                                    # 使用lostup工具将数据放到/dev/loop0&lt;/li&gt;\n&lt;li&gt;xfs_repair -L /dev/loop0                                                                        # 尝试模拟修复&lt;/li&gt;\n&lt;li&gt;mount /dev/loop0 /mnt&lt;/li&gt;\n&lt;li&gt;check the damage&lt;/li&gt;\n&lt;li&gt;(note, this is an image of file system layout, but not the actual data)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;4.拷贝真实数据，并对拷贝的数据进行修复：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;ddrescue -f -n [partition] /path/to/rescued.img rescue.log                      # 这需要一个比原分区大小更大的磁盘&lt;/li&gt;\n&lt;li&gt;ddrescue -d -f -r3 [partition] /path/to/rescued.img rescue.log&lt;/li&gt;\n&lt;li&gt;losetup --show --find /path/to/rescued.img&lt;/li&gt;\n&lt;li&gt;xfs_repair -L /dev/loop0&lt;/li&gt;\n&lt;li&gt;mount /dev/loop0 /mnt&lt;/li&gt;\n&lt;li&gt;check the damage&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;5.如果真实环境缺少这样的备份分区，那么直接使用xfs_repair -L模式进行强制修复。&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;xfs-wen-jian-xi-tong-xiu-fu-liu-cheng&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;XFS文件系统修复流程&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Linux&#34;,&#34;slug&#34;:&#34;U7XkBZwyl&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/U7XkBZwyl/&#34;}],&#34;date&#34;:&#34;2021-03-22 10:34:29&#34;,&#34;dateFormat&#34;:&#34;2021-03-22&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/xfs-wen-jian-xi-tong-xiu-fu-liu-cheng/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;2 min read&#34;,&#34;time&#34;:72000,&#34;words&#34;:272,&#34;minutes&#34;:2},&#34;description&#34;:&#34;详细流程如下：\n1.使用 xfs_repair -n 执行文件系统错误检测，和 fsck -n 类似；\n2.使用 xfs_repair 尝试进行修复；\n3.当遇见无法正常挂载文件系统时，需要使用强制模式 -L 模式进行修复，会丢失部分数据，...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B%E5%A6%82%E4%B8%8B\&#34;&gt;详细流程如下：&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;安装工具\&#34;&gt;安装工具&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;yum install -y ipmitool \n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;启动服务\&#34;&gt;启动服务&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;service ipmi start\nipmitool -I open shell     # 进入交互式shell\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;一-开关机重启\&#34;&gt;一、开关机，重启&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1. 查看开关机状态：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power status\n\n2. 开机：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power on\n\n3. 关机：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power off\n\n4. 重启：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) power reset\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;二-用户管理\&#34;&gt;二、用户管理&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 说明：[ChannelNo] 字段是可选的，ChannoNo为1或者8；BMC默认有2个用户：user id为1的匿名用户，user id为2的ADMIN用户；&amp;lt;&amp;gt;字段为必选内容；&amp;lt;privilege level&amp;gt;：2为user权限，3为Operator权限，4为Administrator权限；\n\n1. 查看用户信息：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user list [ChannelNo]\n\n2. 增加用户：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user set name &amp;lt;user id&amp;gt; &amp;lt;username&amp;gt;\n\n3. 设置密码：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user set password &amp;lt;user id&amp;gt; &amp;lt;password&amp;gt;\n\n4. 设置用户权限：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user priv &amp;lt;user id&amp;gt; &amp;lt;privilege level&amp;gt; [ChannelNo]\n\n5. 启用/禁用用户：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) user enable/disable &amp;lt;user id&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;三-ip网络设置\&#34;&gt;三、IP网络设置&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 说明：[ChannelNo] 字段是可选的，ChannoNo为1(Share Nic网络)或者8（BMC独立管理网络）；设置网络参数，必须首先设置IP为静态，然后再进行其他设置；\n\n1. 查看网络信息：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan print [ChannelNo]\n\n2. 修改IP为静态还是DHCP模式：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set &amp;lt;ChannelNo&amp;gt; ipsrc &amp;lt;static/dhcp&amp;gt;\n\n3. 修改IP地址：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set &amp;lt;ChannelNo&amp;gt; ipaddr &amp;lt;IPAddress&amp;gt;\n\n4. 修改子网掩码：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set &amp;lt;ChannelNo&amp;gt; netmask &amp;lt;NetMask&amp;gt;\n\n5. 修改默认网关：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) lan set &amp;lt;ChannelNo&amp;gt; defgw ipaddr &amp;lt;默认网关&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;四-sol功能\&#34;&gt;四、SOL功能&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 说明：&amp;lt;9.6/19.2/38.4/57.6/115.2&amp;gt;其中115.2代表115200，即*1000是表示的波特率;\n\n1. 设置SOL串口波特率：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sol set volatile-bit-rate &amp;lt;9.6/19.2/38.4/57.6/115.2&amp;gt;\n\n2. 打开SOL功能：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sol activate\n\n3. 关闭SOL功能：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sol deactivate\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;五-sel日志查看\&#34;&gt;五、SEL日志查看&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1. 查看SEL日志：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sel list\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;六-fru信息查看\&#34;&gt;六、FRU信息查看&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1. 查看FRU信息：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) fru list\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;七-sdrsensor信息查看\&#34;&gt;七、SDR，Sensor信息查看&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1. 查看SDR Sensor信息：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sdr\n\n2. 查看Sensor信息：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) sensor list\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;八-mc管理单元bmc状态和控制\&#34;&gt;八、mc(管理单元BMC)状态和控制&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1. 重启动BMC：\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) mc reset &amp;lt;warm/cold&amp;gt;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;九-设置bmc的iptables防火墙\&#34;&gt;九、设置BMC的iptables防火墙&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1. 设置某一段IP可以访问BMC\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x01 0x01 ip1(0xa 0xa 0xa 0xa) ip2(0xb 0xb 0xb 0xb)\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x09\n\n2. 设置某个IP可以访问BMC\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x00 0x01 ip1(0xa 0xa 0xa 0xa)\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x09\n\n3. 取消设置\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x08\n\n4．获取防火墙设置\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x77 0x01 0x00\n\n5. 阻止/开启某个端口\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x02 0x00/0x01 0x00 (portno)0x22 0x00\n\n6. 取消某个端口的设置（6是5的对应取消操作）\nipmitool -H (BMC的管理IP地址) -I lanplus -U (BMC登录用户名) -P (BMC 登录用户名的密码) raw 0x32 0x76 0x06 0x00/0x01 0x00 (portno)0x22 0x00\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;参考文献\&#34;&gt;参考文献&lt;/h3&gt;\n&lt;p&gt;https://www.cnblogs.com/EricDing/p/8995263.html&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;ipmitool-gong-ju-de-shi-yong-shuo-ming&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;ipmitool工具的使用说明&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;工具使用&#34;,&#34;slug&#34;:&#34;ETGdbG1UX&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/ETGdbG1UX/&#34;}],&#34;date&#34;:&#34;2021-03-10 10:09:43&#34;,&#34;dateFormat&#34;:&#34;2021-03-10&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/ipmitool-gong-ju-de-shi-yong-shuo-ming/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;7 min read&#34;,&#34;time&#34;:385000,&#34;words&#34;:1433,&#34;minutes&#34;:7},&#34;description&#34;:&#34;安装工具\nyum install -y ipmitool \n\n启动服务\nservice ipmi start\nipmitool -I open shell     # 进入交互式shell\n\n一、开关机，重启\n1. 查看开关机状态：\nipm...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%AE%89%E8%A3%85%E5%B7%A5%E5%85%B7\&#34;&gt;安装工具&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1\&#34;&gt;启动服务&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%80-%E5%BC%80%E5%85%B3%E6%9C%BA%E9%87%8D%E5%90%AF\&#34;&gt;一、开关机，重启&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%8C-%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86\&#34;&gt;二、用户管理&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%89-ip%E7%BD%91%E7%BB%9C%E8%AE%BE%E7%BD%AE\&#34;&gt;三、IP网络设置&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9B%9B-sol%E5%8A%9F%E8%83%BD\&#34;&gt;四、SOL功能&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%94-sel%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B\&#34;&gt;五、SEL日志查看&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%85%AD-fru%E4%BF%A1%E6%81%AF%E6%9F%A5%E7%9C%8B\&#34;&gt;六、FRU信息查看&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%83-sdrsensor%E4%BF%A1%E6%81%AF%E6%9F%A5%E7%9C%8B\&#34;&gt;七、SDR，Sensor信息查看&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%85%AB-mc%E7%AE%A1%E7%90%86%E5%8D%95%E5%85%83bmc%E7%8A%B6%E6%80%81%E5%92%8C%E6%8E%A7%E5%88%B6\&#34;&gt;八、mc(管理单元BMC)状态和控制&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B9%9D-%E8%AE%BE%E7%BD%AEbmc%E7%9A%84iptables%E9%98%B2%E7%81%AB%E5%A2%99\&#34;&gt;九、设置BMC的iptables防火墙&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\&#34;&gt;参考文献&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;gpu日志收集\&#34;&gt;GPU日志收集&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# nvidia-bug-report.sh   // 执行后输出nvidia-bug-report.log.gz文件\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;驱动问题常见解决方法\&#34;&gt;驱动问题常见解决方法&lt;/h3&gt;\n&lt;ol&gt;\n&lt;li&gt;维持较新的驱动版本&lt;/li&gt;\n&lt;li&gt;禁用nouveau模块&lt;/li&gt;\n&lt;li&gt;打开GPU驱动常驻内存模式并配置开机自启动&lt;/li&gt;\n&lt;li&gt;GPU故障后，可尝试重启主机解决&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h3 id=\&#34;禁用nouveau模块\&#34;&gt;禁用nouveau模块&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# lsmod | grep -i nouveau   // 如果有输出，表示启动状态，否则为禁用状态\n\n# CentOS 7\n# 编辑或新建 blacklist-nouveau.conf 文件\n[root@zj ~]# vim /usr/lib/modprobe.d/blacklist-nouveau.conf\nblacklist nouveau\noptions nouveau modeset=0\n\n# 执行如下命令并重启系统使内核生效\n[root@zj ~]# dracut -f\n[root@zj ~]# shutdown -ry 0\n\n\n# ubuntu \n# vi /etc/modprobe.d/blacklist.conf 最后一行加入\nblacklist nouveau\n# update-initramfs -u\n# reboot\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;gpu驱动内存常驻模式\&#34;&gt;GPU驱动内存常驻模式&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# nvidia-smi -pm 1\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;gpu加载数量和err检查\&#34;&gt;GPU加载数量和ERR检查&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 以下两个命令显示的GPU卡数量需要保持一致，可用于判断是否有GPU离线\n# lspci | grep -i nvidia \n# nvidia-smi\n\n# 检查输出中是否包含ERR错误字样，可用于实现健康检查\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;gpu常用性能指标获取\&#34;&gt;GPU常用性能指标获取&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# nvidia-smi \\\n&amp;gt;  --query-gpu=memory.total,memory.used,memory.free,utilization.memory,utilization.gpu,temperature.gpu,fan.speed \\\n&amp;gt;  --format=csv,noheader,nounits\n\n# nvidia-smi --help-query-gpu   // 查看可用的查询参数\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;nvidia-xian-qia-chang-yong-ming-ling&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;NVIDIA显卡常用命令&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;工具使用&#34;,&#34;slug&#34;:&#34;ETGdbG1UX&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/ETGdbG1UX/&#34;}],&#34;date&#34;:&#34;2021-02-18 09:37:06&#34;,&#34;dateFormat&#34;:&#34;2021-02-18&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/nvidia-xian-qia-chang-yong-ming-ling/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;2 min read&#34;,&#34;time&#34;:79000,&#34;words&#34;:303,&#34;minutes&#34;:2},&#34;description&#34;:&#34;GPU日志收集\n# nvidia-bug-report.sh   // 执行后输出nvidia-bug-report.log.gz文件\n\n驱动问题常见解决方法\n\n维持较新的驱动版本\n禁用nouveau模块\n打开GPU驱动常驻内存模式并配置开...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#gpu%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86\&#34;&gt;GPU日志收集&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%A9%B1%E5%8A%A8%E9%97%AE%E9%A2%98%E5%B8%B8%E8%A7%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95\&#34;&gt;驱动问题常见解决方法&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%A6%81%E7%94%A8nouveau%E6%A8%A1%E5%9D%97\&#34;&gt;禁用nouveau模块&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#gpu%E9%A9%B1%E5%8A%A8%E5%86%85%E5%AD%98%E5%B8%B8%E9%A9%BB%E6%A8%A1%E5%BC%8F\&#34;&gt;GPU驱动内存常驻模式&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#gpu%E5%8A%A0%E8%BD%BD%E6%95%B0%E9%87%8F%E5%92%8Cerr%E6%A3%80%E6%9F%A5\&#34;&gt;GPU加载数量和ERR检查&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#gpu%E5%B8%B8%E7%94%A8%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E8%8E%B7%E5%8F%96\&#34;&gt;GPU常用性能指标获取&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;快递员场景\&#34;&gt;快递员场景&lt;/h3&gt;\n&lt;p&gt;需求：有没有一种办法，让快递员能够自由出入小区，又不用知道小区居民的密码，而且他的唯一权限就是送货，其他需要密码的场合，他都没有权限？&lt;/p&gt;\n&lt;h3 id=\&#34;授权机制的设计\&#34;&gt;授权机制的设计&lt;/h3&gt;\n&lt;p&gt;第一步，门禁系统的密码输入器下面，增加一个按钮，叫做&amp;quot;获取授权&amp;quot;。快递员需要首先按这个按钮，去申请授权。&lt;/p&gt;\n&lt;p&gt;第二步，他按下按钮以后，屋主（也就是我）的手机就会跳出对话框：有人正在要求授权。系统还会显示该快递员的姓名、工号和所属的快递公司。&lt;/p&gt;\n&lt;p&gt;我确认请求属实，就点击按钮，告诉门禁系统，我同意给予他进入小区的授权。&lt;/p&gt;\n&lt;p&gt;第三步，门禁系统得到我的确认以后，向快递员显示一个进入小区的令牌（access token）。令牌就是类似密码的一串数字，只在短期内（比如七天）有效。&lt;/p&gt;\n&lt;p&gt;第四步，快递员向门禁系统输入令牌，进入小区。&lt;/p&gt;\n&lt;p&gt;有人可能会问，为什么不是远程为快递员开门，而要为他单独生成一个令牌？这是因为快递员可能每天都会来送货，第二天他还可以复用这个令牌。另外，有的小区有多重门禁，快递员可以使用同一个令牌通过它们。&lt;/p&gt;\n&lt;h3 id=\&#34;转换理解\&#34;&gt;转换理解&lt;/h3&gt;\n&lt;p&gt;所以，OAuth就是一种授权机制，数据的所有者告诉系统，同意授权第三方应用进入系统，获取这些数据。系统从而产生一个短期的进入令牌（Token），用于替代密码，以供第三方使用。&lt;/p&gt;\n&lt;h3 id=\&#34;关于token\&#34;&gt;关于Token&lt;/h3&gt;\n&lt;p&gt;只需要记住三点：1、令牌的有效期是有限的，为了安全；2、令牌的权限范围一般很小；3、令牌可以被撤销；&lt;/p&gt;\n&lt;h3 id=\&#34;参考文献\&#34;&gt;参考文献&lt;/h3&gt;\n&lt;p&gt;http://www.ruanyifeng.com/blog/2019/04/oauth_design.html&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;li-jie-oauth-20-de-ji-ben-liu-cheng&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;理解OAuth 2.0的基本流程&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;信息安全&#34;,&#34;slug&#34;:&#34;a5GDIyqF3&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/a5GDIyqF3/&#34;}],&#34;date&#34;:&#34;2021-02-04 09:00:32&#34;,&#34;dateFormat&#34;:&#34;2021-02-04&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/li-jie-oauth-20-de-ji-ben-liu-cheng/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;2 min read&#34;,&#34;time&#34;:103000,&#34;words&#34;:499,&#34;minutes&#34;:2},&#34;description&#34;:&#34;快递员场景\n需求：有没有一种办法，让快递员能够自由出入小区，又不用知道小区居民的密码，而且他的唯一权限就是送货，其他需要密码的场合，他都没有权限？\n授权机制的设计\n第一步，门禁系统的密码输入器下面，增加一个按钮，叫做&amp;quot;获取授权&amp;q...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%BF%AB%E9%80%92%E5%91%98%E5%9C%BA%E6%99%AF\&#34;&gt;快递员场景&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%8E%88%E6%9D%83%E6%9C%BA%E5%88%B6%E7%9A%84%E8%AE%BE%E8%AE%A1\&#34;&gt;授权机制的设计&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%BD%AC%E6%8D%A2%E7%90%86%E8%A7%A3\&#34;&gt;转换理解&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%85%B3%E4%BA%8Etoken\&#34;&gt;关于Token&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\&#34;&gt;参考文献&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;######Nginx配置文件nginx.conf中文详解#####\n\n#定义Nginx运行的用户和用户组\nuser www www;\n\n#nginx进程数，建议设置为等于CPU总核心数。\nworker_processes 8;\n \n#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]\nerror_log /usr/local/nginx/logs/error.log info;\n\n#进程pid文件\npid /usr/local/nginx/logs/nginx.pid;\n\n#指定进程可以打开的最大描述符：数目\n#工作模式与连接数上限\n#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。\n#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。\n#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。\nworker_rlimit_nofile 65535;\n\nevents\n{\n    use epoll;\n\n    #单个进程最大连接数（最大连接数=连接数*进程数）\n    worker_connections 65535;\n\n    #keepalive超时时间。\n    keepalive_timeout 60;\n\n    #分页大小可以用命令getconf PAGESIZE 取得。\n    #getconf PAGESIZE 设置为该值的整数倍\n    client_header_buffer_size 4k;\n\n    #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。\n    open_file_cache max=65535 inactive=60s;\n\n    #语法:open_file_cache_valid time \n    #默认值 60 \n    #使用字段:http, server, location \n    #这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.\n    open_file_cache_valid 80s;\n\n    #语法:open_file_cache_min_uses number \n    #默认值: 1 \n    #使用字段:http, server, location  \n    #这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.\n    open_file_cache_min_uses 1;\n    \n    #语法:open_file_cache_errors on | off \n    #默认值: off \n    #使用字段:http, server, location \n    #这个指令指定是否在搜索一个文件是记录cache错误.\n    open_file_cache_errors on;\n}\n \n#设定http服务器，利用它的反向代理功能提供负载均衡支持\nhttp\n{\n    #文件扩展名与文件类型映射表\n    include mime.types;\n\n    #默认文件类型\n    default_type application/octet-stream;\n\n    #默认编码\n    #charset utf-8;\n\n    #服务器名字的hash表大小\n    #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.\n    server_names_hash_bucket_size 128;\n\n    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。\n    client_header_buffer_size 32k;\n\n    #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。\n    large_client_header_buffers 4 64k;\n\n    #设定通过nginx上传文件的大小\n    client_max_body_size 8m;\n\n    #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。\n    #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。\n    sendfile on;\n\n    #开启目录列表访问，合适下载服务器，默认关闭。\n    autoindex on;\n\n    #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用\n    tcp_nopush on;\n    tcp_nodelay on;\n\n    #长连接超时时间，单位是秒\n    keepalive_timeout 120;\n\n    #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。\n    fastcgi_connect_timeout 300;\n    fastcgi_send_timeout 300;\n    fastcgi_read_timeout 300;\n    fastcgi_buffer_size 64k;\n    fastcgi_buffers 4 64k;\n    fastcgi_busy_buffers_size 128k;\n    fastcgi_temp_file_write_size 128k;\n\n    #gzip模块设置\n    gzip on;               #开启gzip压缩输出\n    gzip_min_length 1k;    #最小压缩文件大小\n    gzip_buffers 4 16k;    #压缩缓冲区\n    gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）\n    gzip_comp_level 2;     #压缩等级\n    gzip_types text/plain application/x-javascript text/css application/xml;    #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。\n    gzip_vary on;\n\n    #开启限制IP连接数的时候需要使用\n    #limit_zone crawler $binary_remote_addr 10m;\n\n    #负载均衡配置\n    upstream piao.jd.com {\n        #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。\n        server 192.168.80.121:80 weight=3;\n        server 192.168.80.122:80 weight=2;\n        server 192.168.80.123:80 weight=3;\n\n        #nginx的upstream目前支持4种方式的分配\n        #1、轮询（默认）\n        #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。\n        #2、weight\n        #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。\n        #2、ip_hash\n        #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。\n        #例如：\n        #upstream bakend {\n        #    ip_hash;\n        #    server 192.168.0.14:88;\n        #    server 192.168.0.15:80;\n        #}\n        #3、fair（第三方）\n        #按后端服务器的响应时间来分配请求，响应时间短的优先分配。\n        #upstream backend {\n        #    server server1;\n        #    server server2;\n        #    fair;\n        #}\n        #4、url_hash（第三方）\n        #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。\n        #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法\n        #upstream backend {\n        #    server squid1:3128;\n        #    server squid2:3128;\n        #    hash $request_uri;\n        #    hash_method crc32;\n        #}\n\n        #tips:\n        #upstream bakend{#定义负载均衡设备的Ip及设备状态}{\n        #    ip_hash;\n        #    server 127.0.0.1:9090 down;\n        #    server 127.0.0.1:8080 weight=2;\n        #    server 127.0.0.1:6060;\n        #    server 127.0.0.1:7070 backup;\n        #}\n        #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;\n\n        #每个设备的状态设置为:\n        #1.down表示单前的server暂时不参与负载\n        #2.weight为weight越大，负载的权重就越大。\n        #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误\n        #4.fail_timeout:max_fails次失败后，暂停的时间。\n        #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。\n\n        #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。\n        #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug\n        #client_body_temp_path设置记录文件的目录 可以设置最多3层目录\n        #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡\n    }\n     \n     \n     \n    #虚拟主机的配置\n    server\n    {\n        #监听端口\n        listen 80;\n\n        #域名可以有多个，用空格隔开\n        server_name www.jd.com jd.com;\n        index index.html index.htm index.php;\n        root /data/www/jd;\n\n        #对******进行负载均衡\n        location ~ .*.(php|php5)?$\n        {\n            fastcgi_pass 127.0.0.1:9000;\n            fastcgi_index index.php;\n            include fastcgi.conf;\n        }\n         \n        #图片缓存时间设置\n        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$\n        {\n            expires 10d;\n        }\n         \n        #JS和CSS缓存时间设置\n        location ~ .*.(js|css)?$\n        {\n            expires 1h;\n        }\n         \n        #日志格式设定\n        #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；\n        #$remote_user：用来记录客户端用户名称；\n        #$time_local： 用来记录访问时间与时区；\n        #$request： 用来记录请求的url与http协议；\n        #$status： 用来记录请求状态；成功是200，\n        #$body_bytes_sent ：记录发送给客户端文件主体内容大小；\n        #$http_referer：用来记录从那个页面链接访问过来的；\n        #$http_user_agent：记录客户浏览器的相关信息；\n        #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。\n        log_format access &#39;$remote_addr - $remote_user [$time_local] &amp;quot;$request&amp;quot; &#39;\n        &#39;$status $body_bytes_sent &amp;quot;$http_referer&amp;quot; &#39;\n        &#39;&amp;quot;$http_user_agent&amp;quot; $http_x_forwarded_for&#39;;\n         \n        #定义本虚拟主机的访问日志\n        access_log  /usr/local/nginx/logs/host.access.log  main;\n        access_log  /usr/local/nginx/logs/host.access.404.log  log404;\n         \n        #对 &amp;quot;/&amp;quot; 启用反向代理\n        location / {\n            proxy_pass http://127.0.0.1:88;\n            proxy_redirect off;\n            proxy_set_header X-Real-IP $remote_addr;\n             \n            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n             \n            #以下是一些反向代理的配置，可选。\n            proxy_set_header Host $host;\n\n            #允许客户端请求的最大单文件字节数\n            client_max_body_size 10m;\n\n            #缓冲区代理缓冲用户端请求的最大字节数，\n            #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。\n            #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误\n            client_body_buffer_size 128k;\n\n            #表示使nginx阻止HTTP应答代码为400或者更高的应答。\n            proxy_intercept_errors on;\n\n            #后端服务器连接的超时时间_发起握手等候响应超时时间\n            #nginx跟后端服务器连接超时时间(代理连接超时)\n            proxy_connect_timeout 90;\n\n            #后端服务器数据回传时间(代理发送超时)\n            #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据\n            proxy_send_timeout 90;\n\n            #连接成功后，后端服务器响应时间(代理接收超时)\n            #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）\n            proxy_read_timeout 90;\n\n            #设置代理服务器（nginx）保存用户头信息的缓冲区大小\n            #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小\n            proxy_buffer_size 4k;\n\n            #proxy_buffers缓冲区，网页平均在32k以下的设置\n            #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k\n            proxy_buffers 4 32k;\n\n            #高负荷下缓冲大小（proxy_buffers*2）\n            proxy_busy_buffers_size 64k;\n\n            #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长\n            #设定缓存文件夹大小，大于这个值，将从upstream服务器传\n            proxy_temp_file_write_size 64k;\n        }\n         \n        #设定查看Nginx状态的地址\n        location /NginxStatus {\n            stub_status on;\n            access_log on;\n            auth_basic &amp;quot;NginxStatus&amp;quot;;\n            auth_basic_user_file confpasswd;\n            #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。\n        }\n         \n        #本地动静分离反向代理配置\n        #所有jsp的页面均交由tomcat或resin处理\n        location ~ .(jsp|jspx|do)?$ {\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_pass http://127.0.0.1:8080;\n        }\n         \n        #所有静态文件由nginx直接读取不经过tomcat或resin\n        location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|\n        pdf|xls|mp3|wma)$\n        {\n            expires 15d; \n        }\n         \n        location ~ .*.(js|css)?$\n        {\n            expires 1h;\n        }\n    }\n}\n######Nginx配置文件nginx.conf中文详解#####\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;nginx-pei-zhi-wen-jian-xiang-jie&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Nginx配置文件详解&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;Nginx&#34;,&#34;slug&#34;:&#34;0UDqNZrMg&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/0UDqNZrMg/&#34;}],&#34;date&#34;:&#34;2021-02-03 14:15:08&#34;,&#34;dateFormat&#34;:&#34;2021-02-03&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/nginx-pei-zhi-wen-jian-xiang-jie/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;13 min read&#34;,&#34;time&#34;:731000,&#34;words&#34;:3112,&#34;minutes&#34;:13},&#34;description&#34;:&#34;######Nginx配置文件nginx.conf中文详解#####\n\n#定义Nginx运行的用户和用户组\nuser www www;\n\n#nginx进程数，建议设置为等于CPU总核心数。\nworker_processes 8;\n \n#全局...&#34;,&#34;toc&#34;:&#34;&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;端口扫描\&#34;&gt;端口扫描&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# nc -vz -w 5 127.0.0.1 1-1024   // 扫描本地1-1024端口范围\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;监听端口\&#34;&gt;监听端口&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# nc -l 8000     // 监听TCP端口\n# nc -ul 9999    // 监听UDP端口\n# nc -vuz 127.0.0.1 9999   // 测试本地UDP端口\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;传输文件\&#34;&gt;传输文件&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1.上传\n# nc -l 9999 &amp;gt; filename\n# nc 127.0.0.1 9999 &amp;lt; source\n\n2.下载\n# nc -l 9999 &amp;lt; filename\n# nc 127.0.0.1 9999 &amp;gt; target\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;nc-ming-ling-shi-yong&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;nc命令使用&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;工具使用&#34;,&#34;slug&#34;:&#34;ETGdbG1UX&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/ETGdbG1UX/&#34;}],&#34;date&#34;:&#34;2021-02-03 09:27:30&#34;,&#34;dateFormat&#34;:&#34;2021-02-03&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/nc-ming-ling-shi-yong/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:28000,&#34;words&#34;:94,&#34;minutes&#34;:1},&#34;description&#34;:&#34;端口扫描\n# nc -vz -w 5 127.0.0.1 1-1024   // 扫描本地1-1024端口范围\n\n监听端口\n# nc -l 8000     // 监听TCP端口\n# nc -ul 9999    // 监听UDP端口\n# ...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%AB%AF%E5%8F%A3%E6%89%AB%E6%8F%8F\&#34;&gt;端口扫描&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%9B%91%E5%90%AC%E7%AB%AF%E5%8F%A3\&#34;&gt;监听端口&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6\&#34;&gt;传输文件&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;记录一下storcli工具的基本查询方法主要用于实现监控目的对于更改raid的相关命令暂时不在这里记录\&#34;&gt;记录一下storcli工具的基本查询方法，主要用于实现监控目的，对于更改Raid的相关命令暂时不在这里记录。&lt;/h3&gt;\n&lt;h3 id=\&#34;获取帮助信息\&#34;&gt;获取帮助信息&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 -h\n     Storage Command Line Tool  Ver 1.23.02 Mar 28, 2017\n\n     (c)Copyright 2017, AVAGO Corporation, All Rights Reserved.\n\nstorcli -v \nstorcli -h| -help| ? \nstorcli -h| -help| ? legacy\nstorcli show \nstorcli show all\nstorcli show ctrlcount\nstorcli show file=&amp;lt;filepath&amp;gt;\nstorcli /cx add vd r[0|1|5|6|00|10|50|60]\n...\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;显示raid卡相关信息\&#34;&gt;显示Raid卡相关信息&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 show all\nStatus Code = 0\nStatus = Success\nDescription = None\n\nNumber of Controllers = 1\nHost Name = A-f8f21e93eca4-nas014\nOperating System  = Linux3.10.0-1062.el7.x86_64\n\nSystem Overview :\n===============\n\n-------------------------------------------------------------------------------------\nCtl Model                   Ports PDs DGs DNOpt VDs VNOpt BBU sPR DS  EHS ASOs Hlth  \n-------------------------------------------------------------------------------------\n  0 AVAGOMegaRAIDSAS9361-8i     8  25   2     1   2     1 Opt On  1&amp;amp;2 Y      3 NdAtn \n-------------------------------------------------------------------------------------\n\nCtl=Controller Index|DGs=Drive groups|VDs=Virtual drives|Fld=Failed\nPDs=Physical drives|DNOpt=DG NotOptimal|VNOpt=VD NotOptimal|Opt=Optimal\nMsng=Missing|Dgd=Degraded|NdAtn=Need Attention|Unkwn=Unknown\nsPR=Scheduled Patrol Read|DS=DimmerSwitch|EHS=Emergency Hot Spare\nY=Yes|N=No|ASOs=Advanced Software Options|BBU=Battery backup unit\nHlth=Health|Safe=Safe-mode boot\n\n# 这里的optimal表示是否是最优状态\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;显示控制器信息\&#34;&gt;显示控制器信息&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0 show   //这里c0表示第一个控制器\nGenerating detailed summary of the adapter, it may take a while to complete.\n\nController = 0\n...省略\nDevice Number = 0\nFunction Number = 0\nDrive Groups = 2\n\nTOPOLOGY :\n========\n\n-----------------------------------------------------------------------------\nDG Arr Row EID:Slot DID Type  State BT       Size PDC  PI SED DS3  FSpace TR \n-----------------------------------------------------------------------------\n ... 省略\n 1 0   12  10:12    37  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  \n 1 0   13  10:13    36  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  \n 1 0   14  10:14    46  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  \n 1 0   15  -        -   DRIVE Msng  -   14.551 TB -    -  -   -    -      N  \n 1 0   16  10:16    38  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  \n 1 0   17  10:17    35  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  \n 1 0   18  10:18    45  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N    \n-----------------------------------------------------------------------------\n... 省略\n\nMissing Drives Count = 1\n\n# 这里提示我们有一块盘丢失，需要进行处理\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;显示剩余空间\&#34;&gt;显示剩余空间&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0 show freespace\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;显示ccconsistency-check\&#34;&gt;显示CC（Consistency Check）&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0 show cc\nController = 0\nStatus = Success\nDescription = None\n\nController Properties :\n=====================\n\n-----------------------------------------------\nCtrl_Prop                 Value                \n-----------------------------------------------\nCC Operation Mode         Concurrent           \nCC Execution Delay        168                  \nCC Next Starttime         02/04/2021, 15:00:00 \nCC Current State          Stopped              \nCC Number of iterations   15                   \nCC Number of VD completed 1                    \nCC Excluded VDs           None                 \n-----------------------------------------------\n\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;显示cc速率\&#34;&gt;显示CC速率&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0 show ccrate\nController = 0\nStatus = Success\nDescription = None\n\n\nController Properties :\n=====================\n\n----------------\nCtrl_Prop Value \n----------------\nCC Rate   30%   \n----------------\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;查看与设置rebuild速率\&#34;&gt;查看与设置Rebuild速率&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0 show rebuildrate     //查看速率\n# ./storcli64 /c0 set rebuildrate=30   //设置速率\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;清除raid卡物理磁盘cache\&#34;&gt;清除Raid卡，物理磁盘Cache&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0 flushcache\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;获取所有enclosure信息\&#34;&gt;获取所有enclosure信息&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0/eall show\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;获取单个enclosure信息\&#34;&gt;获取单个enclosure信息&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0/e10 show &amp;lt;all&amp;gt;    //加上all参数表示获取详细信息\n# ./strocli64 /c0/e10 show status   //获取风扇等设备详细信息\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;获取所有磁盘详细信息\&#34;&gt;获取所有磁盘详细信息&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0/eall/sall show\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;卷组信息获取\&#34;&gt;卷组信息获取&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# ./storcli64 /c0/dall show   // 这里的卷组称为DG\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;参考文献\&#34;&gt;参考文献&lt;/h2&gt;\n&lt;p&gt;https://www.cnblogs.com/luxiaodai/p/9878747.html&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;storcli-gong-ju-shi-yong-shuo-ming&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;StorCLI工具使用说明&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;工具使用&#34;,&#34;slug&#34;:&#34;ETGdbG1UX&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/ETGdbG1UX/&#34;}],&#34;date&#34;:&#34;2021-02-01 09:59:11&#34;,&#34;dateFormat&#34;:&#34;2021-02-01&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/storcli-gong-ju-shi-yong-shuo-ming/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;4 min read&#34;,&#34;time&#34;:215000,&#34;words&#34;:669,&#34;minutes&#34;:4},&#34;description&#34;:&#34;记录一下storcli工具的基本查询方法，主要用于实现监控目的，对于更改Raid的相关命令暂时不在这里记录。\n获取帮助信息\n# ./storcli64 -h\n     Storage Command Line Tool  Ver 1.23....&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%8Bstorcli%E5%B7%A5%E5%85%B7%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%9F%A5%E8%AF%A2%E6%96%B9%E6%B3%95%E4%B8%BB%E8%A6%81%E7%94%A8%E4%BA%8E%E5%AE%9E%E7%8E%B0%E7%9B%91%E6%8E%A7%E7%9B%AE%E7%9A%84%E5%AF%B9%E4%BA%8E%E6%9B%B4%E6%94%B9raid%E7%9A%84%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%E6%9A%82%E6%97%B6%E4%B8%8D%E5%9C%A8%E8%BF%99%E9%87%8C%E8%AE%B0%E5%BD%95\&#34;&gt;记录一下storcli工具的基本查询方法，主要用于实现监控目的，对于更改Raid的相关命令暂时不在这里记录。&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%8E%B7%E5%8F%96%E5%B8%AE%E5%8A%A9%E4%BF%A1%E6%81%AF\&#34;&gt;获取帮助信息&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%98%BE%E7%A4%BAraid%E5%8D%A1%E7%9B%B8%E5%85%B3%E4%BF%A1%E6%81%AF\&#34;&gt;显示Raid卡相关信息&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%98%BE%E7%A4%BA%E6%8E%A7%E5%88%B6%E5%99%A8%E4%BF%A1%E6%81%AF\&#34;&gt;显示控制器信息&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%98%BE%E7%A4%BA%E5%89%A9%E4%BD%99%E7%A9%BA%E9%97%B4\&#34;&gt;显示剩余空间&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%98%BE%E7%A4%BAccconsistency-check\&#34;&gt;显示CC（Consistency Check）&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%98%BE%E7%A4%BAcc%E9%80%9F%E7%8E%87\&#34;&gt;显示CC速率&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%9F%A5%E7%9C%8B%E4%B8%8E%E8%AE%BE%E7%BD%AErebuild%E9%80%9F%E7%8E%87\&#34;&gt;查看与设置Rebuild速率&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%B8%85%E9%99%A4raid%E5%8D%A1%E7%89%A9%E7%90%86%E7%A3%81%E7%9B%98cache\&#34;&gt;清除Raid卡，物理磁盘Cache&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%8E%B7%E5%8F%96%E6%89%80%E6%9C%89enclosure%E4%BF%A1%E6%81%AF\&#34;&gt;获取所有enclosure信息&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%8E%B7%E5%8F%96%E5%8D%95%E4%B8%AAenclosure%E4%BF%A1%E6%81%AF\&#34;&gt;获取单个enclosure信息&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%8E%B7%E5%8F%96%E6%89%80%E6%9C%89%E7%A3%81%E7%9B%98%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF\&#34;&gt;获取所有磁盘详细信息&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8D%B7%E7%BB%84%E4%BF%A1%E6%81%AF%E8%8E%B7%E5%8F%96\&#34;&gt;卷组信息获取&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\&#34;&gt;参考文献&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;事务提交流程\&#34;&gt;事务提交流程&lt;/h2&gt;\n&lt;h3 id=\&#34;大致流程如下\&#34;&gt;大致流程如下：&lt;/h3&gt;\n&lt;p&gt;有binlog的情况下，commit动作开始时，会有一个Redo XID写入redo，然后写data到binlog，binlog写成功后，会将binlog的filename和日志写的position再写回redo（position也会写入pos文件），此时事务完成（committed）。如果只有XID，没有filename和position，则表示事务为prepare状态。&lt;/p&gt;\n&lt;h3 id=\&#34;流程\&#34;&gt;流程：&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# commit; --&amp;gt; write XID to redo. --&amp;gt; write data to Binlog. --&amp;gt; write filename,postsion of binlog to redo. --&amp;gt; commited.\n# 记录Binlog是在InnoDB引擎Prepare（即Redo Log写入磁盘）之后，这点至关重要。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://esp0x.github.io/post-images/1610962074302.png\&#34; alt=\&#34;\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;h3 id=\&#34;不同阶段crash的情况\&#34;&gt;不同阶段crash的情况：&lt;/h3&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;crash发生阶段&lt;/th&gt;\n&lt;th&gt;事务状态&lt;/th&gt;\n&lt;th&gt;事务结果&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;当事务在prepare阶段crash&lt;/td&gt;\n&lt;td&gt;该事务未写入binlog，引擎层也未写入redo到磁盘&lt;/td&gt;\n&lt;td&gt;该事务rollback&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;当事务在binlog写阶段crash&lt;/td&gt;\n&lt;td&gt;此时引擎层redo写盘完成，但binlog日志还未落盘&lt;/td&gt;\n&lt;td&gt;该事务rollback&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;当事务在binlog日志写入磁盘后crash，但引擎层未来得及commit&lt;/td&gt;\n&lt;td&gt;此时引擎层redo已经写盘，server层binlog已经写盘，但redo中事务状态未正确结束&lt;/td&gt;\n&lt;td&gt;读出binlog中的XID，并通知引擎层提交这些XID的事务。引擎层提交这些事务后，会回滚其他事务，使引擎层redo和binlog日志在事务上始终保持一致。事务通过recovery自动完成提交&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;h2 id=\&#34;wal机制\&#34;&gt;WAL机制&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;WAL（Write Ahead Log）：对数据文件进行修改前，必须将修改先记录到日志。&lt;/li&gt;\n&lt;li&gt;Redo log就是一种WAL应用，用于保证数据库的持久性，每次事务提交时，不用同步刷新磁盘，只需要刷新redo log就行了。相比刷盘的随机IO，写redo log的顺序IO能够提升事务提交速度。&lt;/li&gt;\n&lt;li&gt;组提交：\n&lt;ol&gt;\n&lt;li&gt;未开启binlog：redo log的刷盘操作是主要瓶颈，mysql使用组提交，将多个redo log刷盘操作合并成一个。&lt;/li&gt;\n&lt;li&gt;开启binlog：为了保证redo log和binlog数据一致性，mysql使用了二阶段提交，此时binlog成为瓶颈，mysql增加了binlog的组提交来解决这个问题，分为三个阶段（Flush、Sync、Commit），最大化刷盘收益。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;过程详解\&#34;&gt;过程详解&lt;/h3&gt;\n&lt;p&gt;在Mysql中每个阶段都有一个队列，每个队列都有一把锁保护，第一个进入队列的事务成为leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。&lt;/p&gt;\n&lt;h4 id=\&#34;flush阶段\&#34;&gt;Flush阶段&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;首先获取队列中的事务组；&lt;/li&gt;\n&lt;li&gt;将redo中prepare阶段的数据刷盘；&lt;/li&gt;\n&lt;li&gt;将binlog数据写入文件，此处是文件缓冲，不保证数据库crash时，binlog的完整性；&lt;/li&gt;\n&lt;li&gt;Flush阶段的作用是提供了redo 的组提交；&lt;/li&gt;\n&lt;li&gt;如果这一步crash，由于不保证binlog中存在事务记录，所以数据库恢复后会回滚，此时二阶段提交状态还是prepare；&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;sync阶段\&#34;&gt;Sync阶段&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;为了增加一组事务中的事务数量，提升刷盘效率，使用两个参数进行控制：\n&lt;ol&gt;\n&lt;li&gt;binlog_group_commit_sync_delay=N  等待N 微秒后，开始事务刷盘&lt;/li&gt;\n&lt;li&gt;binlog_group_commit_sync_no_delay=N  对列中事务达到N个，立刻刷盘，忽略上面那个时间参数&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/li&gt;\n&lt;li&gt;Sync阶段的作用是支持binlog的组提交；&lt;/li&gt;\n&lt;li&gt;如果此时crash，由于binlog中有事务记录，数据库恢复后会继续提交该事务；&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;commit阶段\&#34;&gt;Commit阶段&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;首先获取队列中的事务组；&lt;/li&gt;\n&lt;li&gt;依次将redo中已经prepare的事务在引擎层进行提交；&lt;/li&gt;\n&lt;li&gt;Commit阶段不用刷盘，如上所述，Flush阶段中的Redo log刷盘已经足够保证数据库崩溃时的数据安全了；&lt;/li&gt;\n&lt;li&gt;Commit阶段队列的作用是承接Sync阶段的事务，完成最后的引擎提交，使得Sync可以尽早的处理下一组事务，最大化组提交的效率；&lt;/li&gt;\n&lt;/ul&gt;\n&#34;,&#34;fileName&#34;:&#34;mysql-de-zu-ti-jiao-yuan-li&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Mysql的组提交原理&#34;,&#34;tags&#34;:[],&#34;date&#34;:&#34;2021-01-18 17:25:56&#34;,&#34;dateFormat&#34;:&#34;2021-01-18&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/mysql-de-zu-ti-jiao-yuan-li/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;4 min read&#34;,&#34;time&#34;:207000,&#34;words&#34;:938,&#34;minutes&#34;:4},&#34;description&#34;:&#34;事务提交流程\n大致流程如下：\n有binlog的情况下，commit动作开始时，会有一个Redo XID写入redo，然后写data到binlog，binlog写成功后，会将binlog的filename和日志写的position再写回red...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B\&#34;&gt;事务提交流程&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%A4%A7%E8%87%B4%E6%B5%81%E7%A8%8B%E5%A6%82%E4%B8%8B\&#34;&gt;大致流程如下：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%B5%81%E7%A8%8B\&#34;&gt;流程：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%8D%E5%90%8C%E9%98%B6%E6%AE%B5crash%E7%9A%84%E6%83%85%E5%86%B5\&#34;&gt;不同阶段crash的情况：&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#wal%E6%9C%BA%E5%88%B6\&#34;&gt;WAL机制&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3\&#34;&gt;过程详解&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#flush%E9%98%B6%E6%AE%B5\&#34;&gt;Flush阶段&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#sync%E9%98%B6%E6%AE%B5\&#34;&gt;Sync阶段&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#commit%E9%98%B6%E6%AE%B5\&#34;&gt;Commit阶段&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;一-gtid概述\&#34;&gt;一、GTID概述&lt;/h2&gt;\n&lt;p&gt;GTID是MYSQL5.6新增的特性，GTID（Global Transaction Identifier）全称为全局事务标示符,用以数据库实例事务唯一标识，其组成主要是source_id和transaction_id 即GTID = source_id:transaction_id。其中source_id是数据库启动自动生成的数据库实例唯一标识，保存在auto.cnf中，而transaction_id则是事务执行的序列号。&lt;/p&gt;\n&lt;h2 id=\&#34;二-gtid优缺点\&#34;&gt;二、GTID优缺点&lt;/h2&gt;\n&lt;h3 id=\&#34;优点\&#34;&gt;优点：&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;复制安全性更高，一个事务在每个实例上只执行一次；&lt;/li&gt;\n&lt;li&gt;故障切换简单，可通过设置MASTER_AUTO_POSITION=1，而非master_log_file和master_log_pos来建立主从关系；&lt;/li&gt;\n&lt;li&gt;可根据GTID确定事务最早提交的实例；&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;缺点\&#34;&gt;缺点：&lt;/h3&gt;\n&lt;ul&gt;\n&lt;li&gt;组复制中，必须要求统一开启GTID或者关闭GTID；&lt;/li&gt;\n&lt;li&gt;不支持复制create table table_name select ... from table_name_xx ;&lt;/li&gt;\n&lt;li&gt;不支持create temporary table和drop temporary table；&lt;/li&gt;\n&lt;li&gt;不支持sql_slave_skip_counter，可通过set global gtid_next=&#39;&#39; 跳过；&lt;/li&gt;\n&lt;li&gt;从库和主库都必须设置log_slave_updates&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;三-gtid工作原理\&#34;&gt;三、GTID工作原理&lt;/h2&gt;\n&lt;p&gt;1、master更新数据时，会在事务前产生GTID，一同记录到binlog日志中。&lt;br&gt;\n2、slave端的i/o 线程将变更的binlog，写入到本地的relay log中。&lt;br&gt;\n3、sql线程从relay log中获取GTID，然后对比slave端的binlog是否有记录。&lt;br&gt;\n4、如果有记录，说明该GTID的事务已经执行，slave会忽略。&lt;br&gt;\n5、如果没有记录，slave就会从relay log中执行该GTID的事务，并记录到binlog。&lt;br&gt;\n6、在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。&lt;/p&gt;\n&lt;h2 id=\&#34;四-gtid开启和关闭\&#34;&gt;四、GTID开启和关闭&lt;/h2&gt;\n&lt;p&gt;gtid_mode=ON(必选)&lt;br&gt;\nlog_bin=ON(必选)&lt;br&gt;\nlog-slave-updates=ON(必选)&lt;br&gt;\nenforce-gtid-consistency(必选)&lt;br&gt;\nlog-bin = /home/mysql/mysql-bin（必选）&lt;br&gt;\nbinlog_format = MIXED（必选mixed或者row）&lt;br&gt;\n##&lt;br&gt;\nchange master to master_host = &#39;ipaddr&#39;,master_port = 3306,master_user = &#39;username&#39;,master_password=&#39;password&#39;,master_auto_position = 1;&lt;/p&gt;\n&lt;h2 id=\&#34;五-gtid适用场景\&#34;&gt;五、GTID适用场景&lt;/h2&gt;\n&lt;p&gt;1、搭建高可用架构，方便主从切换后，新的从库重新指定主库（例如一主二从的结构，A为mater,B为Slave，C为Slave，A宕机切换到B后，C重新指定主库为B）&lt;br&gt;\n2、不经常使用create table table_name select * from table_name/create temporary table/update t1,t2 where ...这种语句的场合&lt;/p&gt;\n&#34;,&#34;fileName&#34;:&#34;gtid-ji-chu-yuan-li&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;GTID基础原理&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;mysql&#34;,&#34;slug&#34;:&#34;lEg5TWDNv&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/lEg5TWDNv/&#34;}],&#34;date&#34;:&#34;2021-01-18 17:03:20&#34;,&#34;dateFormat&#34;:&#34;2021-01-18&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/gtid-ji-chu-yuan-li/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;3 min read&#34;,&#34;time&#34;:123000,&#34;words&#34;:515,&#34;minutes&#34;:3},&#34;description&#34;:&#34;一、GTID概述\nGTID是MYSQL5.6新增的特性，GTID（Global Transaction Identifier）全称为全局事务标示符,用以数据库实例事务唯一标识，其组成主要是source_id和transaction_id 即...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%80-gtid%E6%A6%82%E8%BF%B0\&#34;&gt;一、GTID概述&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%8C-gtid%E4%BC%98%E7%BC%BA%E7%82%B9\&#34;&gt;二、GTID优缺点&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BC%98%E7%82%B9\&#34;&gt;优点：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E7%BC%BA%E7%82%B9\&#34;&gt;缺点：&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%89-gtid%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86\&#34;&gt;三、GTID工作原理&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9B%9B-gtid%E5%BC%80%E5%90%AF%E5%92%8C%E5%85%B3%E9%97%AD\&#34;&gt;四、GTID开启和关闭&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%94-gtid%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF\&#34;&gt;五、GTID适用场景&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;四个基本要素acid\&#34;&gt;四个基本要素（ACID）&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;原子性（Atomicity）&lt;/li&gt;\n&lt;li&gt;一致性（Consistency）&lt;/li&gt;\n&lt;li&gt;隔离性（Isolation）&lt;/li&gt;\n&lt;li&gt;持久性（Durability）&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;事务的并发问题\&#34;&gt;事务的并发问题&lt;/h2&gt;\n&lt;ol&gt;\n&lt;li&gt;脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读到的数据是脏数据；&lt;/li&gt;\n&lt;li&gt;不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取的数据不一致；&lt;/li&gt;\n&lt;li&gt;幻读：幻读并不是说两次读取的结果集不同，幻读侧重的方面是某一次的select操作得到的结果所表征的数据状态无法支撑后续的业务操作。具体来说，select某条记录是否存在，不存在，准备插入此记录，但执行insert时发现此记录已存在，无法插入，此时就发生了幻读。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;事务隔离级别\&#34;&gt;事务隔离级别&lt;/h2&gt;\n&lt;table&gt;\n&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;事务隔离级别&lt;/th&gt;\n&lt;th&gt;脏读&lt;/th&gt;\n&lt;th&gt;不可重复读&lt;/th&gt;\n&lt;th&gt;幻读&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;读未提交（read-uncommitted）&lt;/td&gt;\n&lt;td&gt;是&lt;/td&gt;\n&lt;td&gt;是&lt;/td&gt;\n&lt;td&gt;是&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;不可重复读（read-committed）&lt;/td&gt;\n&lt;td&gt;否&lt;/td&gt;\n&lt;td&gt;是&lt;/td&gt;\n&lt;td&gt;是&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;可重复读（repeatable-read）&lt;/td&gt;\n&lt;td&gt;否&lt;/td&gt;\n&lt;td&gt;否&lt;/td&gt;\n&lt;td&gt;是&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;串行化（serializable）&lt;/td&gt;\n&lt;td&gt;否&lt;/td&gt;\n&lt;td&gt;否&lt;/td&gt;\n&lt;td&gt;否&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;h4 id=\&#34;查看数据库隔离级别\&#34;&gt;查看数据库隔离级别&lt;/h4&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-sql\&#34;&gt;mysql&amp;gt; select @@global.tx_isolation, @@tx_isolation;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;acid实现原理\&#34;&gt;ACID实现原理&lt;/h2&gt;\n&lt;h3 id=\&#34;原子性\&#34;&gt;原子性&lt;/h3&gt;\n&lt;p&gt;实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB实现回滚，依赖的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log，如果事务执行失败或调用rollback，导致事务需要回滚，便可以利用undo log中的信息将数据进行回滚。undo log其实就是记录数据修改时的相反操作。&lt;/p&gt;\n&lt;h3 id=\&#34;持久性\&#34;&gt;持久性&lt;/h3&gt;\n&lt;p&gt;实现持久性主要依赖redo log，redo log采用WAL，所有修改先写入日志，再更新到Buffer Pool，保证了数据库不会因意外宕机而丢失。写redo log是要比刷缓存到磁盘要快的，原因如下：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;刷脏是随机IO、这个很好理解；而redo log是追加操作，属于顺序IO，所以速度快；&lt;/li&gt;\n&lt;li&gt;刷脏是以Page为单位的，Mysql默认页大小是16KB，一个Page上一个小的修改都需要整页写入；而redo log中只包含真正需要写入的部分，无效IO减少；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;关于binlog和redo log的区别：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;作用不同：redo log是用于crash recovery的，保证MySQL宕机也不会影响持久性；binlog是用于point-in-time recovery的，保证服务器可以基于时间点恢复数据，此外binlog还用于主从复制。&lt;/li&gt;\n&lt;li&gt;层次不同：redo log是InnoDB存储引擎实现的，而binlog是MySQL的服务器层实现的，同时支持InnoDB和其他存储引擎。&lt;/li&gt;\n&lt;li&gt;内容不同：redo log是物理日志，内容基于磁盘的Page；binlog的内容是二进制的，根据binlog_format参数的不同，可能基于sql语句、基于数据本身或者二者的混合。&lt;/li&gt;\n&lt;li&gt;写入时机不同：binlog在事务提交时写入；redo log的写入时机相对多元，可以通过双1设置进行控制；&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h3 id=\&#34;隔离性\&#34;&gt;隔离性&lt;/h3&gt;\n&lt;p&gt;隔离性追求的是并发条件下事务之间互不干扰；主要考虑两种场景：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;\n&lt;p&gt;两个事务的写操作之间的影响：&lt;/p&gt;\n&lt;ul&gt;\n&lt;li&gt;InnoDB通过锁机制来保证同一时刻只有一个事务进行写操作，简单理解为，事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据，其他事务需要等待该锁释放后才能对同一数据进行操作。&lt;/li&gt;\n&lt;li&gt;表锁会锁住整个表，并发性能较差；&lt;/li&gt;\n&lt;li&gt;行锁只锁定需要操作的数据，并发性能好，但数据较多时性能也会下降；绝大多数情况下，我们使用行锁即可；&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;两个事务的读操作之间的影响：&lt;/p&gt;\n&lt;p&gt;Mysql中默认的隔离级别是RR，InnoDB实现的RR可以避免幻读的问题，即使用MVCC技术，Multi-Version Concurrency Control。&lt;/p&gt;\n&lt;p&gt;MVCC最大的优点是读不加锁，因此读写不冲突，并发性好。InnoDB实现MVCC，多个版本的数据可以共存，主要依赖以下技术和数据结构：&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;数据库需要做好版本控制，防止不该被事务看到的数据(例如还没提交的事务修改的数据)被看到。在InnoDB中，主要是通过使用readview的技术来实现判断。查询出来的每一行记录，都会用readview来判断一下当前这行是否可以被当前事务看到，如果可以，则输出，否则就利用undolog来构建历史版本，再进行判断，知道记录构建到最老的版本或者可见性条件满足。\n\n在trx_sys中，一直维护这一个全局的活跃的读写事务id(trx_sys-&amp;gt;descriptors)，id按照从小到大排序，表示在某个时间点，数据库中所有的活跃(已经开始但还没提交)的读写(必须是读写事务，只读事务不包含在内)事务。当需要一个一致性读的时候(即创建新的readview时)，会把全局读写事务id拷贝一份到readview本地(read_view_t-&amp;gt;descriptors)，当做当前事务的快照。read_view_t-&amp;gt;up_limit_id是read_view_t-&amp;gt;descriptors这数组中最小的值，read_view_t-&amp;gt;low_limit_id是创建readview时的max_trx_id，即一定大于read_view_t-&amp;gt;descriptors中的最大值。当查询出一条记录后(记录上有一个trx_id，表示这条记录最后被修改时的事务id)，可见性判断的逻辑如下(lock_clust_rec_cons_read_sees)：\n\n如果记录上的trx_id小于read_view_t-&amp;gt;up_limit_id，则说明这条记录的最后修改在readview创建之前，因此这条记录可以被看见。\n\n如果记录上的trx_id大于等于read_view_t-&amp;gt;low_limit_id，则说明这条记录的最后修改在readview创建之后，因此这条记录肯定不可以被看家。\n\n如果记录上的trx_id在up_limit_id和low_limit_id之间，且trx_id在read_view_t-&amp;gt;descriptors之中，则表示这条记录的最后修改是在readview创建之时，被另外一个活跃事务所修改，所以这条记录也不可以被看见。如果trx_id不在read_view_t-&amp;gt;descriptors之中，则表示这条记录的最后修改在readview创建之前，所以可以看到。\n\n基于上述判断，如果记录不可见，则尝试使用undo去构建老的版本(row_vers_build_for_consistent_read)，直到找到可以被看见的记录或者解析完所有的undo。\n\n针对RR隔离级别，在第一次创建readview后，这个readview就会一直持续到事务结束，也就是说在事务执行过程中，数据的可见性不会变，所以在事务内部不会出现不一致的情况。针对RC隔离级别，事务中的每个查询语句都单独构建一个readview，所以如果两个查询之间有事务提交了，两个查询读出来的结果就不一样。从这里可以看出，在InnoDB中，RR隔离级别的效率是比RC隔离级别的高。此外，针对RU隔离级别，由于不会去检查可见性，所以在一条SQL中也会读到不一致的数据。针对串行化隔离级别，InnoDB是通过锁机制来实现的，而不是通过多版本控制的机制，所以性能很差。\n\n由于readview的创建涉及到拷贝全局活跃读写事务id，所以需要加上trx_sys-&amp;gt;mutex这把大锁，为了减少其对性能的影响，关于readview有很多优化。例如，如果前后两个查询之间，没有产生新的读写事务，那么前一个查询创建的readview是可以被后一个查询复用的。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;操作指令：&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ol&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-sql\&#34;&gt;mysql&amp;gt; select * from information_schema.innodb_locks; #锁的概况\nmysql&amp;gt; show engine innodb status;                     #InnoDB整体状态，其中包括锁的情况\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h3 id=\&#34;一致性\&#34;&gt;一致性&lt;/h3&gt;\n&lt;p&gt;一致性是事务追求的终极目标，原子性、持久性和隔离性，都是为了实现一致性而存在的；实现一致性也需要应用层面进行保障；&lt;/p&gt;\n&lt;h3 id=\&#34;运维相关指令和参数\&#34;&gt;运维相关指令和参数&lt;/h3&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1、首先介绍一下information_schema中的三张表: innodb_trx, innodb_locks和innodb_lock_waits。由于这些表几乎需要查询所有事务子系统的核心数据结构，为了减少查询对系统性能的影响，InnoDB预留了一块内存，内存里面存了相关数据的副本，如果两次查询的时间小于0.1秒(CACHE_MIN_IDLE_TIME_US)，则访问的都是同一个副本。如果超过0.1秒，则这块内存会做一次更新，每次更新会把三张表用到的所有数据统一更新一遍，因为这三张表经常需要做表连接操作，所以一起更新能保证数据的一致性。这里简单介绍一下innodb_trx表中的字段，另外两张表涉及到事物锁的相关信息，由于篇幅限制，后续有机会在介绍。\n\ntrx_id: 就是trx_t中的事务id，如果是只读事务，这个id跟trx_t的指针地址有关，所以可能是一个很大的数字(trx_get_id_for_print)。\ntrx_weight: 这个是事务的权重，计算方法就是undolog数量加上事务已经加上锁的数量。在事务回滚的时候，优先选择回滚权重小的事务，有非事务引擎参与的事务被认为权重是最大的。\ntrx_rows_modified：这个就是当前事务已经产生的undolog数量，每更新一条记录一次，就会产生一条undo。\ntrx_concurrency_tickets: 每次这个事务需要进入InnoDB层时，这个值都会减一，如果减到0，则事务需要等待(压力大的情况下)。\ntrx_is_read_only: 如果是以start transaction read only启动事务的，那么这个字段是1，否则为0。\ntrx_autocommit_non_locking: 如果一个事务是一个普通的select语句(后面没有跟for update, share lock等)，且当时的autocommit为1，则这个字段为1，否则为0。\ntrx_state: 表示事务当前的状态，只能有RUNNING, LOCK WAIT, ROLLING BACK, COMMITTING这几种状态, 是比较粗粒度的状态。\ntrx_operation_state: 表示事务当前的详细状态，相比于trx_state更加详细，例如有rollback to a savepoint, getting list of referencing foreign keys, rollback of internal trx on stats tables, dropping indexes等。\n\n2、与事务相关的undo参数\n\ninnodb_undo_directory: undo文件的目录，建议放在独立的一块盘上，尤其在经常有大事务的情况下。\ninnodb_undo_logs: 这个是定义了undo segment的个数。在给读写事务分配undo segment的时候，拿这个值去做轮训分配。\nInnodb_available_undo_logs: 这个是一个status变量，在启动的时候就确定了，表示的是系统上分配的undo segment。举个例子说明其与innodb_undo_logs的关系：假设系统初始化的时候innodb_undo_logs为128，则在文件上一定有128个undo segment，Innodb_available_undo_logs也为128，但是启动起来后，innodb_undo_logs动态被调整为100，则后续的读写事务只会使用到前100个回滚段，最后的20多个不会使用。\ninnodb_undo_tablespaces: 存放undo segment的物理文件个数，文件名为undoN，undo segment会比较均匀的分布在undo tablespace中。\n\n3、与Purge相关的参数\n\ninnodb_purge_threads: Purge Worker和Purge Coordinator总共的个数。在实际的实现中，使用多少个线程去做Purge是InnoDB根据实时负载进行动态调节的。\ninnodb_purge_batch_size: 一次性处理的undolog的数量，处理完这个数量后，Purge线程会计算是否需要sleep。\ninnodb_max_purge_lag: 如果全局历史链表超过这个值，就会增加Purge Worker线程的数量，也会使用sleep的方式delay用户的DML。\ninnodb_max_purge_lag_delay: 这个表示通过sleep方式delay用户DML最大的时间。\n\n4、与回滚相关的参数\n\ninnodb_lock_wait_timeout: 等待行锁的最大时间，如果超时，则会滚当前语句或者整个事务。发生回滚后返回类似错误：Lock wait timeout exceeded; try restarting transaction。\ninnodb_rollback_on_timeout: 如果这个参数为true，则当发生因为等待行锁而产生的超时时，回滚掉整个事务，否则只回滚当前的语句。这个就是隐式回滚机制。主要是为了兼容之前的版本。\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;总结\&#34;&gt;总结&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;原子性：语句要么全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；实现主要基于undo log&lt;/li&gt;\n&lt;li&gt;持久性：保证事务提交后不会因为宕机等原因导致数据丢失；实现主要基于redo log&lt;/li&gt;\n&lt;li&gt;隔离性：保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是RR，RR的实现主要基于锁机制（包含next-key lock）、MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView）&lt;/li&gt;\n&lt;li&gt;一致性：事务追求的最终目标，一致性的实现既需要数据库层面的保障，也需要应用层面的保障&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;参考文献\&#34;&gt;参考文献&lt;/h2&gt;\n&lt;h4 id=\&#34;httpmysqltaobaoorgmonthly20171201\&#34;&gt;http://mysql.taobao.org/monthly/2017/12/01/&lt;/h4&gt;\n&lt;h4 id=\&#34;httpswwwcnblogscomkismetvp10331633html\&#34;&gt;https://www.cnblogs.com/kismetv/p/10331633.html&lt;/h4&gt;\n&lt;h4 id=\&#34;httpszhuanlanzhihucomp40208895\&#34;&gt;https://zhuanlan.zhihu.com/p/40208895&lt;/h4&gt;\n&lt;h4 id=\&#34;httpswwwcnblogscomhuanongyingp7021555html\&#34;&gt;https://www.cnblogs.com/huanongying/p/7021555.html&lt;/h4&gt;\n&#34;,&#34;fileName&#34;:&#34;mysql-shi-wu-ge-chi-ji-bie-ji-shi-xian&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Mysql事务隔离级别及实现&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;mysql&#34;,&#34;slug&#34;:&#34;lEg5TWDNv&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/lEg5TWDNv/&#34;}],&#34;date&#34;:&#34;2021-01-18 16:12:13&#34;,&#34;dateFormat&#34;:&#34;2021-01-18&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/mysql-shi-wu-ge-chi-ji-bie-ji-shi-xian/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;12 min read&#34;,&#34;time&#34;:712000,&#34;words&#34;:3270,&#34;minutes&#34;:12},&#34;description&#34;:&#34;四个基本要素（ACID）\n\n原子性（Atomicity）\n一致性（Consistency）\n隔离性（Isolation）\n持久性（Durability）\n\n事务的并发问题\n\n脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读到的数...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9B%9B%E4%B8%AA%E5%9F%BA%E6%9C%AC%E8%A6%81%E7%B4%A0acid\&#34;&gt;四个基本要素（ACID）&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%98\&#34;&gt;事务的并发问题&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB\&#34;&gt;事务隔离级别&lt;/a&gt;&lt;br&gt;\n*\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB\&#34;&gt;查看数据库隔离级别&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#acid%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86\&#34;&gt;ACID实现原理&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E5%AD%90%E6%80%A7\&#34;&gt;原子性&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%8C%81%E4%B9%85%E6%80%A7\&#34;&gt;持久性&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E9%9A%94%E7%A6%BB%E6%80%A7\&#34;&gt;隔离性&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%80%E8%87%B4%E6%80%A7\&#34;&gt;一致性&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3%E6%8C%87%E4%BB%A4%E5%92%8C%E5%8F%82%E6%95%B0\&#34;&gt;运维相关指令和参数&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%80%BB%E7%BB%93\&#34;&gt;总结&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\&#34;&gt;参考文献&lt;/a&gt;&lt;br&gt;\n*\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#httpmysqltaobaoorgmonthly20171201\&#34;&gt;http://mysql.taobao.org/monthly/2017/12/01/&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#httpswwwcnblogscomkismetvp10331633html\&#34;&gt;https://www.cnblogs.com/kismetv/p/10331633.html&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#httpszhuanlanzhihucomp40208895\&#34;&gt;https://zhuanlan.zhihu.com/p/40208895&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#httpswwwcnblogscomhuanongyingp7021555html\&#34;&gt;https://www.cnblogs.com/huanongying/p/7021555.html&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;准备机器\&#34;&gt;准备机器&lt;/h2&gt;\n&lt;p&gt;两台centos7系统服务器：&lt;/p&gt;\n&lt;p&gt;主mysql：192.168.50.1&lt;/p&gt;\n&lt;p&gt;从mysql：192.168.50.2&lt;/p&gt;\n&lt;h2 id=\&#34;安装mysql\&#34;&gt;安装mysql&lt;/h2&gt;\n&lt;ol&gt;\n&lt;li&gt;\n&lt;p&gt;下载yum源&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;安装yum源&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;rpm -Uvh mysql80-community-release-el7-3.noarch.rpm\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;安装mysql&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;yum install -y mysql-community-server\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;启动mysql，并获取root初始密码&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# 确保selinux为disabled\n# 确保关闭了firewalld服务\n\nsystemctl start mysqld\n\n[root@localhost ~]# grep password /var/log/mysqld.log \n2020-10-19T02:47:35.912896Z 1 [Note] A temporary password is generated for root@localhost: -1k-1KjU*LG)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;登入mysql，并重置root密码&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;mysql -uroot -p \nmysql&amp;gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;qUXmZP11JwJ_11&#39;; # root本地访问，且重置\nmysql&amp;gt; exit\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;主mysql数据库配置\&#34;&gt;主Mysql数据库配置&lt;/h2&gt;\n&lt;p&gt;编辑my.cnf配置文件&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;vim /etc/my.cnf\n\n[mysqld]\nport=9006          #指定新的端口\nserver-id=110      #设置主服务器的ID(不能和别的服务器重复，建议使用ip的最后一段)\nlog-bin=mysql-bin  #binlog日志文件名\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;创建用于主从同步的账户&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;$ mysql -u root -p  #登录MySQL\nmysql&amp;gt; CREATE USER &#39;repl&#39;@&#39;192.168.50.2&#39; IDENTIFIED WITH mysql_native_password BY &#39;Top_master_1&#39;; # 主库创建用于从库同步的账号\nmysql&amp;gt; grant replication slave on *.* to &#39;repl&#39;@&#39;192.168.50.2&#39;;  #赋予主从同步权限，指定具体的数据库在/etc/my.cnf中完成\nmysql&amp;gt; flush privileges;\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;重启MySQL，使my.cnf 配置生效；查看主库状态&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;$ systemctl restart mysqld #重启MySQL\nmysql -u root -p\nmysql&amp;gt; show master status; #查看主库的状态  File,Position 这两个值需要放到slave配置中\n+--------------------+----------+--------------+------------------+-------------------+\n| File               | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+--------------------+----------+--------------+------------------+-------------------+\n| mysql-bin.00001    |      156 |     xxxx     |                  |                   |\n+--------------------+----------+--------------+------------------+-------------------+\n1 row in set (0.00 sec)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;从mysql数据库配置\&#34;&gt;从Mysql数据库配置&lt;/h2&gt;\n&lt;p&gt;编辑配置文件&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;vim /etc/my.cnf\n\n[mysqld]\nport=9006\nserver-id=111\n&lt;/code&gt;&lt;/pre&gt;\n&lt;p&gt;配置完成后，重启从库的MySQL&lt;/p&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;$ systemctl restart mysqld  #重启MySQL\n$ mysql -u root -p          #登录mysql\nmysql&amp;gt; stop slave;          #关闭从库\nmysql&amp;gt; change master to master_host=&#39;192.168.50.1&#39;,master_port=9006,master_user=&#39;repl&#39;,master_password=&#39;Top_master_1&#39;,master_log_file=&#39;mysql-bin.00001&#39;,master_log_pos=156; #配置主库信息\nmysql&amp;gt; start slave;            #开启从库 \nmysql&amp;gt; show slave status \\G;   #Slave_IO_Running,Slave_SQL_Running 都为Yes的时候表示配置成功\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;主库创建数据库和数据表\&#34;&gt;主库创建数据库和数据表&lt;/h2&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-sql\&#34;&gt;create database topmanager DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;\n登入从库，可以看到从库中出现同样的数据库和数据表，表明已同步&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;mysql-zhu-cong-fu-zhi-huan-jing-da-jian&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Mysql主从复制环境搭建&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;mysql&#34;,&#34;slug&#34;:&#34;lEg5TWDNv&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/lEg5TWDNv/&#34;}],&#34;date&#34;:&#34;2021-01-15 10:15:27&#34;,&#34;dateFormat&#34;:&#34;2021-01-15&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-huan-jing-da-jian/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;3 min read&#34;,&#34;time&#34;:151000,&#34;words&#34;:533,&#34;minutes&#34;:3},&#34;description&#34;:&#34;准备机器\n两台centos7系统服务器：\n主mysql：192.168.50.1\n从mysql：192.168.50.2\n安装mysql\n\n\n下载yum源\nwget https://dev.mysql.com/get/mysql80-com...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%87%86%E5%A4%87%E6%9C%BA%E5%99%A8\&#34;&gt;准备机器&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%AE%89%E8%A3%85mysql\&#34;&gt;安装mysql&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%BBmysql%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE\&#34;&gt;主Mysql数据库配置&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BB%8Emysql%E6%95%B0%E6%8D%AE%E5%BA%93%E9%85%8D%E7%BD%AE\&#34;&gt;从Mysql数据库配置&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%BB%E5%BA%93%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E6%95%B0%E6%8D%AE%E8%A1%A8\&#34;&gt;主库创建数据库和数据表&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h2 id=\&#34;一-参数及设置说明\&#34;&gt;一、参数及设置说明&lt;/h2&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;# innodb_flush_log_at_trx_commit\n1.设置为0：log buffer将每秒一次地写入log file中，并且log file的flush操作同时进行；该模式下，在事务提交时，不会主动触发写入磁盘的操作；\n2.设置为1：每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去;\n3.设置为2：每次事务提交时MySQL都会把log buffer的数据写入log file，但是flush(刷到磁盘)操作并不会同时进行。该模式下,MySQL会每秒执行一次 flush(刷到磁盘)操作。\n\n# sync_binlog\nsync_binlog 的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。\n当sync_binlog =N (N&amp;gt;0) ，MySQL 在每写 N次 二进制日志binary log时，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去。\n\n注意：如果启用了autocommit，那么每一个语句statement就会有一次写操作；否则每个事务对应一个写操作。\n\n# 性能与安全性对比 \n1.双1设置时，写入性能最差，安全性最高；\n2.sync_binlog=N (N&amp;gt;1 ) innodb_flush_log_at_trx_commit=2 时，性能最好，安全性较差；\n3.innodb_flush_log_at_trx_commit设置为0，mysqld进程崩溃会导致上一秒钟所有事务数据的丢失；\n4.innodb_flush_log_at_trx_commit设置为2，当系统崩溃或者断电时，上一秒的所有数据才有可能丢失；\n&lt;/code&gt;&lt;/pre&gt;\n&lt;h2 id=\&#34;二-对io影响较大的几个参数\&#34;&gt;二、对IO影响较大的几个参数&lt;/h2&gt;\n&lt;pre&gt;&lt;code class=\&#34;language-shell\&#34;&gt;1.innodb_buffer_pool_size # 该参数控制innodb缓存大小，用于缓存应用访问的数据，推荐配置为系统可用内存的80%。\n2.binlog_cache_size       # 该参数控制二进制日志缓冲大小，当事务还没有提交时，事务日志存放于cache，当遇到大事务cache不够用的时，mysql会把uncommitted的部分写入临时文件,等到committed的时候才会写入正式的持久化日志文件。\n3.innodb_max_dirty_pages_pct     # 该参数可以直接控制Dirty Page在BP中所占的比率，当dirty page达到了该参数的阈值，就会触发MySQL系统刷新数据到磁盘。\n4.innodb_flush_log_at_trx_commit # 该参数确定日志文件何时write、flush。\n5.sync_binlog         # sync_binlog的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。\n6.innodb_flush_method # 该参数控制日志或数据文件如何write、flush。可选的值为fsync，o_dsync，o_direct，littlesync，nosync。\n&lt;/code&gt;&lt;/pre&gt;\n&#34;,&#34;fileName&#34;:&#34;mysql-shuang-1-she-zhi-shu-ju-an-quan-de-guan-jian-can-shu&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Mysql双1设置-数据安全的关键参数&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;mysql&#34;,&#34;slug&#34;:&#34;lEg5TWDNv&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/lEg5TWDNv/&#34;}],&#34;date&#34;:&#34;2021-01-15 10:14:24&#34;,&#34;dateFormat&#34;:&#34;2021-01-15&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/mysql-shuang-1-she-zhi-shu-ju-an-quan-de-guan-jian-can-shu/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;3 min read&#34;,&#34;time&#34;:142000,&#34;words&#34;:633,&#34;minutes&#34;:3},&#34;description&#34;:&#34;一、参数及设置说明\n# innodb_flush_log_at_trx_commit\n1.设置为0：log buffer将每秒一次地写入log file中，并且log file的flush操作同时进行；该模式下，在事务提交时，不会主动触发写...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%80-%E5%8F%82%E6%95%B0%E5%8F%8A%E8%AE%BE%E7%BD%AE%E8%AF%B4%E6%98%8E\&#34;&gt;一、参数及设置说明&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%BA%8C-%E5%AF%B9io%E5%BD%B1%E5%93%8D%E8%BE%83%E5%A4%A7%E7%9A%84%E5%87%A0%E4%B8%AA%E5%8F%82%E6%95%B0\&#34;&gt;二、对IO影响较大的几个参数&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;p&gt;数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库性能的目的。&lt;/p&gt;\n&lt;h2 id=\&#34;垂直切分\&#34;&gt;垂直切分&lt;/h2&gt;\n&lt;p&gt;&lt;img src=\&#34;https://esp0x.github.io/post-images/1610676801903.jpg\&#34; alt=\&#34;\&#34; loading=\&#34;lazy\&#34;&gt;&lt;br&gt;\n垂直切分常见有垂直分库和垂直分表两种：&lt;/p&gt;\n&lt;p&gt;垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库中。类似微服务架构，每一个微服务单独使用一个数据库的形式。&lt;/p&gt;\n&lt;p&gt;垂直分表是基于数据库中的列进行， 针对某个表字段过多，可以新建一张扩展表，将不常用的字段或长度较大的字段拆分到扩展表中。这样可以避免跨页问题，MySQL底层是通过数据页存储的，一条记录过大会导致跨页，造成额外的性能损失。&lt;/p&gt;\n&lt;h3 id=\&#34;垂直切分的优点\&#34;&gt;垂直切分的优点：&lt;/h3&gt;\n&lt;ol&gt;\n&lt;li&gt;解决业务系统层面的耦合，使得业务逻辑更清晰；&lt;/li&gt;\n&lt;li&gt;与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等；&lt;/li&gt;\n&lt;li&gt;高并发场景下，垂直切分一定程度上能够提升访问性能；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h3 id=\&#34;垂直切分的缺点\&#34;&gt;垂直切分的缺点：&lt;/h3&gt;\n&lt;ol&gt;\n&lt;li&gt;部分表无法join，只能通过接口方式，开发难度增加；&lt;/li&gt;\n&lt;li&gt;分布式事务处理复杂；&lt;/li&gt;\n&lt;li&gt;没有解决单表数据过大的问题；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;水平切分\&#34;&gt;水平切分&lt;/h2&gt;\n&lt;p&gt;&lt;img src=\&#34;https://esp0x.github.io/post-images/1610676821810.jpg\&#34; alt=\&#34;\&#34; loading=\&#34;lazy\&#34;&gt;&lt;br&gt;\n当一个应用难以再细粒化的垂直切分，或切分后单表数据量过大，存在读写性能问题时，就需要考虑水平切分了。&lt;/p&gt;\n&lt;p&gt;水平切分包括库内分表和分库分表，库内分表只解决了单一表数据量过大的问题，没有将表分布到不同的机器上，对于数据库访问性能提升有限。&lt;/p&gt;\n&lt;h3 id=\&#34;水平切分的优点\&#34;&gt;水平切分的优点：&lt;/h3&gt;\n&lt;ol&gt;\n&lt;li&gt;不存在单表数据量过大问题，提升了表的访问性能；&lt;/li&gt;\n&lt;li&gt;应用端改造较小，不需要进行业务拆分；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h3 id=\&#34;水平切分的缺点\&#34;&gt;水平切分的缺点：&lt;/h3&gt;\n&lt;ol&gt;\n&lt;li&gt;跨分片事务的一致性难以保证；&lt;/li&gt;\n&lt;li&gt;跨库的join关联查询性能较差；&lt;/li&gt;\n&lt;li&gt;数据库多次扩展难度和维护量增加；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;几种典型的数据分片规则\&#34;&gt;几种典型的数据分片规则&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;根据数值范围&lt;/p&gt;\n&lt;p&gt;例如：按照时间维度，将不同月，甚至不同日的数据存储到不同的表；又或者，按照userId进行划分，1-9999的记录分到第一个库，10000-20000的分到第二个库，以此类推；&lt;/p&gt;\n&lt;p&gt;优点：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;单表大小可控；&lt;/li&gt;\n&lt;li&gt;天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点，无需对其他分片进行数据迁移；&lt;/li&gt;\n&lt;li&gt;使用分片字段进行查询时，速度更快；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;缺点：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;热点数据成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间的数据，可能会被频繁地读写，有些分片存储历史数据，则很少被查询。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;根据数值取模&lt;/p&gt;\n&lt;p&gt;一般采用hash取模mod的切分方式。&lt;/p&gt;\n&lt;p&gt;优点：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;p&gt;缺点：&lt;/p&gt;\n&lt;ol&gt;\n&lt;li&gt;后期扩展时，需要迁移旧的数据；（通过一致性hash算法可以避免这个问题）&lt;/li&gt;\n&lt;li&gt;容易面临跨分片查询的复杂问题，比如频繁查询中不包含分片字段，将会导致无法定位数据库，从而向所有数据库发起请求，再在内存中合并数据，性能损失严重；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h2 id=\&#34;分库分表需要解决的问题\&#34;&gt;分库分表需要解决的问题&lt;/h2&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;p&gt;事务问题&lt;/p&gt;\n&lt;p&gt;方案一：使用分布式事务，交由数据库管理，简单有效；缺点是随着节点增加，性能代价越来越高。（需要协调的节点变多）&lt;/p&gt;\n&lt;p&gt;方案二：由应用程序和数据库共同控制，性能上有优势；缺点是开发难度较大；&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;跨节点Join问题&lt;/p&gt;\n&lt;p&gt;分两次查询，第一次查询的结果集中找出关联数据的ID，根据这些ID发起第二次请求得到关联数据；在应用设计时应尽量避免进行关联查询；&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;跨节点的count、order by、group by以及聚合函数问题&lt;/p&gt;\n&lt;p&gt;分别在各个节点进行数据合并，最后在统一进行合并，缺点是当数据集较大时，占用的内存资源很多；&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;数据迁移、容量规划、扩容等问题&lt;/p&gt;\n&lt;p&gt;当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;全局主键避重问题&lt;/p&gt;\n&lt;p&gt;由于表同时存在于多个数据库中，主键值设置为自增序列将不能使用，需要单独设计全局主键，一般可以用UUID的方案解决；&lt;/p&gt;\n&lt;/li&gt;\n&lt;li&gt;\n&lt;p&gt;跨分片的排序分页&lt;/p&gt;\n&lt;p&gt;一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。&lt;/p&gt;\n&lt;p&gt;如果是在前台应用提供分页，则限定用户只能看前面n页，这个限制在业务上也是合理的，一般看后面的分页意义不大（如果一定要看，可以要求用户缩小范围重新查询）。&lt;/p&gt;\n&lt;p&gt;如果是后台批处理任务要求分批获取数据，则可以加大page size，比如每次获取5000条记录，有效减少分页数（当然离线访问一般走备库，避免冲击主库）。&lt;/p&gt;\n&lt;p&gt;分库设计时，一般还有配套大数据平台汇总所有分库的记录，有些分页查询可以考虑走大数据平台。&lt;/p&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;,&#34;fileName&#34;:&#34;mysql-fen-ku-fen-biao-ce-lue&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Mysql分库分表策略&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;mysql&#34;,&#34;slug&#34;:&#34;lEg5TWDNv&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/lEg5TWDNv/&#34;}],&#34;date&#34;:&#34;2021-01-15 10:12:20&#34;,&#34;dateFormat&#34;:&#34;2021-01-15&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/mysql-fen-ku-fen-biao-ce-lue/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;6 min read&#34;,&#34;time&#34;:353000,&#34;words&#34;:1746,&#34;minutes&#34;:6},&#34;description&#34;:&#34;数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库性能的目的。\n垂直切分\n\n垂直切分常见有垂直分库和垂直分表两种：\n垂直分库就是根据业务耦合性，将关联度低的...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9E%82%E7%9B%B4%E5%88%87%E5%88%86\&#34;&gt;垂直切分&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9E%82%E7%9B%B4%E5%88%87%E5%88%86%E7%9A%84%E4%BC%98%E7%82%B9\&#34;&gt;垂直切分的优点：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%9E%82%E7%9B%B4%E5%88%87%E5%88%86%E7%9A%84%E7%BC%BA%E7%82%B9\&#34;&gt;垂直切分的缺点：&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%B0%B4%E5%B9%B3%E5%88%87%E5%88%86\&#34;&gt;水平切分&lt;/a&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%B0%B4%E5%B9%B3%E5%88%87%E5%88%86%E7%9A%84%E4%BC%98%E7%82%B9\&#34;&gt;水平切分的优点：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E6%B0%B4%E5%B9%B3%E5%88%87%E5%88%86%E7%9A%84%E7%BC%BA%E7%82%B9\&#34;&gt;水平切分的缺点：&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%87%A0%E7%A7%8D%E5%85%B8%E5%9E%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87%E8%A7%84%E5%88%99\&#34;&gt;几种典型的数据分片规则&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E9%9C%80%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98\&#34;&gt;分库分表需要解决的问题&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;h3 id=\&#34;原理图如下\&#34;&gt;原理图如下：&lt;/h3&gt;\n&lt;figure data-type=\&#34;image\&#34; tabindex=\&#34;1\&#34;&gt;&lt;img src=\&#34;https://esp0x.github.io/post-images/1610671157156.png\&#34; alt=\&#34;\&#34; loading=\&#34;lazy\&#34;&gt;&lt;/figure&gt;\n&lt;h2 id=\&#34;主从复制流程详解\&#34;&gt;主从复制流程详解：&lt;/h2&gt;\n&lt;ol&gt;\n&lt;li&gt;master库发生数据改变时，会将改变写入binglog日志；&lt;/li&gt;\n&lt;li&gt;slave库会在一定时间间隔内对master的binlog进行检测以确定是否发生改变，如果发生改变，则开始一个IO thread请求master二进制事件；&lt;/li&gt;\n&lt;li&gt;同时，master为每一个过来请求的IO thread开启一个dump线程，用于将二进制事件发送给IO thread，slave的IO thread将此二进制事件写入本地relay log（中继日志）中，并开启SQL thread从中继日志中读取二进制日志，在本地进行重放（replay），从而使得本地数据与master保持一致；最后IO thread和SQL thread进入睡眠状态，等待下次唤醒。&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;主从复制形式\&#34;&gt;主从复制形式：&lt;/h2&gt;\n&lt;ol&gt;\n&lt;li&gt;主从&lt;/li&gt;\n&lt;li&gt;主主&lt;/li&gt;\n&lt;li&gt;一主多从&lt;/li&gt;\n&lt;li&gt;多主一从&lt;/li&gt;\n&lt;li&gt;联级复制&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;主从同步延时分析\&#34;&gt;主从同步延时分析：&lt;/h2&gt;\n&lt;ol&gt;\n&lt;li&gt;master对所有DDL和DML产生的日志都写入binlog，由于是顺序写，所以效率很高；反之，slave的SQL thread进行relay log的重放时，DML和DDL的IO是随机的，不是顺序，所以成本较高，这里会增加一部分延时；&lt;/li&gt;\n&lt;li&gt;由于SQL thread是单线程的，当master的并发较高时，过多的DML可能会导致slave的SQL thread来不及处理，这里会增加一部分延时；&lt;/li&gt;\n&lt;li&gt;slave中有部分SQL产生了锁等待，这种情况就是slave有一些读请求与重放请求产生了锁冲突导致的，也会增加延时；&lt;/li&gt;\n&lt;li&gt;slave在充当读库角色的时候，如果查询访问压力过大，会消耗部分系统资源，影响同步效率；&lt;/li&gt;\n&lt;li&gt;大事务执行，即当master有大事务执行时，比如执行了10分钟，binlog写入必须要等待事务处理完毕，那么slave开始进行同步的时候就已经延时10分钟了；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;延时解决办法\&#34;&gt;延时解决办法：&lt;/h2&gt;\n&lt;ol&gt;\n&lt;li&gt;业务层实现读写分离，一主多从，主写从读，分散压力；&lt;/li&gt;\n&lt;li&gt;业务层和数据库层之间加入缓存策略，降低直接对数据库的读压力；频繁写的场景不适合加缓存，会导致缓存命中降低；&lt;/li&gt;\n&lt;li&gt;升级硬件；&lt;/li&gt;\n&lt;li&gt;MTS问题，即多线程的slave，从5.6版本开始支持，针对不同粒度（库、表、行）设置并行同步；&lt;/li&gt;\n&lt;/ol&gt;\n&lt;h2 id=\&#34;57版本后的并行复制策略\&#34;&gt;5.7版本后的并行复制策略&lt;/h2&gt;\n&lt;h4 id=\&#34;redo-log的两阶段提交\&#34;&gt;Redo log的两阶段提交&lt;/h4&gt;\n&lt;ul&gt;\n&lt;li&gt;先写redo，再写binlog：假设在redo写完，binlog还没有写完的时候，Mysql进程异常重启，这时仍然能够通过redo log恢复数据，但由于binlog没有这条记录，所以之后备份日志的时候，binlog是缺失这条记录的，以后需要用binlog恢复数据时，就会缺少一条数据的更新；&lt;/li&gt;\n&lt;li&gt;先写binlog，再写redo log：如果binlog写完后crash，由于redo log还没写，崩溃恢复后这个事务无效，但是binlog有记录，以后用这个binlog恢复数据时，就会多出一条更新记录；&lt;/li&gt;\n&lt;li&gt;二阶段提交：使用二阶段提交时，会综合redo和binlog的状态进行处理，如果写入binlog之前crash，那么由于redo处于prepare阶段，只需要对当前事务进行回滚即可；如果写入binlog之后crash，那么由于redo处于prepare阶段，只需要对当前事务进行提交即可。&lt;/li&gt;\n&lt;/ul&gt;\n&lt;h4 id=\&#34;并行复制的思想\&#34;&gt;并行复制的思想&lt;/h4&gt;\n&lt;ol&gt;\n&lt;li&gt;同时处于prepare状态的事务，在备库执行是可以并行的；&lt;/li&gt;\n&lt;li&gt;处于prepare状态的事务，与处于commit状态的事务之间，在备库执行也是可以并行的；&lt;/li&gt;\n&lt;li&gt;binlog_group_commit_sync_delay参数，表示延迟多少微妙后才调用fsync；&lt;/li&gt;\n&lt;li&gt;binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync；&lt;/li&gt;\n&lt;/ol&gt;\n&#34;,&#34;fileName&#34;:&#34;mysql-zhu-cong-fu-zhi-yuan-li&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;Mysql主从复制原理&#34;,&#34;tags&#34;:[{&#34;name&#34;:&#34;mysql&#34;,&#34;slug&#34;:&#34;lEg5TWDNv&#34;,&#34;used&#34;:true,&#34;link&#34;:&#34;https://esp0x.github.io/tag/lEg5TWDNv/&#34;}],&#34;date&#34;:&#34;2021-01-14 16:23:14&#34;,&#34;dateFormat&#34;:&#34;2021-01-14&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-yuan-li/&#34;,&#34;hideInList&#34;:false,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;4 min read&#34;,&#34;time&#34;:197000,&#34;words&#34;:922,&#34;minutes&#34;:4},&#34;description&#34;:&#34;原理图如下：\n\n主从复制流程详解：\n\nmaster库发生数据改变时，会将改变写入binglog日志；\nslave库会在一定时间间隔内对master的binlog进行检测以确定是否发生改变，如果发生改变，则开始一个IO thread请求mas...&#34;,&#34;toc&#34;:&#34;&lt;ul class=\&#34;markdownIt-TOC\&#34;&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%8E%9F%E7%90%86%E5%9B%BE%E5%A6%82%E4%B8%8B\&#34;&gt;原理图如下：&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3\&#34;&gt;主从复制流程详解：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%BD%A2%E5%BC%8F\&#34;&gt;主从复制形式：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%BB%B6%E6%97%B6%E5%88%86%E6%9E%90\&#34;&gt;主从同步延时分析：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%BB%B6%E6%97%B6%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95\&#34;&gt;延时解决办法：&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#57%E7%89%88%E6%9C%AC%E5%90%8E%E7%9A%84%E5%B9%B6%E8%A1%8C%E5%A4%8D%E5%88%B6%E7%AD%96%E7%95%A5\&#34;&gt;5.7版本后的并行复制策略&lt;/a&gt;&lt;br&gt;\n*\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\&#34;#redo-log%E7%9A%84%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4\&#34;&gt;Redo log的两阶段提交&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\&#34;#%E5%B9%B6%E8%A1%8C%E5%A4%8D%E5%88%B6%E7%9A%84%E6%80%9D%E6%83%B3\&#34;&gt;并行复制的思想&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/li&gt;\n&lt;/ul&gt;\n&#34;},{&#34;content&#34;:&#34;&lt;blockquote&gt;\n&lt;p&gt;系统管理员 &amp;amp; 独立安全研究员 &amp;amp; 半吊子的程序员 /&amp;lt;.&amp;gt;:) 😈&lt;/p&gt;\n&lt;/blockquote&gt;\n&#34;,&#34;fileName&#34;:&#34;about&#34;,&#34;abstract&#34;:&#34;&#34;,&#34;title&#34;:&#34;关于&#34;,&#34;tags&#34;:[],&#34;date&#34;:&#34;2019-01-25 19:09:48&#34;,&#34;dateFormat&#34;:&#34;2019-01-25&#34;,&#34;feature&#34;:&#34;&#34;,&#34;link&#34;:&#34;https://esp0x.github.io/post/about/&#34;,&#34;hideInList&#34;:true,&#34;isTop&#34;:false,&#34;stats&#34;:{&#34;text&#34;:&#34;1 min read&#34;,&#34;time&#34;:5000,&#34;words&#34;:23,&#34;minutes&#34;:1},&#34;description&#34;:&#34;\n系统管理员 &amp;amp; 独立安全研究员 &amp;amp; 半吊子的程序员 /&amp;lt;.&amp;gt;:) 😈\n\n&#34;,&#34;toc&#34;:&#34;&#34;}]";
  // var json = escape.substr(1, escape.length - 2);
  // var datas = json.split(',');
  // for (let i=0; i < datas.length; i++) {
  //   let item = datas[i];
  //   let attrs = item.split('34;:&#34')
  //   debugger
  //   console.log(datas[i])
  // }
  let escapeMap = new Map();
  escapeMap.set('&#34;', '"');
  escapeMap.set('&gt;', '>');
  escapeMap.set('&#39;', "'");
  escapeMap.set('&lt;', '<');
  escapeMap.set('&quot;', '"');
  escapeMap.set('&amp;', '&');
</script> -->

<script src="/media/js/mouse/peace.js"></script>


<script src=" /media/js/cool.js"></script>


</html>