<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://esp0x.github.io</id>
    <title>Grey</title>
    <updated>2021-02-03T06:15:53.107Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://esp0x.github.io"/>
    <link rel="self" href="https://esp0x.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://esp0x.github.io/images/avatar.png</logo>
    <icon>https://esp0x.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Grey</rights>
    <entry>
        <title type="html"><![CDATA[Nginx配置文件详解]]></title>
        <id>https://esp0x.github.io/post/nginx-pei-zhi-wen-jian-xiang-jie/</id>
        <link href="https://esp0x.github.io/post/nginx-pei-zhi-wen-jian-xiang-jie/">
        </link>
        <updated>2021-02-03T06:15:08.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-shell">######Nginx配置文件nginx.conf中文详解#####

#定义Nginx运行的用户和用户组
user www www;

#nginx进程数，建议设置为等于CPU总核心数。
worker_processes 8;
 
#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]
error_log /usr/local/nginx/logs/error.log info;

#进程pid文件
pid /usr/local/nginx/logs/nginx.pid;

#指定进程可以打开的最大描述符：数目
#工作模式与连接数上限
#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。
#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。
#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。
worker_rlimit_nofile 65535;

events
{
    use epoll;

    #单个进程最大连接数（最大连接数=连接数*进程数）
    worker_connections 65535;

    #keepalive超时时间。
    keepalive_timeout 60;

    #分页大小可以用命令getconf PAGESIZE 取得。
    #getconf PAGESIZE 设置为该值的整数倍
    client_header_buffer_size 4k;

    #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。
    open_file_cache max=65535 inactive=60s;

    #语法:open_file_cache_valid time 
    #默认值 60 
    #使用字段:http, server, location 
    #这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.
    open_file_cache_valid 80s;

    #语法:open_file_cache_min_uses number 
    #默认值: 1 
    #使用字段:http, server, location  
    #这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.
    open_file_cache_min_uses 1;
    
    #语法:open_file_cache_errors on | off 
    #默认值: off 
    #使用字段:http, server, location 
    #这个指令指定是否在搜索一个文件是记录cache错误.
    open_file_cache_errors on;
}
 
#设定http服务器，利用它的反向代理功能提供负载均衡支持
http
{
    #文件扩展名与文件类型映射表
    include mime.types;

    #默认文件类型
    default_type application/octet-stream;

    #默认编码
    #charset utf-8;

    #服务器名字的hash表大小
    #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.
    server_names_hash_bucket_size 128;

    #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。
    client_header_buffer_size 32k;

    #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。
    large_client_header_buffers 4 64k;

    #设定通过nginx上传文件的大小
    client_max_body_size 8m;

    #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。
    #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。
    sendfile on;

    #开启目录列表访问，合适下载服务器，默认关闭。
    autoindex on;

    #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用
    tcp_nopush on;
    tcp_nodelay on;

    #长连接超时时间，单位是秒
    keepalive_timeout 120;

    #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。
    fastcgi_connect_timeout 300;
    fastcgi_send_timeout 300;
    fastcgi_read_timeout 300;
    fastcgi_buffer_size 64k;
    fastcgi_buffers 4 64k;
    fastcgi_busy_buffers_size 128k;
    fastcgi_temp_file_write_size 128k;

    #gzip模块设置
    gzip on;               #开启gzip压缩输出
    gzip_min_length 1k;    #最小压缩文件大小
    gzip_buffers 4 16k;    #压缩缓冲区
    gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）
    gzip_comp_level 2;     #压缩等级
    gzip_types text/plain application/x-javascript text/css application/xml;    #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。
    gzip_vary on;

    #开启限制IP连接数的时候需要使用
    #limit_zone crawler $binary_remote_addr 10m;

    #负载均衡配置
    upstream piao.jd.com {
        #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。
        server 192.168.80.121:80 weight=3;
        server 192.168.80.122:80 weight=2;
        server 192.168.80.123:80 weight=3;

        #nginx的upstream目前支持4种方式的分配
        #1、轮询（默认）
        #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。
        #2、weight
        #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。
        #2、ip_hash
        #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。
        #例如：
        #upstream bakend {
        #    ip_hash;
        #    server 192.168.0.14:88;
        #    server 192.168.0.15:80;
        #}
        #3、fair（第三方）
        #按后端服务器的响应时间来分配请求，响应时间短的优先分配。
        #upstream backend {
        #    server server1;
        #    server server2;
        #    fair;
        #}
        #4、url_hash（第三方）
        #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。
        #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法
        #upstream backend {
        #    server squid1:3128;
        #    server squid2:3128;
        #    hash $request_uri;
        #    hash_method crc32;
        #}

        #tips:
        #upstream bakend{#定义负载均衡设备的Ip及设备状态}{
        #    ip_hash;
        #    server 127.0.0.1:9090 down;
        #    server 127.0.0.1:8080 weight=2;
        #    server 127.0.0.1:6060;
        #    server 127.0.0.1:7070 backup;
        #}
        #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;

        #每个设备的状态设置为:
        #1.down表示单前的server暂时不参与负载
        #2.weight为weight越大，负载的权重就越大。
        #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误
        #4.fail_timeout:max_fails次失败后，暂停的时间。
        #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。

        #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。
        #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug
        #client_body_temp_path设置记录文件的目录 可以设置最多3层目录
        #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡
    }
     
     
     
    #虚拟主机的配置
    server
    {
        #监听端口
        listen 80;

        #域名可以有多个，用空格隔开
        server_name www.jd.com jd.com;
        index index.html index.htm index.php;
        root /data/www/jd;

        #对******进行负载均衡
        location ~ .*.(php|php5)?$
        {
            fastcgi_pass 127.0.0.1:9000;
            fastcgi_index index.php;
            include fastcgi.conf;
        }
         
        #图片缓存时间设置
        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$
        {
            expires 10d;
        }
         
        #JS和CSS缓存时间设置
        location ~ .*.(js|css)?$
        {
            expires 1h;
        }
         
        #日志格式设定
        #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；
        #$remote_user：用来记录客户端用户名称；
        #$time_local： 用来记录访问时间与时区；
        #$request： 用来记录请求的url与http协议；
        #$status： 用来记录请求状态；成功是200，
        #$body_bytes_sent ：记录发送给客户端文件主体内容大小；
        #$http_referer：用来记录从那个页面链接访问过来的；
        #$http_user_agent：记录客户浏览器的相关信息；
        #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。
        log_format access '$remote_addr - $remote_user [$time_local] &quot;$request&quot; '
        '$status $body_bytes_sent &quot;$http_referer&quot; '
        '&quot;$http_user_agent&quot; $http_x_forwarded_for';
         
        #定义本虚拟主机的访问日志
        access_log  /usr/local/nginx/logs/host.access.log  main;
        access_log  /usr/local/nginx/logs/host.access.404.log  log404;
         
        #对 &quot;/&quot; 启用反向代理
        location / {
            proxy_pass http://127.0.0.1:88;
            proxy_redirect off;
            proxy_set_header X-Real-IP $remote_addr;
             
            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
             
            #以下是一些反向代理的配置，可选。
            proxy_set_header Host $host;

            #允许客户端请求的最大单文件字节数
            client_max_body_size 10m;

            #缓冲区代理缓冲用户端请求的最大字节数，
            #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。
            #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误
            client_body_buffer_size 128k;

            #表示使nginx阻止HTTP应答代码为400或者更高的应答。
            proxy_intercept_errors on;

            #后端服务器连接的超时时间_发起握手等候响应超时时间
            #nginx跟后端服务器连接超时时间(代理连接超时)
            proxy_connect_timeout 90;

            #后端服务器数据回传时间(代理发送超时)
            #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据
            proxy_send_timeout 90;

            #连接成功后，后端服务器响应时间(代理接收超时)
            #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）
            proxy_read_timeout 90;

            #设置代理服务器（nginx）保存用户头信息的缓冲区大小
            #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小
            proxy_buffer_size 4k;

            #proxy_buffers缓冲区，网页平均在32k以下的设置
            #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k
            proxy_buffers 4 32k;

            #高负荷下缓冲大小（proxy_buffers*2）
            proxy_busy_buffers_size 64k;

            #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长
            #设定缓存文件夹大小，大于这个值，将从upstream服务器传
            proxy_temp_file_write_size 64k;
        }
         
        #设定查看Nginx状态的地址
        location /NginxStatus {
            stub_status on;
            access_log on;
            auth_basic &quot;NginxStatus&quot;;
            auth_basic_user_file confpasswd;
            #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。
        }
         
        #本地动静分离反向代理配置
        #所有jsp的页面均交由tomcat或resin处理
        location ~ .(jsp|jspx|do)?$ {
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_pass http://127.0.0.1:8080;
        }
         
        #所有静态文件由nginx直接读取不经过tomcat或resin
        location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|
        pdf|xls|mp3|wma)$
        {
            expires 15d; 
        }
         
        location ~ .*.(js|css)?$
        {
            expires 1h;
        }
    }
}
######Nginx配置文件nginx.conf中文详解#####
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[nc命令使用]]></title>
        <id>https://esp0x.github.io/post/nc-ming-ling-shi-yong/</id>
        <link href="https://esp0x.github.io/post/nc-ming-ling-shi-yong/">
        </link>
        <updated>2021-02-03T01:27:30.000Z</updated>
        <content type="html"><![CDATA[<h3 id="端口扫描">端口扫描</h3>
<pre><code class="language-shell"># nc -vz -w 5 127.0.0.1 1-1024   // 扫描本地1-1024端口范围
</code></pre>
<h3 id="监听端口">监听端口</h3>
<pre><code class="language-shell"># nc -l 8000     // 监听TCP端口
# nc -ul 9999    // 监听UDP端口
# nc -vuz 127.0.0.1 9999   // 测试本地UDP端口
</code></pre>
<h3 id="传输文件">传输文件</h3>
<pre><code class="language-shell">1.上传
# nc -l 9999 &gt; filename
# nc 127.0.0.1 9999 &lt; source

2.下载
# nc -l 9999 &lt; filename
# nc 127.0.0.1 9999 &gt; target
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[StorCLI工具使用说明]]></title>
        <id>https://esp0x.github.io/post/storcli-gong-ju-shi-yong-shuo-ming/</id>
        <link href="https://esp0x.github.io/post/storcli-gong-ju-shi-yong-shuo-ming/">
        </link>
        <updated>2021-02-01T01:59:11.000Z</updated>
        <content type="html"><![CDATA[<h3 id="记录一下storcli工具的基本查询方法主要用于实现监控目的对于更改raid的相关命令暂时不在这里记录">记录一下storcli工具的基本查询方法，主要用于实现监控目的，对于更改Raid的相关命令暂时不在这里记录。</h3>
<h3 id="获取帮助信息">获取帮助信息</h3>
<pre><code class="language-shell"># ./storcli64 -h
     Storage Command Line Tool  Ver 1.23.02 Mar 28, 2017

     (c)Copyright 2017, AVAGO Corporation, All Rights Reserved.

storcli -v 
storcli -h| -help| ? 
storcli -h| -help| ? legacy
storcli show 
storcli show all
storcli show ctrlcount
storcli show file=&lt;filepath&gt;
storcli /cx add vd r[0|1|5|6|00|10|50|60]
...
</code></pre>
<h3 id="显示raid卡相关信息">显示Raid卡相关信息</h3>
<pre><code class="language-shell"># ./storcli64 show all
Status Code = 0
Status = Success
Description = None

Number of Controllers = 1
Host Name = A-f8f21e93eca4-nas014
Operating System  = Linux3.10.0-1062.el7.x86_64

System Overview :
===============

-------------------------------------------------------------------------------------
Ctl Model                   Ports PDs DGs DNOpt VDs VNOpt BBU sPR DS  EHS ASOs Hlth  
-------------------------------------------------------------------------------------
  0 AVAGOMegaRAIDSAS9361-8i     8  25   2     1   2     1 Opt On  1&amp;2 Y      3 NdAtn 
-------------------------------------------------------------------------------------

Ctl=Controller Index|DGs=Drive groups|VDs=Virtual drives|Fld=Failed
PDs=Physical drives|DNOpt=DG NotOptimal|VNOpt=VD NotOptimal|Opt=Optimal
Msng=Missing|Dgd=Degraded|NdAtn=Need Attention|Unkwn=Unknown
sPR=Scheduled Patrol Read|DS=DimmerSwitch|EHS=Emergency Hot Spare
Y=Yes|N=No|ASOs=Advanced Software Options|BBU=Battery backup unit
Hlth=Health|Safe=Safe-mode boot

# 这里的optimal表示是否是最优状态
</code></pre>
<h3 id="显示控制器信息">显示控制器信息</h3>
<pre><code class="language-shell"># ./storcli64 /c0 show   //这里c0表示第一个控制器
Generating detailed summary of the adapter, it may take a while to complete.

Controller = 0
...省略
Device Number = 0
Function Number = 0
Drive Groups = 2

TOPOLOGY :
========

-----------------------------------------------------------------------------
DG Arr Row EID:Slot DID Type  State BT       Size PDC  PI SED DS3  FSpace TR 
-----------------------------------------------------------------------------
 ... 省略
 1 0   12  10:12    37  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   13  10:13    36  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   14  10:14    46  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   15  -        -   DRIVE Msng  -   14.551 TB -    -  -   -    -      N  
 1 0   16  10:16    38  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   17  10:17    35  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N  
 1 0   18  10:18    45  DRIVE Onln  Y   14.551 TB dflt N  N   dflt -      N    
-----------------------------------------------------------------------------
... 省略

Missing Drives Count = 1

# 这里提示我们有一块盘丢失，需要进行处理
</code></pre>
<h3 id="显示剩余空间">显示剩余空间</h3>
<pre><code class="language-shell"># ./storcli64 /c0 show freespace
</code></pre>
<h3 id="显示ccconsistency-check">显示CC（Consistency Check）</h3>
<pre><code class="language-shell"># ./storcli64 /c0 show cc
Controller = 0
Status = Success
Description = None

Controller Properties :
=====================

-----------------------------------------------
Ctrl_Prop                 Value                
-----------------------------------------------
CC Operation Mode         Concurrent           
CC Execution Delay        168                  
CC Next Starttime         02/04/2021, 15:00:00 
CC Current State          Stopped              
CC Number of iterations   15                   
CC Number of VD completed 1                    
CC Excluded VDs           None                 
-----------------------------------------------

</code></pre>
<h3 id="显示cc速率">显示CC速率</h3>
<pre><code class="language-shell"># ./storcli64 /c0 show ccrate
Controller = 0
Status = Success
Description = None


Controller Properties :
=====================

----------------
Ctrl_Prop Value 
----------------
CC Rate   30%   
----------------
</code></pre>
<h3 id="查看与设置rebuild速率">查看与设置Rebuild速率</h3>
<pre><code class="language-shell"># ./storcli64 /c0 show rebuildrate     //查看速率
# ./storcli64 /c0 set rebuildrate=30   //设置速率
</code></pre>
<h3 id="清除raid卡物理磁盘cache">清除Raid卡，物理磁盘Cache</h3>
<pre><code class="language-shell"># ./storcli64 /c0 flushcache
</code></pre>
<h3 id="获取所有enclosure信息">获取所有enclosure信息</h3>
<pre><code class="language-shell"># ./storcli64 /c0/eall show
</code></pre>
<h3 id="获取单个enclosure信息">获取单个enclosure信息</h3>
<pre><code class="language-shell"># ./storcli64 /c0/e10 show &lt;all&gt;    //加上all参数表示获取详细信息
# ./strocli64 /c0/e10 show status   //获取风扇等设备详细信息
</code></pre>
<h3 id="获取所有磁盘详细信息">获取所有磁盘详细信息</h3>
<pre><code class="language-shell"># ./storcli64 /c0/eall/sall show
</code></pre>
<h3 id="卷组信息获取">卷组信息获取</h3>
<pre><code class="language-shell"># ./storcli64 /c0/dall show   // 这里的卷组称为DG
</code></pre>
<h2 id="参考文献">参考文献</h2>
<p>https://www.cnblogs.com/luxiaodai/p/9878747.html</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql的组提交原理]]></title>
        <id>https://esp0x.github.io/post/mysql-de-zu-ti-jiao-yuan-li/</id>
        <link href="https://esp0x.github.io/post/mysql-de-zu-ti-jiao-yuan-li/">
        </link>
        <updated>2021-01-18T09:25:56.000Z</updated>
        <content type="html"><![CDATA[<h2 id="事务提交流程">事务提交流程</h2>
<h3 id="大致流程如下">大致流程如下：</h3>
<p>有binlog的情况下，commit动作开始时，会有一个Redo XID写入redo，然后写data到binlog，binlog写成功后，会将binlog的filename和日志写的position再写回redo（position也会写入pos文件），此时事务完成（committed）。如果只有XID，没有filename和position，则表示事务为prepare状态。</p>
<h3 id="流程">流程：</h3>
<pre><code class="language-shell"># commit; --&gt; write XID to redo. --&gt; write data to Binlog. --&gt; write filename,postsion of binlog to redo. --&gt; commited.
# 记录Binlog是在InnoDB引擎Prepare（即Redo Log写入磁盘）之后，这点至关重要。
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://esp0x.github.io/post-images/1610962074302.png" alt="" loading="lazy"></figure>
<h3 id="不同阶段crash的情况">不同阶段crash的情况：</h3>
<table>
<thead>
<tr>
<th>crash发生阶段</th>
<th>事务状态</th>
<th>事务结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>当事务在prepare阶段crash</td>
<td>该事务未写入binlog，引擎层也未写入redo到磁盘</td>
<td>该事务rollback</td>
</tr>
<tr>
<td>当事务在binlog写阶段crash</td>
<td>此时引擎层redo写盘完成，但binlog日志还未落盘</td>
<td>该事务rollback</td>
</tr>
<tr>
<td>当事务在binlog日志写入磁盘后crash，但引擎层未来得及commit</td>
<td>此时引擎层redo已经写盘，server层binlog已经写盘，但redo中事务状态未正确结束</td>
<td>读出binlog中的XID，并通知引擎层提交这些XID的事务。引擎层提交这些事务后，会回滚其他事务，使引擎层redo和binlog日志在事务上始终保持一致。事务通过recovery自动完成提交</td>
</tr>
</tbody>
</table>
<h2 id="wal机制">WAL机制</h2>
<ul>
<li>WAL（Write Ahead Log）：对数据文件进行修改前，必须将修改先记录到日志。</li>
<li>Redo log就是一种WAL应用，用于保证数据库的持久性，每次事务提交时，不用同步刷新磁盘，只需要刷新redo log就行了。相比刷盘的随机IO，写redo log的顺序IO能够提升事务提交速度。</li>
<li>组提交：
<ol>
<li>未开启binlog：redo log的刷盘操作是主要瓶颈，mysql使用组提交，将多个redo log刷盘操作合并成一个。</li>
<li>开启binlog：为了保证redo log和binlog数据一致性，mysql使用了二阶段提交，此时binlog成为瓶颈，mysql增加了binlog的组提交来解决这个问题，分为三个阶段（Flush、Sync、Commit），最大化刷盘收益。</li>
</ol>
</li>
</ul>
<h3 id="过程详解">过程详解</h3>
<p>在Mysql中每个阶段都有一个队列，每个队列都有一把锁保护，第一个进入队列的事务成为leader，leader领导所在队列的所有事务，全权负责整队的操作，完成后通知队内其他事务操作结束。</p>
<h4 id="flush阶段">Flush阶段</h4>
<ul>
<li>首先获取队列中的事务组；</li>
<li>将redo中prepare阶段的数据刷盘；</li>
<li>将binlog数据写入文件，此处是文件缓冲，不保证数据库crash时，binlog的完整性；</li>
<li>Flush阶段的作用是提供了redo 的组提交；</li>
<li>如果这一步crash，由于不保证binlog中存在事务记录，所以数据库恢复后会回滚，此时二阶段提交状态还是prepare；</li>
</ul>
<h4 id="sync阶段">Sync阶段</h4>
<ul>
<li>为了增加一组事务中的事务数量，提升刷盘效率，使用两个参数进行控制：
<ol>
<li>binlog_group_commit_sync_delay=N  等待N 微秒后，开始事务刷盘</li>
<li>binlog_group_commit_sync_no_delay=N  对列中事务达到N个，立刻刷盘，忽略上面那个时间参数</li>
</ol>
</li>
<li>Sync阶段的作用是支持binlog的组提交；</li>
<li>如果此时crash，由于binlog中有事务记录，数据库恢复后会继续提交该事务；</li>
</ul>
<h4 id="commit阶段">Commit阶段</h4>
<ul>
<li>首先获取队列中的事务组；</li>
<li>依次将redo中已经prepare的事务在引擎层进行提交；</li>
<li>Commit阶段不用刷盘，如上所述，Flush阶段中的Redo log刷盘已经足够保证数据库崩溃时的数据安全了；</li>
<li>Commit阶段队列的作用是承接Sync阶段的事务，完成最后的引擎提交，使得Sync可以尽早的处理下一组事务，最大化组提交的效率；</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[GTID基础原理]]></title>
        <id>https://esp0x.github.io/post/gtid-ji-chu-yuan-li/</id>
        <link href="https://esp0x.github.io/post/gtid-ji-chu-yuan-li/">
        </link>
        <updated>2021-01-18T09:03:20.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-gtid概述">一、GTID概述</h2>
<p>GTID是MYSQL5.6新增的特性，GTID（Global Transaction Identifier）全称为全局事务标示符,用以数据库实例事务唯一标识，其组成主要是source_id和transaction_id 即GTID = source_id:transaction_id。其中source_id是数据库启动自动生成的数据库实例唯一标识，保存在auto.cnf中，而transaction_id则是事务执行的序列号。</p>
<h2 id="二-gtid优缺点">二、GTID优缺点</h2>
<h3 id="优点">优点：</h3>
<ul>
<li>复制安全性更高，一个事务在每个实例上只执行一次；</li>
<li>故障切换简单，可通过设置MASTER_AUTO_POSITION=1，而非master_log_file和master_log_pos来建立主从关系；</li>
<li>可根据GTID确定事务最早提交的实例；</li>
</ul>
<h3 id="缺点">缺点：</h3>
<ul>
<li>组复制中，必须要求统一开启GTID或者关闭GTID；</li>
<li>不支持复制create table table_name select ... from table_name_xx ;</li>
<li>不支持create temporary table和drop temporary table；</li>
<li>不支持sql_slave_skip_counter，可通过set global gtid_next='' 跳过；</li>
<li>从库和主库都必须设置log_slave_updates</li>
</ul>
<h2 id="三-gtid工作原理">三、GTID工作原理</h2>
<p>1、master更新数据时，会在事务前产生GTID，一同记录到binlog日志中。<br>
2、slave端的i/o 线程将变更的binlog，写入到本地的relay log中。<br>
3、sql线程从relay log中获取GTID，然后对比slave端的binlog是否有记录。<br>
4、如果有记录，说明该GTID的事务已经执行，slave会忽略。<br>
5、如果没有记录，slave就会从relay log中执行该GTID的事务，并记录到binlog。<br>
6、在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。</p>
<h2 id="四-gtid开启和关闭">四、GTID开启和关闭</h2>
<p>gtid_mode=ON(必选)<br>
log_bin=ON(必选)<br>
log-slave-updates=ON(必选)<br>
enforce-gtid-consistency(必选)<br>
log-bin = /home/mysql/mysql-bin（必选）<br>
binlog_format = MIXED（必选mixed或者row）<br>
##<br>
change master to master_host = 'ipaddr',master_port = 3306,master_user = 'username',master_password='password',master_auto_position = 1;</p>
<h2 id="五-gtid适用场景">五、GTID适用场景</h2>
<p>1、搭建高可用架构，方便主从切换后，新的从库重新指定主库（例如一主二从的结构，A为mater,B为Slave，C为Slave，A宕机切换到B后，C重新指定主库为B）<br>
2、不经常使用create table table_name select * from table_name/create temporary table/update t1,t2 where ...这种语句的场合</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql事务隔离级别及实现]]></title>
        <id>https://esp0x.github.io/post/mysql-shi-wu-ge-chi-ji-bie-ji-shi-xian/</id>
        <link href="https://esp0x.github.io/post/mysql-shi-wu-ge-chi-ji-bie-ji-shi-xian/">
        </link>
        <updated>2021-01-18T08:12:13.000Z</updated>
        <content type="html"><![CDATA[<h2 id="四个基本要素acid">四个基本要素（ACID）</h2>
<ul>
<li>原子性（Atomicity）</li>
<li>一致性（Consistency）</li>
<li>隔离性（Isolation）</li>
<li>持久性（Durability）</li>
</ul>
<h2 id="事务的并发问题">事务的并发问题</h2>
<ol>
<li>脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读到的数据是脏数据；</li>
<li>不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取的数据不一致；</li>
<li>幻读：幻读并不是说两次读取的结果集不同，幻读侧重的方面是某一次的select操作得到的结果所表征的数据状态无法支撑后续的业务操作。具体来说，select某条记录是否存在，不存在，准备插入此记录，但执行insert时发现此记录已存在，无法插入，此时就发生了幻读。</li>
</ol>
<h2 id="事务隔离级别">事务隔离级别</h2>
<table>
<thead>
<tr>
<th>事务隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td>读未提交（read-uncommitted）</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>不可重复读（read-committed）</td>
<td>否</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>可重复读（repeatable-read）</td>
<td>否</td>
<td>否</td>
<td>是</td>
</tr>
<tr>
<td>串行化（serializable）</td>
<td>否</td>
<td>否</td>
<td>否</td>
</tr>
</tbody>
</table>
<h4 id="查看数据库隔离级别">查看数据库隔离级别</h4>
<pre><code class="language-sql">mysql&gt; select @@global.tx_isolation, @@tx_isolation;
</code></pre>
<h2 id="acid实现原理">ACID实现原理</h2>
<h3 id="原子性">原子性</h3>
<p>实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB实现回滚，依赖的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log，如果事务执行失败或调用rollback，导致事务需要回滚，便可以利用undo log中的信息将数据进行回滚。undo log其实就是记录数据修改时的相反操作。</p>
<h3 id="持久性">持久性</h3>
<p>实现持久性主要依赖redo log，redo log采用WAL，所有修改先写入日志，再更新到Buffer Pool，保证了数据库不会因意外宕机而丢失。写redo log是要比刷缓存到磁盘要快的，原因如下：</p>
<ol>
<li>刷脏是随机IO、这个很好理解；而redo log是追加操作，属于顺序IO，所以速度快；</li>
<li>刷脏是以Page为单位的，Mysql默认页大小是16KB，一个Page上一个小的修改都需要整页写入；而redo log中只包含真正需要写入的部分，无效IO减少；</li>
</ol>
<p>关于binlog和redo log的区别：</p>
<ul>
<li>作用不同：redo log是用于crash recovery的，保证MySQL宕机也不会影响持久性；binlog是用于point-in-time recovery的，保证服务器可以基于时间点恢复数据，此外binlog还用于主从复制。</li>
<li>层次不同：redo log是InnoDB存储引擎实现的，而binlog是MySQL的服务器层实现的，同时支持InnoDB和其他存储引擎。</li>
<li>内容不同：redo log是物理日志，内容基于磁盘的Page；binlog的内容是二进制的，根据binlog_format参数的不同，可能基于sql语句、基于数据本身或者二者的混合。</li>
<li>写入时机不同：binlog在事务提交时写入；redo log的写入时机相对多元，可以通过双1设置进行控制；</li>
</ul>
<h3 id="隔离性">隔离性</h3>
<p>隔离性追求的是并发条件下事务之间互不干扰；主要考虑两种场景：</p>
<ol>
<li>
<p>两个事务的写操作之间的影响：</p>
<ul>
<li>InnoDB通过锁机制来保证同一时刻只有一个事务进行写操作，简单理解为，事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据，其他事务需要等待该锁释放后才能对同一数据进行操作。</li>
<li>表锁会锁住整个表，并发性能较差；</li>
<li>行锁只锁定需要操作的数据，并发性能好，但数据较多时性能也会下降；绝大多数情况下，我们使用行锁即可；</li>
</ul>
</li>
<li>
<p>两个事务的读操作之间的影响：</p>
<p>Mysql中默认的隔离级别是RR，InnoDB实现的RR可以避免幻读的问题，即使用MVCC技术，Multi-Version Concurrency Control。</p>
<p>MVCC最大的优点是读不加锁，因此读写不冲突，并发性好。InnoDB实现MVCC，多个版本的数据可以共存，主要依赖以下技术和数据结构：</p>
<pre><code class="language-shell">数据库需要做好版本控制，防止不该被事务看到的数据(例如还没提交的事务修改的数据)被看到。在InnoDB中，主要是通过使用readview的技术来实现判断。查询出来的每一行记录，都会用readview来判断一下当前这行是否可以被当前事务看到，如果可以，则输出，否则就利用undolog来构建历史版本，再进行判断，知道记录构建到最老的版本或者可见性条件满足。

在trx_sys中，一直维护这一个全局的活跃的读写事务id(trx_sys-&gt;descriptors)，id按照从小到大排序，表示在某个时间点，数据库中所有的活跃(已经开始但还没提交)的读写(必须是读写事务，只读事务不包含在内)事务。当需要一个一致性读的时候(即创建新的readview时)，会把全局读写事务id拷贝一份到readview本地(read_view_t-&gt;descriptors)，当做当前事务的快照。read_view_t-&gt;up_limit_id是read_view_t-&gt;descriptors这数组中最小的值，read_view_t-&gt;low_limit_id是创建readview时的max_trx_id，即一定大于read_view_t-&gt;descriptors中的最大值。当查询出一条记录后(记录上有一个trx_id，表示这条记录最后被修改时的事务id)，可见性判断的逻辑如下(lock_clust_rec_cons_read_sees)：

如果记录上的trx_id小于read_view_t-&gt;up_limit_id，则说明这条记录的最后修改在readview创建之前，因此这条记录可以被看见。

如果记录上的trx_id大于等于read_view_t-&gt;low_limit_id，则说明这条记录的最后修改在readview创建之后，因此这条记录肯定不可以被看家。

如果记录上的trx_id在up_limit_id和low_limit_id之间，且trx_id在read_view_t-&gt;descriptors之中，则表示这条记录的最后修改是在readview创建之时，被另外一个活跃事务所修改，所以这条记录也不可以被看见。如果trx_id不在read_view_t-&gt;descriptors之中，则表示这条记录的最后修改在readview创建之前，所以可以看到。

基于上述判断，如果记录不可见，则尝试使用undo去构建老的版本(row_vers_build_for_consistent_read)，直到找到可以被看见的记录或者解析完所有的undo。

针对RR隔离级别，在第一次创建readview后，这个readview就会一直持续到事务结束，也就是说在事务执行过程中，数据的可见性不会变，所以在事务内部不会出现不一致的情况。针对RC隔离级别，事务中的每个查询语句都单独构建一个readview，所以如果两个查询之间有事务提交了，两个查询读出来的结果就不一样。从这里可以看出，在InnoDB中，RR隔离级别的效率是比RC隔离级别的高。此外，针对RU隔离级别，由于不会去检查可见性，所以在一条SQL中也会读到不一致的数据。针对串行化隔离级别，InnoDB是通过锁机制来实现的，而不是通过多版本控制的机制，所以性能很差。

由于readview的创建涉及到拷贝全局活跃读写事务id，所以需要加上trx_sys-&gt;mutex这把大锁，为了减少其对性能的影响，关于readview有很多优化。例如，如果前后两个查询之间，没有产生新的读写事务，那么前一个查询创建的readview是可以被后一个查询复用的。
</code></pre>
</li>
<li>
<p>操作指令：</p>
</li>
</ol>
<pre><code class="language-sql">mysql&gt; select * from information_schema.innodb_locks; #锁的概况
mysql&gt; show engine innodb status;                     #InnoDB整体状态，其中包括锁的情况
</code></pre>
<h3 id="一致性">一致性</h3>
<p>一致性是事务追求的终极目标，原子性、持久性和隔离性，都是为了实现一致性而存在的；实现一致性也需要应用层面进行保障；</p>
<h3 id="运维相关指令和参数">运维相关指令和参数</h3>
<pre><code class="language-shell">1、首先介绍一下information_schema中的三张表: innodb_trx, innodb_locks和innodb_lock_waits。由于这些表几乎需要查询所有事务子系统的核心数据结构，为了减少查询对系统性能的影响，InnoDB预留了一块内存，内存里面存了相关数据的副本，如果两次查询的时间小于0.1秒(CACHE_MIN_IDLE_TIME_US)，则访问的都是同一个副本。如果超过0.1秒，则这块内存会做一次更新，每次更新会把三张表用到的所有数据统一更新一遍，因为这三张表经常需要做表连接操作，所以一起更新能保证数据的一致性。这里简单介绍一下innodb_trx表中的字段，另外两张表涉及到事物锁的相关信息，由于篇幅限制，后续有机会在介绍。

trx_id: 就是trx_t中的事务id，如果是只读事务，这个id跟trx_t的指针地址有关，所以可能是一个很大的数字(trx_get_id_for_print)。
trx_weight: 这个是事务的权重，计算方法就是undolog数量加上事务已经加上锁的数量。在事务回滚的时候，优先选择回滚权重小的事务，有非事务引擎参与的事务被认为权重是最大的。
trx_rows_modified：这个就是当前事务已经产生的undolog数量，每更新一条记录一次，就会产生一条undo。
trx_concurrency_tickets: 每次这个事务需要进入InnoDB层时，这个值都会减一，如果减到0，则事务需要等待(压力大的情况下)。
trx_is_read_only: 如果是以start transaction read only启动事务的，那么这个字段是1，否则为0。
trx_autocommit_non_locking: 如果一个事务是一个普通的select语句(后面没有跟for update, share lock等)，且当时的autocommit为1，则这个字段为1，否则为0。
trx_state: 表示事务当前的状态，只能有RUNNING, LOCK WAIT, ROLLING BACK, COMMITTING这几种状态, 是比较粗粒度的状态。
trx_operation_state: 表示事务当前的详细状态，相比于trx_state更加详细，例如有rollback to a savepoint, getting list of referencing foreign keys, rollback of internal trx on stats tables, dropping indexes等。

2、与事务相关的undo参数

innodb_undo_directory: undo文件的目录，建议放在独立的一块盘上，尤其在经常有大事务的情况下。
innodb_undo_logs: 这个是定义了undo segment的个数。在给读写事务分配undo segment的时候，拿这个值去做轮训分配。
Innodb_available_undo_logs: 这个是一个status变量，在启动的时候就确定了，表示的是系统上分配的undo segment。举个例子说明其与innodb_undo_logs的关系：假设系统初始化的时候innodb_undo_logs为128，则在文件上一定有128个undo segment，Innodb_available_undo_logs也为128，但是启动起来后，innodb_undo_logs动态被调整为100，则后续的读写事务只会使用到前100个回滚段，最后的20多个不会使用。
innodb_undo_tablespaces: 存放undo segment的物理文件个数，文件名为undoN，undo segment会比较均匀的分布在undo tablespace中。

3、与Purge相关的参数

innodb_purge_threads: Purge Worker和Purge Coordinator总共的个数。在实际的实现中，使用多少个线程去做Purge是InnoDB根据实时负载进行动态调节的。
innodb_purge_batch_size: 一次性处理的undolog的数量，处理完这个数量后，Purge线程会计算是否需要sleep。
innodb_max_purge_lag: 如果全局历史链表超过这个值，就会增加Purge Worker线程的数量，也会使用sleep的方式delay用户的DML。
innodb_max_purge_lag_delay: 这个表示通过sleep方式delay用户DML最大的时间。

4、与回滚相关的参数

innodb_lock_wait_timeout: 等待行锁的最大时间，如果超时，则会滚当前语句或者整个事务。发生回滚后返回类似错误：Lock wait timeout exceeded; try restarting transaction。
innodb_rollback_on_timeout: 如果这个参数为true，则当发生因为等待行锁而产生的超时时，回滚掉整个事务，否则只回滚当前的语句。这个就是隐式回滚机制。主要是为了兼容之前的版本。
</code></pre>
<h2 id="总结">总结</h2>
<ul>
<li>原子性：语句要么全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；实现主要基于undo log</li>
<li>持久性：保证事务提交后不会因为宕机等原因导致数据丢失；实现主要基于redo log</li>
<li>隔离性：保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是RR，RR的实现主要基于锁机制（包含next-key lock）、MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView）</li>
<li>一致性：事务追求的最终目标，一致性的实现既需要数据库层面的保障，也需要应用层面的保障</li>
</ul>
<h2 id="参考文献">参考文献</h2>
<h4 id="httpmysqltaobaoorgmonthly20171201">http://mysql.taobao.org/monthly/2017/12/01/</h4>
<h4 id="httpswwwcnblogscomkismetvp10331633html">https://www.cnblogs.com/kismetv/p/10331633.html</h4>
<h4 id="httpszhuanlanzhihucomp40208895">https://zhuanlan.zhihu.com/p/40208895</h4>
<h4 id="httpswwwcnblogscomhuanongyingp7021555html">https://www.cnblogs.com/huanongying/p/7021555.html</h4>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql主从复制环境搭建]]></title>
        <id>https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-huan-jing-da-jian/</id>
        <link href="https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-huan-jing-da-jian/">
        </link>
        <updated>2021-01-15T02:15:27.000Z</updated>
        <content type="html"><![CDATA[<h2 id="准备机器">准备机器</h2>
<p>两台centos7系统服务器：</p>
<p>主mysql：192.168.50.1</p>
<p>从mysql：192.168.50.2</p>
<h2 id="安装mysql">安装mysql</h2>
<ol>
<li>
<p>下载yum源</p>
<pre><code class="language-shell">wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm
</code></pre>
</li>
<li>
<p>安装yum源</p>
<pre><code class="language-shell">rpm -Uvh mysql80-community-release-el7-3.noarch.rpm
</code></pre>
</li>
<li>
<p>安装mysql</p>
<pre><code class="language-shell">yum install -y mysql-community-server
</code></pre>
</li>
<li>
<p>启动mysql，并获取root初始密码</p>
<pre><code class="language-shell"># 确保selinux为disabled
# 确保关闭了firewalld服务

systemctl start mysqld

[root@localhost ~]# grep password /var/log/mysqld.log 
2020-10-19T02:47:35.912896Z 1 [Note] A temporary password is generated for root@localhost: -1k-1KjU*LG)
</code></pre>
</li>
<li>
<p>登入mysql，并重置root密码</p>
<pre><code class="language-shell">mysql -uroot -p 
mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'qUXmZP11JwJ_11'; # root本地访问，且重置
mysql&gt; exit
</code></pre>
</li>
</ol>
<h2 id="主mysql数据库配置">主Mysql数据库配置</h2>
<p>编辑my.cnf配置文件</p>
<pre><code class="language-shell">vim /etc/my.cnf

[mysqld]
port=9006          #指定新的端口
server-id=110      #设置主服务器的ID(不能和别的服务器重复，建议使用ip的最后一段)
log-bin=mysql-bin  #binlog日志文件名
</code></pre>
<p>创建用于主从同步的账户</p>
<pre><code class="language-shell">$ mysql -u root -p  #登录MySQL
mysql&gt; CREATE USER 'repl'@'192.168.50.2' IDENTIFIED WITH mysql_native_password BY 'Top_master_1'; # 主库创建用于从库同步的账号
mysql&gt; grant replication slave on *.* to 'repl'@'192.168.50.2';  #赋予主从同步权限，指定具体的数据库在/etc/my.cnf中完成
mysql&gt; flush privileges;
</code></pre>
<p>重启MySQL，使my.cnf 配置生效；查看主库状态</p>
<pre><code class="language-shell">$ systemctl restart mysqld #重启MySQL
mysql -u root -p
mysql&gt; show master status; #查看主库的状态  File,Position 这两个值需要放到slave配置中
+--------------------+----------+--------------+------------------+-------------------+
| File               | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+--------------------+----------+--------------+------------------+-------------------+
| mysql-bin.00001    |      156 |     xxxx     |                  |                   |
+--------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec)
</code></pre>
<h2 id="从mysql数据库配置">从Mysql数据库配置</h2>
<p>编辑配置文件</p>
<pre><code class="language-shell">vim /etc/my.cnf

[mysqld]
port=9006
server-id=111
</code></pre>
<p>配置完成后，重启从库的MySQL</p>
<pre><code class="language-shell">$ systemctl restart mysqld  #重启MySQL
$ mysql -u root -p          #登录mysql
mysql&gt; stop slave;          #关闭从库
mysql&gt; change master to master_host='192.168.50.1',master_port=9006,master_user='repl',master_password='Top_master_1',master_log_file='mysql-bin.00001',master_log_pos=156; #配置主库信息
mysql&gt; start slave;            #开启从库 
mysql&gt; show slave status \G;   #Slave_IO_Running,Slave_SQL_Running 都为Yes的时候表示配置成功
</code></pre>
<h2 id="主库创建数据库和数据表">主库创建数据库和数据表</h2>
<pre><code class="language-sql">create database topmanager DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
登入从库，可以看到从库中出现同样的数据库和数据表，表明已同步</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql双1设置-数据安全的关键参数]]></title>
        <id>https://esp0x.github.io/post/mysql-shuang-1-she-zhi-shu-ju-an-quan-de-guan-jian-can-shu/</id>
        <link href="https://esp0x.github.io/post/mysql-shuang-1-she-zhi-shu-ju-an-quan-de-guan-jian-can-shu/">
        </link>
        <updated>2021-01-15T02:14:24.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-参数及设置说明">一、参数及设置说明</h2>
<pre><code class="language-shell"># innodb_flush_log_at_trx_commit
1.设置为0：log buffer将每秒一次地写入log file中，并且log file的flush操作同时进行；该模式下，在事务提交时，不会主动触发写入磁盘的操作；
2.设置为1：每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去;
3.设置为2：每次事务提交时MySQL都会把log buffer的数据写入log file，但是flush(刷到磁盘)操作并不会同时进行。该模式下,MySQL会每秒执行一次 flush(刷到磁盘)操作。

# sync_binlog
sync_binlog 的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。
当sync_binlog =N (N&gt;0) ，MySQL 在每写 N次 二进制日志binary log时，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去。

注意：如果启用了autocommit，那么每一个语句statement就会有一次写操作；否则每个事务对应一个写操作。

# 性能与安全性对比 
1.双1设置时，写入性能最差，安全性最高；
2.sync_binlog=N (N&gt;1 ) innodb_flush_log_at_trx_commit=2 时，性能最好，安全性较差；
3.innodb_flush_log_at_trx_commit设置为0，mysqld进程崩溃会导致上一秒钟所有事务数据的丢失；
4.innodb_flush_log_at_trx_commit设置为2，当系统崩溃或者断电时，上一秒的所有数据才有可能丢失；
</code></pre>
<h2 id="二-对io影响较大的几个参数">二、对IO影响较大的几个参数</h2>
<pre><code class="language-shell">1.innodb_buffer_pool_size # 该参数控制innodb缓存大小，用于缓存应用访问的数据，推荐配置为系统可用内存的80%。
2.binlog_cache_size       # 该参数控制二进制日志缓冲大小，当事务还没有提交时，事务日志存放于cache，当遇到大事务cache不够用的时，mysql会把uncommitted的部分写入临时文件,等到committed的时候才会写入正式的持久化日志文件。
3.innodb_max_dirty_pages_pct     # 该参数可以直接控制Dirty Page在BP中所占的比率，当dirty page达到了该参数的阈值，就会触发MySQL系统刷新数据到磁盘。
4.innodb_flush_log_at_trx_commit # 该参数确定日志文件何时write、flush。
5.sync_binlog         # sync_binlog的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。
6.innodb_flush_method # 该参数控制日志或数据文件如何write、flush。可选的值为fsync，o_dsync，o_direct，littlesync，nosync。
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql分库分表策略]]></title>
        <id>https://esp0x.github.io/post/mysql-fen-ku-fen-biao-ce-lue/</id>
        <link href="https://esp0x.github.io/post/mysql-fen-ku-fen-biao-ce-lue/">
        </link>
        <updated>2021-01-15T02:12:20.000Z</updated>
        <content type="html"><![CDATA[<p>数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库性能的目的。</p>
<h2 id="垂直切分">垂直切分</h2>
<p><img src="https://esp0x.github.io/post-images/1610676801903.jpg" alt="" loading="lazy"><br>
垂直切分常见有垂直分库和垂直分表两种：</p>
<p>垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库中。类似微服务架构，每一个微服务单独使用一个数据库的形式。</p>
<p>垂直分表是基于数据库中的列进行， 针对某个表字段过多，可以新建一张扩展表，将不常用的字段或长度较大的字段拆分到扩展表中。这样可以避免跨页问题，MySQL底层是通过数据页存储的，一条记录过大会导致跨页，造成额外的性能损失。</p>
<h3 id="垂直切分的优点">垂直切分的优点：</h3>
<ol>
<li>解决业务系统层面的耦合，使得业务逻辑更清晰；</li>
<li>与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等；</li>
<li>高并发场景下，垂直切分一定程度上能够提升访问性能；</li>
</ol>
<h3 id="垂直切分的缺点">垂直切分的缺点：</h3>
<ol>
<li>部分表无法join，只能通过接口方式，开发难度增加；</li>
<li>分布式事务处理复杂；</li>
<li>没有解决单表数据过大的问题；</li>
</ol>
<h2 id="水平切分">水平切分</h2>
<p><img src="https://esp0x.github.io/post-images/1610676821810.jpg" alt="" loading="lazy"><br>
当一个应用难以再细粒化的垂直切分，或切分后单表数据量过大，存在读写性能问题时，就需要考虑水平切分了。</p>
<p>水平切分包括库内分表和分库分表，库内分表只解决了单一表数据量过大的问题，没有将表分布到不同的机器上，对于数据库访问性能提升有限。</p>
<h3 id="水平切分的优点">水平切分的优点：</h3>
<ol>
<li>不存在单表数据量过大问题，提升了表的访问性能；</li>
<li>应用端改造较小，不需要进行业务拆分；</li>
</ol>
<h3 id="水平切分的缺点">水平切分的缺点：</h3>
<ol>
<li>跨分片事务的一致性难以保证；</li>
<li>跨库的join关联查询性能较差；</li>
<li>数据库多次扩展难度和维护量增加；</li>
</ol>
<h2 id="几种典型的数据分片规则">几种典型的数据分片规则</h2>
<ul>
<li>
<p>根据数值范围</p>
<p>例如：按照时间维度，将不同月，甚至不同日的数据存储到不同的表；又或者，按照userId进行划分，1-9999的记录分到第一个库，10000-20000的分到第二个库，以此类推；</p>
<p>优点：</p>
<ol>
<li>单表大小可控；</li>
<li>天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点，无需对其他分片进行数据迁移；</li>
<li>使用分片字段进行查询时，速度更快；</li>
</ol>
<p>缺点：</p>
<ol>
<li>热点数据成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间的数据，可能会被频繁地读写，有些分片存储历史数据，则很少被查询。</li>
</ol>
</li>
<li>
<p>根据数值取模</p>
<p>一般采用hash取模mod的切分方式。</p>
<p>优点：</p>
<ol>
<li>数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈；</li>
</ol>
<p>缺点：</p>
<ol>
<li>后期扩展时，需要迁移旧的数据；（通过一致性hash算法可以避免这个问题）</li>
<li>容易面临跨分片查询的复杂问题，比如频繁查询中不包含分片字段，将会导致无法定位数据库，从而向所有数据库发起请求，再在内存中合并数据，性能损失严重；</li>
</ol>
</li>
</ul>
<h2 id="分库分表需要解决的问题">分库分表需要解决的问题</h2>
<ul>
<li>
<p>事务问题</p>
<p>方案一：使用分布式事务，交由数据库管理，简单有效；缺点是随着节点增加，性能代价越来越高。（需要协调的节点变多）</p>
<p>方案二：由应用程序和数据库共同控制，性能上有优势；缺点是开发难度较大；</p>
</li>
<li>
<p>跨节点Join问题</p>
<p>分两次查询，第一次查询的结果集中找出关联数据的ID，根据这些ID发起第二次请求得到关联数据；在应用设计时应尽量避免进行关联查询；</p>
</li>
<li>
<p>跨节点的count、order by、group by以及聚合函数问题</p>
<p>分别在各个节点进行数据合并，最后在统一进行合并，缺点是当数据集较大时，占用的内存资源很多；</p>
</li>
<li>
<p>数据迁移、容量规划、扩容等问题</p>
<p>当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。</p>
</li>
<li>
<p>全局主键避重问题</p>
<p>由于表同时存在于多个数据库中，主键值设置为自增序列将不能使用，需要单独设计全局主键，一般可以用UUID的方案解决；</p>
</li>
<li>
<p>跨分片的排序分页</p>
<p>一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。</p>
<p>如果是在前台应用提供分页，则限定用户只能看前面n页，这个限制在业务上也是合理的，一般看后面的分页意义不大（如果一定要看，可以要求用户缩小范围重新查询）。</p>
<p>如果是后台批处理任务要求分批获取数据，则可以加大page size，比如每次获取5000条记录，有效减少分页数（当然离线访问一般走备库，避免冲击主库）。</p>
<p>分库设计时，一般还有配套大数据平台汇总所有分库的记录，有些分页查询可以考虑走大数据平台。</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql主从复制原理]]></title>
        <id>https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-yuan-li/</id>
        <link href="https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-yuan-li/">
        </link>
        <updated>2021-01-14T08:23:14.000Z</updated>
        <content type="html"><![CDATA[<h3 id="原理图如下">原理图如下：</h3>
<figure data-type="image" tabindex="1"><img src="https://esp0x.github.io/post-images/1610671157156.png" alt="" loading="lazy"></figure>
<h2 id="主从复制流程详解">主从复制流程详解：</h2>
<ol>
<li>master库发生数据改变时，会将改变写入binglog日志；</li>
<li>slave库会在一定时间间隔内对master的binlog进行检测以确定是否发生改变，如果发生改变，则开始一个IO thread请求master二进制事件；</li>
<li>同时，master为每一个过来请求的IO thread开启一个dump线程，用于将二进制事件发送给IO thread，slave的IO thread将此二进制事件写入本地relay log（中继日志）中，并开启SQL thread从中继日志中读取二进制日志，在本地进行重放（replay），从而使得本地数据与master保持一致；最后IO thread和SQL thread进入睡眠状态，等待下次唤醒。</li>
</ol>
<h2 id="主从复制形式">主从复制形式：</h2>
<ol>
<li>主从</li>
<li>主主</li>
<li>一主多从</li>
<li>多主一从</li>
<li>联级复制</li>
</ol>
<h2 id="主从同步延时分析">主从同步延时分析：</h2>
<ol>
<li>master对所有DDL和DML产生的日志都写入binlog，由于是顺序写，所以效率很高；反之，slave的SQL thread进行relay log的重放时，DML和DDL的IO是随机的，不是顺序，所以成本较高，这里会增加一部分延时；</li>
<li>由于SQL thread是单线程的，当master的并发较高时，过多的DML可能会导致slave的SQL thread来不及处理，这里会增加一部分延时；</li>
<li>slave中有部分SQL产生了锁等待，这种情况就是slave有一些读请求与重放请求产生了锁冲突导致的，也会增加延时；</li>
<li>slave在充当读库角色的时候，如果查询访问压力过大，会消耗部分系统资源，影响同步效率；</li>
<li>大事务执行，即当master有大事务执行时，比如执行了10分钟，binlog写入必须要等待事务处理完毕，那么slave开始进行同步的时候就已经延时10分钟了；</li>
</ol>
<h2 id="延时解决办法">延时解决办法：</h2>
<ol>
<li>业务层实现读写分离，一主多从，主写从读，分散压力；</li>
<li>业务层和数据库层之间加入缓存策略，降低直接对数据库的读压力；频繁写的场景不适合加缓存，会导致缓存命中降低；</li>
<li>升级硬件；</li>
<li>MTS问题，即多线程的slave，从5.6版本开始支持，针对不同粒度（库、表、行）设置并行同步；</li>
</ol>
<h2 id="57版本后的并行复制策略">5.7版本后的并行复制策略</h2>
<h4 id="redo-log的两阶段提交">Redo log的两阶段提交</h4>
<ul>
<li>先写redo，再写binlog：假设在redo写完，binlog还没有写完的时候，Mysql进程异常重启，这时仍然能够通过redo log恢复数据，但由于binlog没有这条记录，所以之后备份日志的时候，binlog是缺失这条记录的，以后需要用binlog恢复数据时，就会缺少一条数据的更新；</li>
<li>先写binlog，再写redo log：如果binlog写完后crash，由于redo log还没写，崩溃恢复后这个事务无效，但是binlog有记录，以后用这个binlog恢复数据时，就会多出一条更新记录；</li>
<li>二阶段提交：使用二阶段提交时，会综合redo和binlog的状态进行处理，如果写入binlog之前crash，那么由于redo处于prepare阶段，只需要对当前事务进行回滚即可；如果写入binlog之后crash，那么由于redo处于prepare阶段，只需要对当前事务进行提交即可。</li>
</ul>
<h4 id="并行复制的思想">并行复制的思想</h4>
<ol>
<li>同时处于prepare状态的事务，在备库执行是可以并行的；</li>
<li>处于prepare状态的事务，与处于commit状态的事务之间，在备库执行也是可以并行的；</li>
<li>binlog_group_commit_sync_delay参数，表示延迟多少微妙后才调用fsync；</li>
<li>binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync；</li>
</ol>
]]></content>
    </entry>
</feed>