<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://esp0x.github.io</id>
    <title>Grey</title>
    <updated>2021-01-18T09:03:45.971Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://esp0x.github.io"/>
    <link rel="self" href="https://esp0x.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://esp0x.github.io/images/avatar.png</logo>
    <icon>https://esp0x.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Grey</rights>
    <entry>
        <title type="html"><![CDATA[GTID基础原理]]></title>
        <id>https://esp0x.github.io/post/gtid-ji-chu-yuan-li/</id>
        <link href="https://esp0x.github.io/post/gtid-ji-chu-yuan-li/">
        </link>
        <updated>2021-01-18T09:03:20.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-gtid概述">一、GTID概述</h2>
<p>GTID是MYSQL5.6新增的特性，GTID（Global Transaction Identifier）全称为全局事务标示符,用以数据库实例事务唯一标识，其组成主要是source_id和transaction_id 即GTID = source_id:transaction_id。其中source_id是数据库启动自动生成的数据库实例唯一标识，保存在auto.cnf中，而transaction_id则是事务执行的序列号。</p>
<h2 id="二-gtid优缺点">二、GTID优缺点</h2>
<h3 id="优点">优点：</h3>
<ul>
<li>复制安全性更高，一个事务在每个实例上只执行一次；</li>
<li>故障切换简单，可通过设置MASTER_AUTO_POSITION=1，而非master_log_file和master_log_pos来建立主从关系；</li>
<li>可根据GTID确定事务最早提交的实例；</li>
</ul>
<h3 id="缺点">缺点：</h3>
<ul>
<li>组复制中，必须要求统一开启GTID或者关闭GTID；</li>
<li>不支持复制create table table_name select ... from table_name_xx ;</li>
<li>不支持create temporary table和drop temporary table；</li>
<li>不支持sql_slave_skip_counter，可通过set global gtid_next='' 跳过；</li>
<li>从库和主库都必须设置log_slave_updates</li>
</ul>
<h2 id="三-gtid工作原理">三、GTID工作原理</h2>
<p>1、master更新数据时，会在事务前产生GTID，一同记录到binlog日志中。<br>
2、slave端的i/o 线程将变更的binlog，写入到本地的relay log中。<br>
3、sql线程从relay log中获取GTID，然后对比slave端的binlog是否有记录。<br>
4、如果有记录，说明该GTID的事务已经执行，slave会忽略。<br>
5、如果没有记录，slave就会从relay log中执行该GTID的事务，并记录到binlog。<br>
6、在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。</p>
<h2 id="四-gtid开启和关闭">四、GTID开启和关闭</h2>
<p>gtid_mode=ON(必选)<br>
log_bin=ON(必选)<br>
log-slave-updates=ON(必选)<br>
enforce-gtid-consistency(必选)<br>
log-bin = /home/mysql/mysql-bin（必选）<br>
binlog_format = MIXED（必选mixed或者row）<br>
##<br>
change master to master_host = 'ipaddr',master_port = 3306,master_user = 'username',master_password='password',master_auto_position = 1;</p>
<h2 id="五-gtid适用场景">五、GTID适用场景</h2>
<p>1、搭建高可用架构，方便主从切换后，新的从库重新指定主库（例如一主二从的结构，A为mater,B为Slave，C为Slave，A宕机切换到B后，C重新指定主库为B）<br>
2、不经常使用create table table_name select * from table_name/create temporary table/update t1,t2 where ...这种语句的场合</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql事务隔离级别及实现]]></title>
        <id>https://esp0x.github.io/post/mysql-shi-wu-ge-chi-ji-bie-ji-shi-xian/</id>
        <link href="https://esp0x.github.io/post/mysql-shi-wu-ge-chi-ji-bie-ji-shi-xian/">
        </link>
        <updated>2021-01-18T08:12:13.000Z</updated>
        <content type="html"><![CDATA[<h2 id="四个基本要素acid">四个基本要素（ACID）</h2>
<ul>
<li>原子性（Atomicity）</li>
<li>一致性（Consistency）</li>
<li>隔离性（Isolation）</li>
<li>持久性（Durability）</li>
</ul>
<h2 id="事务的并发问题">事务的并发问题</h2>
<ol>
<li>脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读到的数据是脏数据；</li>
<li>不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取的数据不一致；</li>
<li>幻读：幻读并不是说两次读取的结果集不同，幻读侧重的方面是某一次的select操作得到的结果所表征的数据状态无法支撑后续的业务操作。具体来说，select某条记录是否存在，不存在，准备插入此记录，但执行insert时发现此记录已存在，无法插入，此时就发生了幻读。</li>
</ol>
<h2 id="事务隔离级别">事务隔离级别</h2>
<table>
<thead>
<tr>
<th>事务隔离级别</th>
<th>脏读</th>
<th>不可重复读</th>
<th>幻读</th>
</tr>
</thead>
<tbody>
<tr>
<td>读未提交（read-uncommitted）</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>不可重复读（read-committed）</td>
<td>否</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>可重复读（repeatable-read）</td>
<td>否</td>
<td>否</td>
<td>是</td>
</tr>
<tr>
<td>串行化（serializable）</td>
<td>否</td>
<td>否</td>
<td>否</td>
</tr>
</tbody>
</table>
<h4 id="查看数据库隔离级别">查看数据库隔离级别</h4>
<pre><code class="language-sql">mysql&gt; select @@global.tx_isolation, @@tx_isolation;
</code></pre>
<h2 id="acid实现原理">ACID实现原理</h2>
<h3 id="原子性">原子性</h3>
<p>实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB实现回滚，依赖的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log，如果事务执行失败或调用rollback，导致事务需要回滚，便可以利用undo log中的信息将数据进行回滚。undo log其实就是记录数据修改时的相反操作。</p>
<h3 id="持久性">持久性</h3>
<p>实现持久性主要依赖redo log，redo log采用WAL，所有修改先写入日志，再更新到Buffer Pool，保证了数据库不会因意外宕机而丢失。写redo log是要比刷缓存到磁盘要快的，原因如下：</p>
<ol>
<li>刷脏是随机IO、这个很好理解；而redo log是追加操作，属于顺序IO，所以速度快；</li>
<li>刷脏是以Page为单位的，Mysql默认页大小是16KB，一个Page上一个小的修改都需要整页写入；而redo log中只包含真正需要写入的部分，无效IO减少；</li>
</ol>
<p>关于binlog和redo log的区别：</p>
<ul>
<li>作用不同：redo log是用于crash recovery的，保证MySQL宕机也不会影响持久性；binlog是用于point-in-time recovery的，保证服务器可以基于时间点恢复数据，此外binlog还用于主从复制。</li>
<li>层次不同：redo log是InnoDB存储引擎实现的，而binlog是MySQL的服务器层实现的，同时支持InnoDB和其他存储引擎。</li>
<li>内容不同：redo log是物理日志，内容基于磁盘的Page；binlog的内容是二进制的，根据binlog_format参数的不同，可能基于sql语句、基于数据本身或者二者的混合。</li>
<li>写入时机不同：binlog在事务提交时写入；redo log的写入时机相对多元，可以通过双1设置进行控制；</li>
</ul>
<h3 id="隔离性">隔离性</h3>
<p>隔离性追求的是并发条件下事务之间互不干扰；主要考虑两种场景：</p>
<ol>
<li>
<p>两个事务的写操作之间的影响：</p>
<ul>
<li>InnoDB通过锁机制来保证同一时刻只有一个事务进行写操作，简单理解为，事务在修改数据之前，需要先获得相应的锁；获得锁之后，事务便可以修改数据，其他事务需要等待该锁释放后才能对同一数据进行操作。</li>
<li>表锁会锁住整个表，并发性能较差；</li>
<li>行锁只锁定需要操作的数据，并发性能好，但数据较多时性能也会下降；绝大多数情况下，我们使用行锁即可；</li>
</ul>
</li>
<li>
<p>两个事务的读操作之间的影响：</p>
<p>Mysql中默认的隔离级别是RR，InnoDB实现的RR可以避免幻读的问题，即使用MVCC技术，Multi-Version Concurrency Control。</p>
<p>MVCC最大的优点是读不加锁，因此读写不冲突，并发性好。InnoDB实现MVCC，多个版本的数据可以共存，主要依赖以下技术和数据结构：</p>
<pre><code class="language-shell">数据库需要做好版本控制，防止不该被事务看到的数据(例如还没提交的事务修改的数据)被看到。在InnoDB中，主要是通过使用readview的技术来实现判断。查询出来的每一行记录，都会用readview来判断一下当前这行是否可以被当前事务看到，如果可以，则输出，否则就利用undolog来构建历史版本，再进行判断，知道记录构建到最老的版本或者可见性条件满足。

在trx_sys中，一直维护这一个全局的活跃的读写事务id(trx_sys-&gt;descriptors)，id按照从小到大排序，表示在某个时间点，数据库中所有的活跃(已经开始但还没提交)的读写(必须是读写事务，只读事务不包含在内)事务。当需要一个一致性读的时候(即创建新的readview时)，会把全局读写事务id拷贝一份到readview本地(read_view_t-&gt;descriptors)，当做当前事务的快照。read_view_t-&gt;up_limit_id是read_view_t-&gt;descriptors这数组中最小的值，read_view_t-&gt;low_limit_id是创建readview时的max_trx_id，即一定大于read_view_t-&gt;descriptors中的最大值。当查询出一条记录后(记录上有一个trx_id，表示这条记录最后被修改时的事务id)，可见性判断的逻辑如下(lock_clust_rec_cons_read_sees)：

如果记录上的trx_id小于read_view_t-&gt;up_limit_id，则说明这条记录的最后修改在readview创建之前，因此这条记录可以被看见。

如果记录上的trx_id大于等于read_view_t-&gt;low_limit_id，则说明这条记录的最后修改在readview创建之后，因此这条记录肯定不可以被看家。

如果记录上的trx_id在up_limit_id和low_limit_id之间，且trx_id在read_view_t-&gt;descriptors之中，则表示这条记录的最后修改是在readview创建之时，被另外一个活跃事务所修改，所以这条记录也不可以被看见。如果trx_id不在read_view_t-&gt;descriptors之中，则表示这条记录的最后修改在readview创建之前，所以可以看到。

基于上述判断，如果记录不可见，则尝试使用undo去构建老的版本(row_vers_build_for_consistent_read)，直到找到可以被看见的记录或者解析完所有的undo。

针对RR隔离级别，在第一次创建readview后，这个readview就会一直持续到事务结束，也就是说在事务执行过程中，数据的可见性不会变，所以在事务内部不会出现不一致的情况。针对RC隔离级别，事务中的每个查询语句都单独构建一个readview，所以如果两个查询之间有事务提交了，两个查询读出来的结果就不一样。从这里可以看出，在InnoDB中，RR隔离级别的效率是比RC隔离级别的高。此外，针对RU隔离级别，由于不会去检查可见性，所以在一条SQL中也会读到不一致的数据。针对串行化隔离级别，InnoDB是通过锁机制来实现的，而不是通过多版本控制的机制，所以性能很差。

由于readview的创建涉及到拷贝全局活跃读写事务id，所以需要加上trx_sys-&gt;mutex这把大锁，为了减少其对性能的影响，关于readview有很多优化。例如，如果前后两个查询之间，没有产生新的读写事务，那么前一个查询创建的readview是可以被后一个查询复用的。
</code></pre>
</li>
<li>
<p>操作指令：</p>
</li>
</ol>
<pre><code class="language-sql">mysql&gt; select * from information_schema.innodb_locks; #锁的概况
mysql&gt; show engine innodb status;                     #InnoDB整体状态，其中包括锁的情况
</code></pre>
<h3 id="一致性">一致性</h3>
<p>一致性是事务追求的终极目标，原子性、持久性和隔离性，都是为了实现一致性而存在的；实现一致性也需要应用层面进行保障；</p>
<h3 id="运维相关指令和参数">运维相关指令和参数</h3>
<pre><code class="language-shell">1、首先介绍一下information_schema中的三张表: innodb_trx, innodb_locks和innodb_lock_waits。由于这些表几乎需要查询所有事务子系统的核心数据结构，为了减少查询对系统性能的影响，InnoDB预留了一块内存，内存里面存了相关数据的副本，如果两次查询的时间小于0.1秒(CACHE_MIN_IDLE_TIME_US)，则访问的都是同一个副本。如果超过0.1秒，则这块内存会做一次更新，每次更新会把三张表用到的所有数据统一更新一遍，因为这三张表经常需要做表连接操作，所以一起更新能保证数据的一致性。这里简单介绍一下innodb_trx表中的字段，另外两张表涉及到事物锁的相关信息，由于篇幅限制，后续有机会在介绍。

trx_id: 就是trx_t中的事务id，如果是只读事务，这个id跟trx_t的指针地址有关，所以可能是一个很大的数字(trx_get_id_for_print)。
trx_weight: 这个是事务的权重，计算方法就是undolog数量加上事务已经加上锁的数量。在事务回滚的时候，优先选择回滚权重小的事务，有非事务引擎参与的事务被认为权重是最大的。
trx_rows_modified：这个就是当前事务已经产生的undolog数量，每更新一条记录一次，就会产生一条undo。
trx_concurrency_tickets: 每次这个事务需要进入InnoDB层时，这个值都会减一，如果减到0，则事务需要等待(压力大的情况下)。
trx_is_read_only: 如果是以start transaction read only启动事务的，那么这个字段是1，否则为0。
trx_autocommit_non_locking: 如果一个事务是一个普通的select语句(后面没有跟for update, share lock等)，且当时的autocommit为1，则这个字段为1，否则为0。
trx_state: 表示事务当前的状态，只能有RUNNING, LOCK WAIT, ROLLING BACK, COMMITTING这几种状态, 是比较粗粒度的状态。
trx_operation_state: 表示事务当前的详细状态，相比于trx_state更加详细，例如有rollback to a savepoint, getting list of referencing foreign keys, rollback of internal trx on stats tables, dropping indexes等。

2、与事务相关的undo参数

innodb_undo_directory: undo文件的目录，建议放在独立的一块盘上，尤其在经常有大事务的情况下。
innodb_undo_logs: 这个是定义了undo segment的个数。在给读写事务分配undo segment的时候，拿这个值去做轮训分配。
Innodb_available_undo_logs: 这个是一个status变量，在启动的时候就确定了，表示的是系统上分配的undo segment。举个例子说明其与innodb_undo_logs的关系：假设系统初始化的时候innodb_undo_logs为128，则在文件上一定有128个undo segment，Innodb_available_undo_logs也为128，但是启动起来后，innodb_undo_logs动态被调整为100，则后续的读写事务只会使用到前100个回滚段，最后的20多个不会使用。
innodb_undo_tablespaces: 存放undo segment的物理文件个数，文件名为undoN，undo segment会比较均匀的分布在undo tablespace中。

3、与Purge相关的参数

innodb_purge_threads: Purge Worker和Purge Coordinator总共的个数。在实际的实现中，使用多少个线程去做Purge是InnoDB根据实时负载进行动态调节的。
innodb_purge_batch_size: 一次性处理的undolog的数量，处理完这个数量后，Purge线程会计算是否需要sleep。
innodb_max_purge_lag: 如果全局历史链表超过这个值，就会增加Purge Worker线程的数量，也会使用sleep的方式delay用户的DML。
innodb_max_purge_lag_delay: 这个表示通过sleep方式delay用户DML最大的时间。

4、与回滚相关的参数

innodb_lock_wait_timeout: 等待行锁的最大时间，如果超时，则会滚当前语句或者整个事务。发生回滚后返回类似错误：Lock wait timeout exceeded; try restarting transaction。
innodb_rollback_on_timeout: 如果这个参数为true，则当发生因为等待行锁而产生的超时时，回滚掉整个事务，否则只回滚当前的语句。这个就是隐式回滚机制。主要是为了兼容之前的版本。
</code></pre>
<h2 id="总结">总结</h2>
<ul>
<li>原子性：语句要么全执行，要么全不执行，是事务最核心的特性，事务本身就是以原子性来定义的；实现主要基于undo log</li>
<li>持久性：保证事务提交后不会因为宕机等原因导致数据丢失；实现主要基于redo log</li>
<li>隔离性：保证事务执行尽可能不受其他事务影响；InnoDB默认的隔离级别是RR，RR的实现主要基于锁机制（包含next-key lock）、MVCC（包括数据的隐藏列、基于undo log的版本链、ReadView）</li>
<li>一致性：事务追求的最终目标，一致性的实现既需要数据库层面的保障，也需要应用层面的保障</li>
</ul>
<h2 id="参考文献">参考文献</h2>
<h4 id="httpmysqltaobaoorgmonthly20171201">http://mysql.taobao.org/monthly/2017/12/01/</h4>
<h4 id="httpswwwcnblogscomkismetvp10331633html">https://www.cnblogs.com/kismetv/p/10331633.html</h4>
<h4 id="httpszhuanlanzhihucomp40208895">https://zhuanlan.zhihu.com/p/40208895</h4>
<h4 id="httpswwwcnblogscomhuanongyingp7021555html">https://www.cnblogs.com/huanongying/p/7021555.html</h4>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql主从复制环境搭建]]></title>
        <id>https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-huan-jing-da-jian/</id>
        <link href="https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-huan-jing-da-jian/">
        </link>
        <updated>2021-01-15T02:15:27.000Z</updated>
        <content type="html"><![CDATA[<h2 id="准备机器">准备机器</h2>
<p>两台centos7系统服务器：</p>
<p>主mysql：192.168.50.1</p>
<p>从mysql：192.168.50.2</p>
<h2 id="安装mysql">安装mysql</h2>
<ol>
<li>
<p>下载yum源</p>
<pre><code class="language-shell">wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm
</code></pre>
</li>
<li>
<p>安装yum源</p>
<pre><code class="language-shell">rpm -Uvh mysql80-community-release-el7-3.noarch.rpm
</code></pre>
</li>
<li>
<p>安装mysql</p>
<pre><code class="language-shell">yum install -y mysql-community-server
</code></pre>
</li>
<li>
<p>启动mysql，并获取root初始密码</p>
<pre><code class="language-shell"># 确保selinux为disabled
# 确保关闭了firewalld服务

systemctl start mysqld

[root@localhost ~]# grep password /var/log/mysqld.log 
2020-10-19T02:47:35.912896Z 1 [Note] A temporary password is generated for root@localhost: -1k-1KjU*LG)
</code></pre>
</li>
<li>
<p>登入mysql，并重置root密码</p>
<pre><code class="language-shell">mysql -uroot -p 
mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'qUXmZP11JwJ_11'; # root本地访问，且重置
mysql&gt; exit
</code></pre>
</li>
</ol>
<h2 id="主mysql数据库配置">主Mysql数据库配置</h2>
<p>编辑my.cnf配置文件</p>
<pre><code class="language-shell">vim /etc/my.cnf

[mysqld]
port=9006          #指定新的端口
server-id=110      #设置主服务器的ID(不能和别的服务器重复，建议使用ip的最后一段)
log-bin=mysql-bin  #binlog日志文件名
</code></pre>
<p>创建用于主从同步的账户</p>
<pre><code class="language-shell">$ mysql -u root -p  #登录MySQL
mysql&gt; CREATE USER 'repl'@'192.168.50.2' IDENTIFIED WITH mysql_native_password BY 'Top_master_1'; # 主库创建用于从库同步的账号
mysql&gt; grant replication slave on *.* to 'repl'@'192.168.50.2';  #赋予主从同步权限，指定具体的数据库在/etc/my.cnf中完成
mysql&gt; flush privileges;
</code></pre>
<p>重启MySQL，使my.cnf 配置生效；查看主库状态</p>
<pre><code class="language-shell">$ systemctl restart mysqld #重启MySQL
mysql -u root -p
mysql&gt; show master status; #查看主库的状态  File,Position 这两个值需要放到slave配置中
+--------------------+----------+--------------+------------------+-------------------+
| File               | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+--------------------+----------+--------------+------------------+-------------------+
| mysql-bin.00001    |      156 |     xxxx     |                  |                   |
+--------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec)
</code></pre>
<h2 id="从mysql数据库配置">从Mysql数据库配置</h2>
<p>编辑配置文件</p>
<pre><code class="language-shell">vim /etc/my.cnf

[mysqld]
port=9006
server-id=111
</code></pre>
<p>配置完成后，重启从库的MySQL</p>
<pre><code class="language-shell">$ systemctl restart mysqld  #重启MySQL
$ mysql -u root -p          #登录mysql
mysql&gt; stop slave;          #关闭从库
mysql&gt; change master to master_host='192.168.50.1',master_port=9006,master_user='repl',master_password='Top_master_1',master_log_file='mysql-bin.00001',master_log_pos=156; #配置主库信息
mysql&gt; start slave;            #开启从库 
mysql&gt; show slave status \G;   #Slave_IO_Running,Slave_SQL_Running 都为Yes的时候表示配置成功
</code></pre>
<h2 id="主库创建数据库和数据表">主库创建数据库和数据表</h2>
<pre><code class="language-sql">create database topmanager DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
登入从库，可以看到从库中出现同样的数据库和数据表，表明已同步</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql双1设置-数据安全的关键参数]]></title>
        <id>https://esp0x.github.io/post/mysql-shuang-1-she-zhi-shu-ju-an-quan-de-guan-jian-can-shu/</id>
        <link href="https://esp0x.github.io/post/mysql-shuang-1-she-zhi-shu-ju-an-quan-de-guan-jian-can-shu/">
        </link>
        <updated>2021-01-15T02:14:24.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-参数及设置说明">一、参数及设置说明</h2>
<pre><code class="language-shell"># innodb_flush_log_at_trx_commit
1.设置为0：log buffer将每秒一次地写入log file中，并且log file的flush操作同时进行；该模式下，在事务提交时，不会主动触发写入磁盘的操作；
2.设置为1：每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去;
3.设置为2：每次事务提交时MySQL都会把log buffer的数据写入log file，但是flush(刷到磁盘)操作并不会同时进行。该模式下,MySQL会每秒执行一次 flush(刷到磁盘)操作。

# sync_binlog
sync_binlog 的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。
当sync_binlog =N (N&gt;0) ，MySQL 在每写 N次 二进制日志binary log时，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去。

注意：如果启用了autocommit，那么每一个语句statement就会有一次写操作；否则每个事务对应一个写操作。

# 性能与安全性对比 
1.双1设置时，写入性能最差，安全性最高；
2.sync_binlog=N (N&gt;1 ) innodb_flush_log_at_trx_commit=2 时，性能最好，安全性较差；
3.innodb_flush_log_at_trx_commit设置为0，mysqld进程崩溃会导致上一秒钟所有事务数据的丢失；
4.innodb_flush_log_at_trx_commit设置为2，当系统崩溃或者断电时，上一秒的所有数据才有可能丢失；
</code></pre>
<h2 id="二-对io影响较大的几个参数">二、对IO影响较大的几个参数</h2>
<pre><code class="language-shell">1.innodb_buffer_pool_size # 该参数控制innodb缓存大小，用于缓存应用访问的数据，推荐配置为系统可用内存的80%。
2.binlog_cache_size       # 该参数控制二进制日志缓冲大小，当事务还没有提交时，事务日志存放于cache，当遇到大事务cache不够用的时，mysql会把uncommitted的部分写入临时文件,等到committed的时候才会写入正式的持久化日志文件。
3.innodb_max_dirty_pages_pct     # 该参数可以直接控制Dirty Page在BP中所占的比率，当dirty page达到了该参数的阈值，就会触发MySQL系统刷新数据到磁盘。
4.innodb_flush_log_at_trx_commit # 该参数确定日志文件何时write、flush。
5.sync_binlog         # sync_binlog的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。
6.innodb_flush_method # 该参数控制日志或数据文件如何write、flush。可选的值为fsync，o_dsync，o_direct，littlesync，nosync。
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql分库分表策略]]></title>
        <id>https://esp0x.github.io/post/mysql-fen-ku-fen-biao-ce-lue/</id>
        <link href="https://esp0x.github.io/post/mysql-fen-ku-fen-biao-ce-lue/">
        </link>
        <updated>2021-01-15T02:12:20.000Z</updated>
        <content type="html"><![CDATA[<p>数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库性能的目的。</p>
<h2 id="垂直切分">垂直切分</h2>
<p><img src="https://esp0x.github.io/post-images/1610676801903.jpg" alt="" loading="lazy"><br>
垂直切分常见有垂直分库和垂直分表两种：</p>
<p>垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库中。类似微服务架构，每一个微服务单独使用一个数据库的形式。</p>
<p>垂直分表是基于数据库中的列进行， 针对某个表字段过多，可以新建一张扩展表，将不常用的字段或长度较大的字段拆分到扩展表中。这样可以避免跨页问题，MySQL底层是通过数据页存储的，一条记录过大会导致跨页，造成额外的性能损失。</p>
<h3 id="垂直切分的优点">垂直切分的优点：</h3>
<ol>
<li>解决业务系统层面的耦合，使得业务逻辑更清晰；</li>
<li>与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等；</li>
<li>高并发场景下，垂直切分一定程度上能够提升访问性能；</li>
</ol>
<h3 id="垂直切分的缺点">垂直切分的缺点：</h3>
<ol>
<li>部分表无法join，只能通过接口方式，开发难度增加；</li>
<li>分布式事务处理复杂；</li>
<li>没有解决单表数据过大的问题；</li>
</ol>
<h2 id="水平切分">水平切分</h2>
<p><img src="https://esp0x.github.io/post-images/1610676821810.jpg" alt="" loading="lazy"><br>
当一个应用难以再细粒化的垂直切分，或切分后单表数据量过大，存在读写性能问题时，就需要考虑水平切分了。</p>
<p>水平切分包括库内分表和分库分表，库内分表只解决了单一表数据量过大的问题，没有将表分布到不同的机器上，对于数据库访问性能提升有限。</p>
<h3 id="水平切分的优点">水平切分的优点：</h3>
<ol>
<li>不存在单表数据量过大问题，提升了表的访问性能；</li>
<li>应用端改造较小，不需要进行业务拆分；</li>
</ol>
<h3 id="水平切分的缺点">水平切分的缺点：</h3>
<ol>
<li>跨分片事务的一致性难以保证；</li>
<li>跨库的join关联查询性能较差；</li>
<li>数据库多次扩展难度和维护量增加；</li>
</ol>
<h2 id="几种典型的数据分片规则">几种典型的数据分片规则</h2>
<ul>
<li>
<p>根据数值范围</p>
<p>例如：按照时间维度，将不同月，甚至不同日的数据存储到不同的表；又或者，按照userId进行划分，1-9999的记录分到第一个库，10000-20000的分到第二个库，以此类推；</p>
<p>优点：</p>
<ol>
<li>单表大小可控；</li>
<li>天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点，无需对其他分片进行数据迁移；</li>
<li>使用分片字段进行查询时，速度更快；</li>
</ol>
<p>缺点：</p>
<ol>
<li>热点数据成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间的数据，可能会被频繁地读写，有些分片存储历史数据，则很少被查询。</li>
</ol>
</li>
<li>
<p>根据数值取模</p>
<p>一般采用hash取模mod的切分方式。</p>
<p>优点：</p>
<ol>
<li>数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈；</li>
</ol>
<p>缺点：</p>
<ol>
<li>后期扩展时，需要迁移旧的数据；（通过一致性hash算法可以避免这个问题）</li>
<li>容易面临跨分片查询的复杂问题，比如频繁查询中不包含分片字段，将会导致无法定位数据库，从而向所有数据库发起请求，再在内存中合并数据，性能损失严重；</li>
</ol>
</li>
</ul>
<h2 id="分库分表需要解决的问题">分库分表需要解决的问题</h2>
<ul>
<li>
<p>事务问题</p>
<p>方案一：使用分布式事务，交由数据库管理，简单有效；缺点是随着节点增加，性能代价越来越高。（需要协调的节点变多）</p>
<p>方案二：由应用程序和数据库共同控制，性能上有优势；缺点是开发难度较大；</p>
</li>
<li>
<p>跨节点Join问题</p>
<p>分两次查询，第一次查询的结果集中找出关联数据的ID，根据这些ID发起第二次请求得到关联数据；在应用设计时应尽量避免进行关联查询；</p>
</li>
<li>
<p>跨节点的count、order by、group by以及聚合函数问题</p>
<p>分别在各个节点进行数据合并，最后在统一进行合并，缺点是当数据集较大时，占用的内存资源很多；</p>
</li>
<li>
<p>数据迁移、容量规划、扩容等问题</p>
<p>当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。</p>
</li>
<li>
<p>全局主键避重问题</p>
<p>由于表同时存在于多个数据库中，主键值设置为自增序列将不能使用，需要单独设计全局主键，一般可以用UUID的方案解决；</p>
</li>
<li>
<p>跨分片的排序分页</p>
<p>一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。</p>
<p>如果是在前台应用提供分页，则限定用户只能看前面n页，这个限制在业务上也是合理的，一般看后面的分页意义不大（如果一定要看，可以要求用户缩小范围重新查询）。</p>
<p>如果是后台批处理任务要求分批获取数据，则可以加大page size，比如每次获取5000条记录，有效减少分页数（当然离线访问一般走备库，避免冲击主库）。</p>
<p>分库设计时，一般还有配套大数据平台汇总所有分库的记录，有些分页查询可以考虑走大数据平台。</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql主从复制原理]]></title>
        <id>https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-yuan-li/</id>
        <link href="https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-yuan-li/">
        </link>
        <updated>2021-01-14T08:23:14.000Z</updated>
        <content type="html"><![CDATA[<h3 id="原理图如下">原理图如下：</h3>
<figure data-type="image" tabindex="1"><img src="https://esp0x.github.io/post-images/1610671157156.png" alt="" loading="lazy"></figure>
<h2 id="主从复制流程详解">主从复制流程详解：</h2>
<ol>
<li>master库发生数据改变时，会将改变写入binglog日志；</li>
<li>slave库会在一定时间间隔内对master的binlog进行检测以确定是否发生改变，如果发生改变，则开始一个IO thread请求master二进制事件；</li>
<li>同时，master为每一个过来请求的IO thread开启一个dump线程，用于将二进制事件发送给IO thread，slave的IO thread将此二进制事件写入本地relay log（中继日志）中，并开启SQL thread从中继日志中读取二进制日志，在本地进行重放（replay），从而使得本地数据与master保持一致；最后IO thread和SQL thread进入睡眠状态，等待下次唤醒。</li>
</ol>
<h2 id="主从复制形式">主从复制形式：</h2>
<ol>
<li>主从</li>
<li>主主</li>
<li>一主多从</li>
<li>多主一从</li>
<li>联级复制</li>
</ol>
<h2 id="主从同步延时分析">主从同步延时分析：</h2>
<ol>
<li>master对所有DDL和DML产生的日志都写入binlog，由于是顺序写，所以效率很高；反之，slave的SQL thread进行relay log的重放时，DML和DDL的IO是随机的，不是顺序，所以成本较高，这里会增加一部分延时；</li>
<li>由于SQL thread是单线程的，当master的并发较高时，过多的DML可能会导致slave的SQL thread来不及处理，这里会增加一部分延时；</li>
<li>slave中有部分SQL产生了锁等待，这种情况就是slave有一些读请求与重放请求产生了锁冲突导致的，也会增加延时；</li>
<li>slave在充当读库角色的时候，如果查询访问压力过大，会消耗部分系统资源，影响同步效率；</li>
<li>大事务执行，即当master有大事务执行时，比如执行了10分钟，binlog写入必须要等待事务处理完毕，那么slave开始进行同步的时候就已经延时10分钟了；</li>
</ol>
<h2 id="延时解决办法">延时解决办法：</h2>
<ol>
<li>业务层实现读写分离，一主多从，主写从读，分散压力；</li>
<li>业务层和数据库层之间加入缓存策略，降低直接对数据库的读压力；频繁写的场景不适合加缓存，会导致缓存命中降低；</li>
<li>升级硬件；</li>
<li>MTS问题，即多线程的slave，从5.6版本开始支持，针对不同粒度（库、表、行）设置并行同步；</li>
</ol>
<h2 id="57版本后的并行复制策略">5.7版本后的并行复制策略</h2>
<h4 id="redo-log的两阶段提交">Redo log的两阶段提交</h4>
<ul>
<li>先写redo，再写binlog：假设在redo写完，binlog还没有写完的时候，Mysql进程异常重启，这时仍然能够通过redo log恢复数据，但由于binlog没有这条记录，所以之后备份日志的时候，binlog是缺失这条记录的，以后需要用binlog恢复数据时，就会缺少一条数据的更新；</li>
<li>先写binlog，再写redo log：如果binlog写完后crash，由于redo log还没写，崩溃恢复后这个事务无效，但是binlog有记录，以后用这个binlog恢复数据时，就会多出一条更新记录；</li>
<li>二阶段提交：使用二阶段提交时，会综合redo和binlog的状态进行处理，如果写入binlog之前crash，那么由于redo处于prepare阶段，只需要对当前事务进行回滚即可；如果写入binlog之后crash，那么由于redo处于prepare阶段，只需要对当前事务进行提交即可。</li>
</ul>
<h4 id="并行复制的思想">并行复制的思想</h4>
<ol>
<li>同时处于prepare状态的事务，在备库执行是可以并行的；</li>
<li>处于prepare状态的事务，与处于commit状态的事务之间，在备库执行也是可以并行的；</li>
<li>binlog_group_commit_sync_delay参数，表示延迟多少微妙后才调用fsync；</li>
<li>binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync；</li>
</ol>
]]></content>
    </entry>
</feed>