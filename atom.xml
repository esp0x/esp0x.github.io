<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://esp0x.github.io</id>
    <title>Grey</title>
    <updated>2021-07-14T01:33:03.540Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://esp0x.github.io"/>
    <link rel="self" href="https://esp0x.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://esp0x.github.io/images/avatar.png</logo>
    <icon>https://esp0x.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Grey</rights>
    <entry>
        <title type="html"><![CDATA[Centos 7/8 使用chrony进行时间同步配置]]></title>
        <id>https://esp0x.github.io/post/centos-78-shi-yong-chrony-jin-xing-shi-jian-tong-bu-pei-zhi/</id>
        <link href="https://esp0x.github.io/post/centos-78-shi-yong-chrony-jin-xing-shi-jian-tong-bu-pei-zhi/">
        </link>
        <updated>2021-07-14T01:25:52.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-安装">1. 安装</h3>
<pre><code class="language-shell"># yum -y install chrony
# systemctl enable chronyd
# systemctl start chronyd
</code></pre>
<h3 id="2配置">2.配置</h3>
<pre><code class="language-shell"># vi /etc/chrony.conf

# 使用 pool.ntp.org 项目中的公共服务器。以server开，理论上想添加多少时间服务器都可以。
# Use public servers from the pool.ntp.org project.
# Please consider joining the pool (http://www.pool.ntp.org/join.html).
server 0.centos.pool.ntp.org iburst
server 1.centos.pool.ntp.org iburst
server 2.centos.pool.ntp.org iburst
server 3.centos.pool.ntp.org iburst

# 根据实际时间计算出服务器增减时间的比率，然后记录到一个文件中，在系统重启后为系统做出最佳时间补偿调整。
# Record the rate at which the system clock gains/losses time.
driftfile /var/lib/chrony/drift

# 如果系统时钟的偏移量大于1秒，则允许系统时钟在前三次更新中步进。
# Allow the system clock to be stepped in the first three updates if its offset is larger than 1 second.
makestep 1.0 3

# 启用实时时钟（RTC）的内核同步。
# Enable kernel synchronization of the real-time clock (RTC).
rtcsync

# 通过使用 hwtimestamp 指令启用硬件时间戳
# Enable hardware timestamping on all interfaces that support it.
#hwtimestamp *

# Increase the minimum number of selectable sources required to adjust the system clock.
#minsources 2

# 指定 NTP 客户端地址，以允许或拒绝连接到扮演时钟服务器的机器
# Allow NTP client access from local network.
#allow 192.168.0.0/16

# Serve time even if not synchronized to a time source.
#local stratum 10

# 指定包含 NTP 身份验证密钥的文件。
# Specify file containing keys for NTP authentication.
#keyfile /etc/chrony.keys

# 指定日志文件的目录。
# Specify directory for log files.
logdir /var/log/chrony

# 选择日志文件要记录的信息。
# Select which information is logged.
#log measurements statistics tracking
</code></pre>
<h3 id="3手工同步">3.手工同步</h3>
<pre><code class="language-shell"># 查看 ntp_servers
chronyc sources -v

# 查看 ntp_servers 状态
chronyc sourcestats -v

# 查看 ntp_servers 是否在线
chronyc activity -v

# 查看 ntp 详细信息
chronyc tracking -v

# 手工进行同步
chronyc -a makestep
</code></pre>
<h3 id="4修改时区">4.修改时区</h3>
<pre><code class="language-shell"># 查看日期时间、时区及 NTP 状态
timedatectl

# 查看时区列表
timedatectl list-timezones
timedatectl list-timezones |  grep  -E &quot;Asia/S.*&quot;

# 修改时区
timedatectl set-timezone Asia/Shanghai

# 修改日期时间（可以只修改其中一个）
timedatectl set-time &quot;2019-09-19 15:50:20&quot;

# 开启 NTP
timedatectl set-ntp true/flase
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何避免在第一次SSH登陆时输入yes提示符]]></title>
        <id>https://esp0x.github.io/post/ru-he-bi-mian-zai-di-yi-ci-ssh-deng-lu-shi-shu-ru-yes-ti-shi-fu/</id>
        <link href="https://esp0x.github.io/post/ru-he-bi-mian-zai-di-yi-ci-ssh-deng-lu-shi-shu-ru-yes-ti-shi-fu/">
        </link>
        <updated>2021-06-23T03:46:19.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-shell">echo &quot;StrictHostKeyChecking no&quot; &gt;~/.ssh/config
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[K8s-Pod简单介绍]]></title>
        <id>https://esp0x.github.io/post/k8s-pod-jian-dan-jie-shao/</id>
        <link href="https://esp0x.github.io/post/k8s-pod-jian-dan-jie-shao/">
        </link>
        <updated>2021-06-08T07:06:03.000Z</updated>
        <content type="html"><![CDATA[<h3 id="概念">概念</h3>
<h5 id="在kubernetes集群中pod是所有业务类型的基础也是k8s管理的最小单位级它是一个或多个容器的组合-这些容器共享存储-网络和命名空间以及如何运行的规范-在pod中所有容器都被同一安排和调度并运行在共享的上下文中-对于具体应用而言pod是它们的逻辑主机pod包含业务相关的多个应用容器">在Kubernetes集群中，Pod是所有业务类型的基础，也是K8S管理的最小单位级，它是一个或多个容器的组合。这些容器共享存储、网络和命名空间，以及如何运行的规范。在Pod中，所有容器都被同一安排和调度，并运行在共享的上下文中。对于具体应用而言，Pod是它们的逻辑主机，Pod包含业务相关的多个应用容器。</h5>
<h3 id="两个注意点">两个注意点</h3>
<pre><code class="language-python">1.网络:
  每一个Pod都会被指派一个唯一的Ip地址，在Pod中的每一个容器共享网络命名空间，包括Ip地址和网络端口。在同一个Pod中的容器可以同locahost进行互相通信。当Pod中的容器需要与Pod外的实体进行通信时，则需要通过端口等共享的网络资源。

2.存储:
  Pod能够被指定共享存储卷的集合，在Pod中所有的容器能够访问共享存储卷，允许这些容器共享数据。存储卷也允许在一个Pod持久化数据，以防止其中的容器需要被重启。
</code></pre>
<h3 id="pod的生命周期">Pod的生命周期</h3>
<pre><code class="language-shel">一共有4种状态：

1. Pending：APIserver已经创建该server，但pod中有一个或多个容器的镜像还未创建，可能在下载中；
2. Running：Pod中的所有容器都已创建，且至少有一个容器处于运行状态，正在启动或重启状态；
3. Failed：Pod内所有容器都已退出，其中至少有一个容器退出失败；
4. Unknown：由于某种原因无法获取Pod的状态比如网络问题；
</code></pre>
<h3 id="pod的重启策略">Pod的重启策略</h3>
<pre><code class="language-py">重启策略对同一个Pod中的所有容器起作用，容器的重启由Node上的kubelet执行，支持三种策略，在配置文件中通过restartPolicy字段设置：
1. Always：只要退出就会重启
2. OnFailure：只有在失败退出时，才会重启
3. Never：只要退出，就不再重启

注意，这里的重启是指在Pod的宿主Node上进行本地重启，而不是调度到其它Node上。
</code></pre>
<h3 id="健康检查">健康检查</h3>
<pre><code class="language-shell"># 两种探针类型：
一、LivenessProbe探针：  判断容器是否存活（running）
1.ExecAction，在容器内部执行一个命令，状态返回码为0，表示健康，示例：
apiVersion: v1
kind: Pod
metadata:
 name: liveness
spec:
  containers:
  - name: liveness
    image: liveness
    args: 
    - /bin/sh
    - -c
    - echo ok &gt; /tmp/healthy: sleep 10; rm - rf /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/health
    initialDelaySeconds: 15
    timeoutSeconds: 1
    
2.TcpAction，通过IP和PORT，如果能够和容器建立连接则表示容器健康，示例：
apiVersion: v1
kind: Pod
metadata:
 name: pod-with-healthcheck
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
    livenessProbe:
      tcpSocket:
        port: 80
    initialDelaySeconds: 15
    timeoutSeconds: 1
3.HttpGetAction，发送get请求，返回码在200-400之间表示健康， 示例：
apiVersion: v1
kind: Pod
metadata:
 name: pod-with-healthcheck
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
    - containerPort: 80
    livenessProbe:
      httpGet:
        path: /_status/healthz  //请求路径
        port: 80
    initialDelaySeconds: 15
    timeoutSeconds: 1
    
二、ReadinessProbe探针： 用于判断容器是否启动完成（ready）
</code></pre>
<h3 id="pod的调度">Pod的调度</h3>
<pre><code class="language-shell"># 定向调度，nodeSelector
1.首先通过kubectl给node打上标签：
格式： kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;
kubectl label nodes node1 zone=north

2.在pod定义里选择某个node
apiVersion: v1
kind: Pod
metadata:
name: pod-with-healthcheck
spec:
containers:
- name: nginx
  image: nginx
  ports:
  - containerPort: 80
nodeSelector:
  zone: north

# 亲和性和非亲和性
一、Node affinity（节点亲和性）
1. requiredDuringSchedulingIgnoredDuringExecution：
可认为一种强制限制，如果 Node 的标签发生了变化导致其没有符合 Pod 的调度要求节点，那么pod调度就会失败。
2.preferredDuringSchedulingIgnoredDuringExecution：
软限或偏好，同样如果 Node 的标签发生了变化导致其不再符合 pod 的调度要求，pod 依然会调度运行。

二、Pod Affinity（Pod亲和性）
    podAffinity用于调度pod可以和哪些pod部署在同一拓扑结构之下。而podAntiAffinity相反，其用于规定pod不可以和哪些pod部署在同一拓扑结构下。通过pod affinity与anti-affinity来解决pod和pod之间的关系。
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[K8s-Namespace基本知识]]></title>
        <id>https://esp0x.github.io/post/namespace-ji-ben-zhi-shi/</id>
        <link href="https://esp0x.github.io/post/namespace-ji-ben-zhi-shi/">
        </link>
        <updated>2021-06-08T07:03:54.000Z</updated>
        <content type="html"><![CDATA[<h3 id="名词解释">名词解释</h3>
<h5 id="namespace是对一组资源和对象的抽象集合比如可用来将系统内部的对象划分为不同的项目或用户组-常见的podsservicesrc和deployments等都是属于某一个namespace的默认是default而nodepersistentvolumns等则不属于任何namespace">Namespace是对一组资源和对象的抽象集合，比如可用来将系统内部的对象划分为不同的项目或用户组。常见的pods，services，rc和deployments等都是属于某一个namespace的（默认是default），而node，persistentVolumns等则不属于任何namespace。</h5>
<h3 id="namespace相关操作">Namespace相关操作</h3>
<pre><code class="language-shell">kubectl可以通过–namespace或者-n选项指定namespace。如果不指定，默认为default。查看操作下,也可以通过设置–all-namespace=true来查看所有namespace下的资源。

# 查询ns
$ kubectl get namespaces
NAME          STATUS    AGE
default       Active    11d
kube-system   Active    11d

# 查询哪些资源位于namespace中
kubectl api-resources --namespaced=true
# 查看哪些资源不在命令空间
kubectl api-resources --namespaced=false

# 指定ns查询对应ns中的资源情况
kubectl get pods -n kube-system

# 创建
# 1.命令行直接创建
$ kubectl create namespace new-namespace

# 2.通过文件创建
$ cat my-namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: new-namespace

$ kubectl create -f ./my-namespace.yaml

# 删除，即删除该ns下所有资源
# 注意：default和kube-system命名空间不能删除
$ kubectl delete namespaces new-namespace

# 切换ns
kubectl config set-context --current --namespace=kube-system
</code></pre>
<h3 id="关于namespace是否隔离网络">关于Namespace是否隔离网络</h3>
<h5 id="一般情况下默认是不会隔离网络流量的除非对某个namespace设置了安全策略">一般情况下，默认是不会隔离网络流量的，除非对某个namespace设置了安全策略。</h5>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[K8s-使用Minikube搭建本地学习环境]]></title>
        <id>https://esp0x.github.io/post/shi-yong-minikube-da-jian-ben-di-xue-xi-huan-jing/</id>
        <link href="https://esp0x.github.io/post/shi-yong-minikube-da-jian-ben-di-xue-xi-huan-jing/">
        </link>
        <updated>2021-06-08T07:02:59.000Z</updated>
        <content type="html"><![CDATA[<h3 id="安装kubectl">安装kubectl</h3>
<pre><code class="language-shell"># 注意：安装方法推荐参考官方网站，安装方式随着版本变更会发生变动
# 下载二进制文件
curl -LO &quot;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl&quot;
# 下载校验文件
curl -LO &quot;https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256&quot;
# 检查下载文件和校验文件是否匹配
echo &quot;$(&lt;kubectl.sha256) kubectl&quot; | sha256sum --check
# 安装二进制文件
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
# 检查安装是否成功
kubectl version --client
</code></pre>
<h3 id="安装minikube">安装Minikube</h3>
<pre><code class="language-shell"># 下载二进制文件
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
# 安装二进制文件
sudo install minikube-linux-amd64 /usr/local/bin/minikube
# 启动集群，启动之前需要确保系统中有容器运行时，比如docker，kvm，否则集群启动失败
minikube start

# 若出现：The &quot;docker&quot; driver should not be used with root privileges.
# 将当前具有sudo权限的用户添加到docker组即可
sudo usermod -aG docker &lt;username&gt;
# 激活组的配置，这步必须
newgrp docker
# 再次启动
minikube start
# 查看集群信息
kubectl cluster-info

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ansible-Playbook中使用copy来传输文件]]></title>
        <id>https://esp0x.github.io/post/playbook-zhong-shi-yong-copy-lai-chuan-shu-wen-jian/</id>
        <link href="https://esp0x.github.io/post/playbook-zhong-shi-yong-copy-lai-chuan-shu-wen-jian/">
        </link>
        <updated>2021-06-07T09:27:30.000Z</updated>
        <content type="html"><![CDATA[<h3 id="基本配置示例">基本配置示例</h3>
<pre><code class="language-shell">- hosts: all
    vars: 
      wss_url: http://10.77.10.125:8545 
    tasks:
      - name: &quot;推送配置文件&quot;
        template: src=/home/fm/ops/scripts/default.yaml dest=/etc/bee/default.yaml
      - name: &quot;send all scripts&quot;
        copy:
          src: '{{ item.src }}'
          dest: /tmp/
          owner: root
          group: root
          mode: 755
        with_items:
          - { src: '/home/fm/ops/scripts/start05.sh' }
          - { src: '/home/fm/ops/scripts/stop.sh' }
  
 
# 使用{{ item.src }}读取with_items中的数组元素，访问需要拷贝的每一个文件即可。

# 检查语法
ansible-playbook --syntax-check example.yaml
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ansible-Playbook中用户的切换问题]]></title>
        <id>https://esp0x.github.io/post/playbook-zhong-yong-hu-de-qie-huan-wen-ti/</id>
        <link href="https://esp0x.github.io/post/playbook-zhong-yong-hu-de-qie-huan-wen-ti/">
        </link>
        <updated>2021-06-07T09:21:20.000Z</updated>
        <content type="html"><![CDATA[<h3 id="become配置示例">become配置示例：</h3>
<pre><code class="language-shell">- hosts: www.360.com
  remote_user: zabbix
  become: yes
  become_method: su
  tasks:
   - selinux:
        state: disabled
   - name: disable firewalld
     shell: systemctl stop firewalld &amp;&amp; systemctl disable firewalld
 
# become说明
become:        yes  # 是否允许身份切换
become_method: su   # 切换用户身份的方式，有sudo、su、pbrun等方式，默认为sudo
become_user: root   # 切换指定的用户，默认不写，就是root
</code></pre>
<h3 id="sudo配置解释">sudo配置解释</h3>
<pre><code class="language-shell">hosts                # 指定主机分组，可以取并集，交集等
remote_user          # 用于指定远程主机上的执行任务的用户，最佳实践是该用户具有sudo权限
user                 # 和remote_user相同
sudo                 # 如果设置为yes，执行该任务组的用户在执行任务的时候，获取root权限，也可以命令行使用-b参数
sudo_user            # 如果设置user为A，sudo为yes，sudo_user为B时，则A用户在执行任务时会获得B用户的权限，比较麻烦，不推荐
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ansible-Playbook利用tags执行部分task]]></title>
        <id>https://esp0x.github.io/post/playbook-li-yong-tags-zhi-xing-bu-fen-task/</id>
        <link href="https://esp0x.github.io/post/playbook-li-yong-tags-zhi-xing-bu-fen-task/">
        </link>
        <updated>2021-06-07T09:20:35.000Z</updated>
        <content type="html"><![CDATA[<h3 id="基本使用方法示例配置">基本使用方法，示例配置：</h3>
<pre><code class="language-shell">tasks:
  - yum: name={{ item }} state=installed
    with_items:
       - httpd
    tags:
       - packages
  - name: copy httpd.conf
    template: src=templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf
    tags:
       - configuration
  - name: copy index.html
    template: src=templates/index.html.j2 dest=/var/www/html/index.html
    tags:
       - configuration
  
 
# 执行部分任务
ansible-playbook example.yml --tags &quot;packages&quot;

# 指定不执行packages部分的任务
ansible-playbook example.yml --skip-tags &quot;configuration&quot;
</code></pre>
<h3 id="特殊的tags">特殊的tags</h3>
<pre><code class="language-shell"># always 标签，即使指定执行了某tag的任务，标记为always的任务也会被执行
tasks:
  - debug: msg=&quot;Always print this debug message&quot;
    tags:
      - always
  - yum: name={{ item }} state=installed
    with_items:
       - httpd
    tags:
       - packages
  - template: src=templates/httpd.conf.j2 dest=/etc/httpd/conf/httpd.conf
    tags:
       - configuration

# 这里标记为always的任务也会被执行
ansible-playbook tags_always.yml --tags &quot;packages&quot;

# targged，untagged，all，使用这些标签时，不需要加双引号
tagged，即执行所有被打标签的任务
untagged，即执行所有未被打标签的任务
all，所有任务
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Prometheus-使用prometheus监控主机docker容器运行状态]]></title>
        <id>https://esp0x.github.io/post/shi-yong-prometheus-jian-kong-zhu-ji-docker-rong-qi-yun-xing-zhuang-tai/</id>
        <link href="https://esp0x.github.io/post/shi-yong-prometheus-jian-kong-zhu-ji-docker-rong-qi-yun-xing-zhuang-tai/">
        </link>
        <updated>2021-06-07T08:27:03.000Z</updated>
        <content type="html"><![CDATA[<h3 id="部署方式容器化部署">部署方式：容器化部署</h3>
<h4 id="部署流程">部署流程：</h4>
<pre><code class="language-shell"># 运行node-exporter监控主机基本信息，访问9100端口进行验证
docker run -d --name node \
	-p 9100:9100 \
	-v /proc:/host/proc \
	-v /sys:/host/sys \
	-v /:/rootfs \
	--net=host prom/node-exporter \
	--path.procfs /host/proc \
	--path.sysfs /host/sys \
	--collector.filesystem.ignored-mount-points &quot;^/(sys|proc|dev|host|etc)($|/)&quot;

# 运行cAdvisor监控容器运行状态，访问8080端口进行验证
docker run -v /:/rootfs:ro \
	-v /var/run:/var/run/:rw \
	-v /sys:/sys:ro \
	-v /var/lib/docker:/var/lib/docker:ro \
	-p 8080:8080 \
	--detach=true \
	--name=cadvisor \
	--net=host google/cadvisor

# 在监控主节点上部署prometheus server，客户节点无需安装
docker run -d -p 9090:9090 --name prometheus --net=host prom/prometheus
# 将容器中的配置文件拷贝到宿主，进行修改
docker cp prometheus:/etc/prometheus/prometheus.yml ./
# 修改static_configs，指向所有客户节点的9100和8080端口获取数据
vim prometheus.yml

# 配置更新完成后，删除原prometheus server容器
docker rm prometheus -f
# 重新将本地配置文件映射到容器中，访问9090端口进行验证
docker run -d -p 9090:9090 --name prometheus --net=host -v /root/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus

# 部署grafana图形化界面，访问3000端口进行验证
mkdir grafana-storage
chmod 777 -R grafana-storage/
docker run -d -p 3000:3000 \
	--name grafana \
	-v /root/grafana-storage:/var/lib/grafana \
	-e &quot;GF_SECURITY_ADMIN_PASSWORD=123456&quot; grafana/grafana
	
# grafana模板，打开grafana.com, 点击dashborads，根据数据源和类型选择合适的模板

</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[如何拆除Linux软Raid设备]]></title>
        <id>https://esp0x.github.io/post/ru-he-chai-chu-linux-ruan-raid-she-bei/</id>
        <link href="https://esp0x.github.io/post/ru-he-chai-chu-linux-ruan-raid-she-bei/">
        </link>
        <updated>2021-04-20T08:11:37.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-shell">1. 卸载设备
# umount /dev/md0

2. 停止raid设备
# mdadm -S /dev/md0  // 停止raid设备

3. 查看属于raid组的设备名称
# blkid 

4. 从raid组中删除硬盘
# mdadm --misc --zero-superblock /dev/xxx

以下操作可选：
5. 删除配置文件：rm -f /etc/mdadm.conf

6. 更新/etc/fstab
</code></pre>
]]></content>
    </entry>
</feed>