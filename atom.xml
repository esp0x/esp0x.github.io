<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://esp0x.github.io</id>
    <title>Grey</title>
    <updated>2021-01-18T01:25:23.306Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://esp0x.github.io"/>
    <link rel="self" href="https://esp0x.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://esp0x.github.io/images/avatar.png</logo>
    <icon>https://esp0x.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Grey</rights>
    <entry>
        <title type="html"><![CDATA[Mysql主从复制环境搭建]]></title>
        <id>https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-huan-jing-da-jian/</id>
        <link href="https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-huan-jing-da-jian/">
        </link>
        <updated>2021-01-15T02:15:27.000Z</updated>
        <content type="html"><![CDATA[<h2 id="准备机器">准备机器</h2>
<p>两台centos7系统服务器：</p>
<p>主mysql：192.168.50.1</p>
<p>从mysql：192.168.50.2</p>
<h2 id="安装mysql">安装mysql</h2>
<ol>
<li>
<p>下载yum源</p>
<pre><code class="language-shell">wget https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm
</code></pre>
</li>
<li>
<p>安装yum源</p>
<pre><code class="language-shell">rpm -Uvh mysql80-community-release-el7-3.noarch.rpm
</code></pre>
</li>
<li>
<p>安装mysql</p>
<pre><code class="language-shell">yum install -y mysql-community-server
</code></pre>
</li>
<li>
<p>启动mysql，并获取root初始密码</p>
<pre><code class="language-shell"># 确保selinux为disabled
# 确保关闭了firewalld服务

systemctl start mysqld

[root@localhost ~]# grep password /var/log/mysqld.log 
2020-10-19T02:47:35.912896Z 1 [Note] A temporary password is generated for root@localhost: -1k-1KjU*LG)
</code></pre>
</li>
<li>
<p>登入mysql，并重置root密码</p>
<pre><code class="language-shell">mysql -uroot -p 
mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'qUXmZP11JwJ_11'; # root本地访问，且重置
mysql&gt; exit
</code></pre>
</li>
</ol>
<h2 id="主mysql数据库配置">主Mysql数据库配置</h2>
<p>编辑my.cnf配置文件</p>
<pre><code class="language-shell">vim /etc/my.cnf

[mysqld]
port=9006          #指定新的端口
server-id=110      #设置主服务器的ID(不能和别的服务器重复，建议使用ip的最后一段)
log-bin=mysql-bin  #binlog日志文件名
</code></pre>
<p>创建用于主从同步的账户</p>
<pre><code class="language-shell">$ mysql -u root -p  #登录MySQL
mysql&gt; CREATE USER 'repl'@'192.168.50.2' IDENTIFIED WITH mysql_native_password BY 'Top_master_1'; # 主库创建用于从库同步的账号
mysql&gt; grant replication slave on *.* to 'repl'@'192.168.50.2';  #赋予主从同步权限，指定具体的数据库在/etc/my.cnf中完成
mysql&gt; flush privileges;
</code></pre>
<p>重启MySQL，使my.cnf 配置生效；查看主库状态</p>
<pre><code class="language-shell">$ systemctl restart mysqld #重启MySQL
mysql -u root -p
mysql&gt; show master status; #查看主库的状态  File,Position 这两个值需要放到slave配置中
+--------------------+----------+--------------+------------------+-------------------+
| File               | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+--------------------+----------+--------------+------------------+-------------------+
| mysql-bin.00001    |      156 |     xxxx     |                  |                   |
+--------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec)
</code></pre>
<h2 id="从mysql数据库配置">从Mysql数据库配置</h2>
<p>编辑配置文件</p>
<pre><code class="language-shell">vim /etc/my.cnf

[mysqld]
port=9006
server-id=111
</code></pre>
<p>配置完成后，重启从库的MySQL</p>
<pre><code class="language-shell">$ systemctl restart mysqld  #重启MySQL
$ mysql -u root -p          #登录mysql
mysql&gt; stop slave;          #关闭从库
mysql&gt; change master to master_host='192.168.50.1',master_port=9006,master_user='repl',master_password='Top_master_1',master_log_file='mysql-bin.00001',master_log_pos=156; #配置主库信息
mysql&gt; start slave;            #开启从库 
mysql&gt; show slave status \G;   #Slave_IO_Running,Slave_SQL_Running 都为Yes的时候表示配置成功
</code></pre>
<h2 id="主库创建数据库和数据表">主库创建数据库和数据表</h2>
<pre><code class="language-sql">create database topmanager DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
登入从库，可以看到从库中出现同样的数据库和数据表，表明已同步</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql双1设置-数据安全的关键参数]]></title>
        <id>https://esp0x.github.io/post/mysql-shuang-1-she-zhi-shu-ju-an-quan-de-guan-jian-can-shu/</id>
        <link href="https://esp0x.github.io/post/mysql-shuang-1-she-zhi-shu-ju-an-quan-de-guan-jian-can-shu/">
        </link>
        <updated>2021-01-15T02:14:24.000Z</updated>
        <content type="html"><![CDATA[<h2 id="一-参数及设置说明">一、参数及设置说明</h2>
<pre><code class="language-shell"># innodb_flush_log_at_trx_commit
1.设置为0：log buffer将每秒一次地写入log file中，并且log file的flush操作同时进行；该模式下，在事务提交时，不会主动触发写入磁盘的操作；
2.设置为1：每次事务提交时MySQL都会把log buffer的数据写入log file，并且flush(刷到磁盘)中去;
3.设置为2：每次事务提交时MySQL都会把log buffer的数据写入log file，但是flush(刷到磁盘)操作并不会同时进行。该模式下,MySQL会每秒执行一次 flush(刷到磁盘)操作。

# sync_binlog
sync_binlog 的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。
当sync_binlog =N (N&gt;0) ，MySQL 在每写 N次 二进制日志binary log时，会使用fdatasync()函数将它的写二进制日志binary log同步到磁盘中去。

注意：如果启用了autocommit，那么每一个语句statement就会有一次写操作；否则每个事务对应一个写操作。

# 性能与安全性对比 
1.双1设置时，写入性能最差，安全性最高；
2.sync_binlog=N (N&gt;1 ) innodb_flush_log_at_trx_commit=2 时，性能最好，安全性较差；
3.innodb_flush_log_at_trx_commit设置为0，mysqld进程崩溃会导致上一秒钟所有事务数据的丢失；
4.innodb_flush_log_at_trx_commit设置为2，当系统崩溃或者断电时，上一秒的所有数据才有可能丢失；
</code></pre>
<h2 id="二-对io影响较大的几个参数">二、对IO影响较大的几个参数</h2>
<pre><code class="language-shell">1.innodb_buffer_pool_size # 该参数控制innodb缓存大小，用于缓存应用访问的数据，推荐配置为系统可用内存的80%。
2.binlog_cache_size       # 该参数控制二进制日志缓冲大小，当事务还没有提交时，事务日志存放于cache，当遇到大事务cache不够用的时，mysql会把uncommitted的部分写入临时文件,等到committed的时候才会写入正式的持久化日志文件。
3.innodb_max_dirty_pages_pct     # 该参数可以直接控制Dirty Page在BP中所占的比率，当dirty page达到了该参数的阈值，就会触发MySQL系统刷新数据到磁盘。
4.innodb_flush_log_at_trx_commit # 该参数确定日志文件何时write、flush。
5.sync_binlog         # sync_binlog的默认值是0，像操作系统刷其他文件的机制一样，MySQL不会同步到磁盘中去而是依赖操作系统来刷新binary log。
6.innodb_flush_method # 该参数控制日志或数据文件如何write、flush。可选的值为fsync，o_dsync，o_direct，littlesync，nosync。
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql分库分表策略]]></title>
        <id>https://esp0x.github.io/post/mysql-fen-ku-fen-biao-ce-lue/</id>
        <link href="https://esp0x.github.io/post/mysql-fen-ku-fen-biao-ce-lue/">
        </link>
        <updated>2021-01-15T02:12:20.000Z</updated>
        <content type="html"><![CDATA[<p>数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库性能的目的。</p>
<h2 id="垂直切分">垂直切分</h2>
<p><img src="https://esp0x.github.io/post-images/1610676801903.jpg" alt="" loading="lazy"><br>
垂直切分常见有垂直分库和垂直分表两种：</p>
<p>垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库中。类似微服务架构，每一个微服务单独使用一个数据库的形式。</p>
<p>垂直分表是基于数据库中的列进行， 针对某个表字段过多，可以新建一张扩展表，将不常用的字段或长度较大的字段拆分到扩展表中。这样可以避免跨页问题，MySQL底层是通过数据页存储的，一条记录过大会导致跨页，造成额外的性能损失。</p>
<h3 id="垂直切分的优点">垂直切分的优点：</h3>
<ol>
<li>解决业务系统层面的耦合，使得业务逻辑更清晰；</li>
<li>与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等；</li>
<li>高并发场景下，垂直切分一定程度上能够提升访问性能；</li>
</ol>
<h3 id="垂直切分的缺点">垂直切分的缺点：</h3>
<ol>
<li>部分表无法join，只能通过接口方式，开发难度增加；</li>
<li>分布式事务处理复杂；</li>
<li>没有解决单表数据过大的问题；</li>
</ol>
<h2 id="水平切分">水平切分</h2>
<p><img src="https://esp0x.github.io/post-images/1610676821810.jpg" alt="" loading="lazy"><br>
当一个应用难以再细粒化的垂直切分，或切分后单表数据量过大，存在读写性能问题时，就需要考虑水平切分了。</p>
<p>水平切分包括库内分表和分库分表，库内分表只解决了单一表数据量过大的问题，没有将表分布到不同的机器上，对于数据库访问性能提升有限。</p>
<h3 id="水平切分的优点">水平切分的优点：</h3>
<ol>
<li>不存在单表数据量过大问题，提升了表的访问性能；</li>
<li>应用端改造较小，不需要进行业务拆分；</li>
</ol>
<h3 id="水平切分的缺点">水平切分的缺点：</h3>
<ol>
<li>跨分片事务的一致性难以保证；</li>
<li>跨库的join关联查询性能较差；</li>
<li>数据库多次扩展难度和维护量增加；</li>
</ol>
<h2 id="几种典型的数据分片规则">几种典型的数据分片规则</h2>
<ul>
<li>
<p>根据数值范围</p>
<p>例如：按照时间维度，将不同月，甚至不同日的数据存储到不同的表；又或者，按照userId进行划分，1-9999的记录分到第一个库，10000-20000的分到第二个库，以此类推；</p>
<p>优点：</p>
<ol>
<li>单表大小可控；</li>
<li>天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点，无需对其他分片进行数据迁移；</li>
<li>使用分片字段进行查询时，速度更快；</li>
</ol>
<p>缺点：</p>
<ol>
<li>热点数据成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间的数据，可能会被频繁地读写，有些分片存储历史数据，则很少被查询。</li>
</ol>
</li>
<li>
<p>根据数值取模</p>
<p>一般采用hash取模mod的切分方式。</p>
<p>优点：</p>
<ol>
<li>数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈；</li>
</ol>
<p>缺点：</p>
<ol>
<li>后期扩展时，需要迁移旧的数据；（通过一致性hash算法可以避免这个问题）</li>
<li>容易面临跨分片查询的复杂问题，比如频繁查询中不包含分片字段，将会导致无法定位数据库，从而向所有数据库发起请求，再在内存中合并数据，性能损失严重；</li>
</ol>
</li>
</ul>
<h2 id="分库分表需要解决的问题">分库分表需要解决的问题</h2>
<ul>
<li>
<p>事务问题</p>
<p>方案一：使用分布式事务，交由数据库管理，简单有效；缺点是随着节点增加，性能代价越来越高。（需要协调的节点变多）</p>
<p>方案二：由应用程序和数据库共同控制，性能上有优势；缺点是开发难度较大；</p>
</li>
<li>
<p>跨节点Join问题</p>
<p>分两次查询，第一次查询的结果集中找出关联数据的ID，根据这些ID发起第二次请求得到关联数据；在应用设计时应尽量避免进行关联查询；</p>
</li>
<li>
<p>跨节点的count、order by、group by以及聚合函数问题</p>
<p>分别在各个节点进行数据合并，最后在统一进行合并，缺点是当数据集较大时，占用的内存资源很多；</p>
</li>
<li>
<p>数据迁移、容量规划、扩容等问题</p>
<p>当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。此外还需要根据当前的数据量和QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过1000W）如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。</p>
</li>
<li>
<p>全局主键避重问题</p>
<p>由于表同时存在于多个数据库中，主键值设置为自增序列将不能使用，需要单独设计全局主键，一般可以用UUID的方案解决；</p>
</li>
<li>
<p>跨分片的排序分页</p>
<p>一般来讲，分页时需要按照指定字段进行排序。当排序字段就是分片字段的时候，我们通过分片规则可以比较容易定位到指定的分片，而当排序字段非分片字段的时候，情况就会变得比较复杂了。为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。</p>
<p>如果是在前台应用提供分页，则限定用户只能看前面n页，这个限制在业务上也是合理的，一般看后面的分页意义不大（如果一定要看，可以要求用户缩小范围重新查询）。</p>
<p>如果是后台批处理任务要求分批获取数据，则可以加大page size，比如每次获取5000条记录，有效减少分页数（当然离线访问一般走备库，避免冲击主库）。</p>
<p>分库设计时，一般还有配套大数据平台汇总所有分库的记录，有些分页查询可以考虑走大数据平台。</p>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mysql主从复制原理]]></title>
        <id>https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-yuan-li/</id>
        <link href="https://esp0x.github.io/post/mysql-zhu-cong-fu-zhi-yuan-li/">
        </link>
        <updated>2021-01-14T08:23:14.000Z</updated>
        <content type="html"><![CDATA[<h3 id="原理图如下">原理图如下：</h3>
<figure data-type="image" tabindex="1"><img src="https://esp0x.github.io/post-images/1610671157156.png" alt="" loading="lazy"></figure>
<h2 id="主从复制流程详解">主从复制流程详解：</h2>
<ol>
<li>master库发生数据改变时，会将改变写入binglog日志；</li>
<li>slave库会在一定时间间隔内对master的binlog进行检测以确定是否发生改变，如果发生改变，则开始一个IO thread请求master二进制事件；</li>
<li>同时，master为每一个过来请求的IO thread开启一个dump线程，用于将二进制事件发送给IO thread，slave的IO thread将此二进制事件写入本地relay log（中继日志）中，并开启SQL thread从中继日志中读取二进制日志，在本地进行重放（replay），从而使得本地数据与master保持一致；最后IO thread和SQL thread进入睡眠状态，等待下次唤醒。</li>
</ol>
<h2 id="主从复制形式">主从复制形式：</h2>
<ol>
<li>主从</li>
<li>主主</li>
<li>一主多从</li>
<li>多主一从</li>
<li>联级复制</li>
</ol>
<h2 id="主从同步延时分析">主从同步延时分析：</h2>
<ol>
<li>master对所有DDL和DML产生的日志都写入binlog，由于是顺序写，所以效率很高；反之，slave的SQL thread进行relay log的重放时，DML和DDL的IO是随机的，不是顺序，所以成本较高，这里会增加一部分延时；</li>
<li>由于SQL thread是单线程的，当master的并发较高时，过多的DML可能会导致slave的SQL thread来不及处理，这里会增加一部分延时；</li>
<li>slave中有部分SQL产生了锁等待，这种情况就是slave有一些读请求与重放请求产生了锁冲突导致的，也会增加延时；</li>
<li>slave在充当读库角色的时候，如果查询访问压力过大，会消耗部分系统资源，影响同步效率；</li>
<li>大事务执行，即当master有大事务执行时，比如执行了10分钟，binlog写入必须要等待事务处理完毕，那么slave开始进行同步的时候就已经延时10分钟了；</li>
</ol>
<h2 id="延时解决办法">延时解决办法：</h2>
<ol>
<li>业务层实现读写分离，一主多从，主写从读，分散压力；</li>
<li>业务层和数据库层之间加入缓存策略，降低直接对数据库的读压力；频繁写的场景不适合加缓存，会导致缓存命中降低；</li>
<li>升级硬件；</li>
<li>MTS问题，即多线程的slave，从5.6版本开始支持，针对不同粒度（库、表、行）设置并行同步；</li>
</ol>
<h2 id="57版本后的并行复制策略">5.7版本后的并行复制策略</h2>
<h4 id="redo-log的两阶段提交">Redo log的两阶段提交</h4>
<ul>
<li>先写redo，再写binlog：假设在redo写完，binlog还没有写完的时候，Mysql进程异常重启，这时仍然能够通过redo log恢复数据，但由于binlog没有这条记录，所以之后备份日志的时候，binlog是缺失这条记录的，以后需要用binlog恢复数据时，就会缺少一条数据的更新；</li>
<li>先写binlog，再写redo log：如果binlog写完后crash，由于redo log还没写，崩溃恢复后这个事务无效，但是binlog有记录，以后用这个binlog恢复数据时，就会多出一条更新记录；</li>
<li>二阶段提交：使用二阶段提交时，会综合redo和binlog的状态进行处理，如果写入binlog之前crash，那么由于redo处于prepare阶段，只需要对当前事务进行回滚即可；如果写入binlog之后crash，那么由于redo处于prepare阶段，只需要对当前事务进行提交即可。</li>
</ul>
<h4 id="并行复制的思想">并行复制的思想</h4>
<ol>
<li>同时处于prepare状态的事务，在备库执行是可以并行的；</li>
<li>处于prepare状态的事务，与处于commit状态的事务之间，在备库执行也是可以并行的；</li>
<li>binlog_group_commit_sync_delay参数，表示延迟多少微妙后才调用fsync；</li>
<li>binlog_group_commit_sync_no_delay_count参数，表示累积多少次以后才调用fsync；</li>
</ol>
]]></content>
    </entry>
</feed>